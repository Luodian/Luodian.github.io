<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>机器学习-第四章-SVM（Updating） | Luodian.ink</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="主要梳理以下三个方向：支持向量机，核函数，序列最小最优化算法 支持向量机支持向量学习方法包含构建线性可分支持向量机（Linear support vector machine in linearly separable case）、线性支持向量机（Linear support vector machine）及非线性支持">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习-第四章-SVM（Updating）">
<meta property="og:url" content="https://www.luodian.ink/2017-11-26/机器学习-第四章-SVM/index.html">
<meta property="og:site_name" content="Luodian.ink">
<meta property="og:description" content="主要梳理以下三个方向：支持向量机，核函数，序列最小最优化算法 支持向量机支持向量学习方法包含构建线性可分支持向量机（Linear support vector machine in linearly separable case）、线性支持向量机（Linear support vector machine）及非线性支持向量机（non-linear support vector machine）。">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2017-12-01T07:12:39.150Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习-第四章-SVM（Updating）">
<meta name="twitter:description" content="主要梳理以下三个方向：支持向量机，核函数，序列最小最优化算法 支持向量机支持向量学习方法包含构建线性可分支持向量机（Linear support vector machine in linearly separable case）、线性支持向量机（Linear support vector machine）及非线性支持向量机（non-linear support vector machine）。">
  
    <link rel="alternate" href="/atom.xml" title="Luodian.ink" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  

</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Luodian.ink</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://www.luodian.ink"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-机器学习-第四章-SVM" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017-11-26/机器学习-第四章-SVM/" class="article-date">
  <time datetime="2017-11-26T11:41:31.000Z" itemprop="datePublished">2017-11-26</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      机器学习-第四章-SVM（Updating）
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>主要梳理以下三个方向：支持向量机，核函数，序列最小最优化算法</p>
<h2 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h2><p>支持向量学习方法包含构建线性可分支持向量机（Linear support vector machine in linearly separable case）、线性支持向量机（Linear support vector machine）及非线性支持向量机（non-linear support vector machine）。</p>
<p>在提到SVM以及逻辑回归，有如下几种情况。</p>
<ul>
<li>当我们使用线性可分的数据集时，通过硬间隔最大化（hard margin maximization），学习一个线性的分类器，即线性可分支持向量机。</li>
<li>当训练数据近似可分，通过软间隔最大化（soft margin maximization），也学习一个线性分类器。</li>
<li>再则，当训练数据线性不可分时，通过引入核技巧（kernel trick）及软间隔最大化，学习非线性支持向量机。</li>
</ul>
<h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>假设在给定的特征空间训练集如下：$T = \{(x_1,y_1),…(x_n,y_n)\}$，其中，$x_i \in \chi= \Re^n, y_i \in \{1,-1\}$</p>
<p>假设训练数据集是线性可分的，我们需要找到一个分离的超平面 $w \cdot x + b$ 能够将不同的实例分成两部分，我们利用间隔最大化求最优的分离超平面，这时，解是唯一的。</p>
<h3 id="函数间隔和几何间隔"><a href="#函数间隔和几何间隔" class="headerlink" title="函数间隔和几何间隔"></a>函数间隔和几何间隔</h3><p><strong>函数间隔</strong>：</p>
<ol>
<li>定义给定的数据集 $T$ 和超平面 $（w，b）$.</li>
<li>定义超平面 $(w,b)$ 和样本点 $(x_i,y_i)$ 的函数间隔为：$\hat{\gamma} = y_i(w \dot x_i + b)$.</li>
<li>定义超平面 $(w,b)$ 和数据集 $T$ 的函数间隔为：$\hat{\gamma} = min_{1…n}(\hat{\gamma}_i)$.</li>
</ol>
<p><strong>几何间隔</strong></p>
<p>由于函数间隔在成倍数变化时，虽然超平面不变动，但是数值却在发生变化，因此我们继续定义几何间隔来对函数间隔进行规范化。</p>
<p>几何间隔：$\gamma_i = \frac{w}{\mid \mid w \mid \mid} \cdot x_i + \frac{b}{\mid \mid w \mid \mid}$</p>
<p><strong>为什么要间隔最大化</strong></p>
<p>对于训练数据及找到几何间隔最大化的超平面意味着以充分大的确信度（我们可以定义离超平面越远的点对于分类面的确信度越大）对训练数据进行分类，这样的分类结果对于最难分类的点也有足够大的确信度将其分开，这样的超平面应该对未知的新实例有更好的泛化的效果。</p>
<p><strong>支持向量和间隔边界</strong></p>
<p>在线性可分的情况下，训练数据的样本点与分离超平面距离最近的样本点的实例称为支持向量（Support Vector）.支持向量是使约束条件式子等号成立的点，即 $y_i(w \cdot x_i + b) - 1=0$</p>
<p>对于 $y_i = +1$ 的正例点，支持向量在超平面：$H_1:w \cdot x + b = 1$ 上。</p>
<p>对于 $y_i = -1$ 的负例点，支持向量在超平面：$H_1:w \cdot x + b = -1$ 上。</p>
<blockquote>
<p>在决定分离平面时只有支持向量起作用，支持向量两侧的其余点并不起作用，所以我们将这种分类模型称为支持向量机，支持向量的个数一般很少，所以支持向量机由很少的『重要的』训练样本决定。</p>
</blockquote>
<p><strong>拉格朗日对偶</strong></p>
<p>通过求解对偶问题的解来获取原问题的最优解，被称为Linear SVM的对偶算法，这样做的优点在于，一是，对偶问题往往更容易求解，二是，引入核函数，进而推广到非线性分类问题。</p>
<p>定义拉格朗日函数：$L(w,b,\alpha) = \frac{1}{2} \mid \mid w \mid \mid^2 - \Sigma^N_{i} \alpha_i y_i(w \cdot x_i + b) + \Sigma^N_{i} \alpha_i$. </p>
<p>对于支持向量需要尽量满足 $y_i(w  \cdot x_i + b) - 1 \geq0$，根据拉格朗日对偶性，原始问题的对偶问题是极大极小问题：$\max \limits_{\alpha} \cdot \min \limits_{w,b} \{L(w,b,a)\}$.</p>
<h2 id="核技巧"><a href="#核技巧" class="headerlink" title="核技巧"></a>核技巧</h2><p>当输入空间为欧式空间或者离散集合，特征空间为希尔伯特空间时，核函数表示将输入从输入空间映射到特征空间得到的特征向量之间的内积，通过核函数可以学习到非线性支持向量机，等价于隐式地在高维的特征空间中学习线性支持向量机，这样的方法称为核技巧。</p>
<p>概述的说，线性SVM+核技巧 = 非线性SVM。</p>
<blockquote>
<p>希尔伯特空间：抽象空间中的极限与实数上的极限有一个很大的不同就是，极限点可能不在原来给定的集合中，所以又引入了完备的概念，完备的内积空间就称为Hilbert空间。</p>
</blockquote>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://www.luodian.ink/2017-11-26/机器学习-第四章-SVM/" data-id="cjeaokidf001sf51ypetlb0vw" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2017-11-29/11-29-异常检测周报/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          11-29-异常检测周报
        
      </div>
    </a>
  
  
    <a href="/2017-11-26/机器学习-第三章-逻辑回归/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">机器学习复习-第三章-逻辑回归（Updating）</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Codeforces/">Codeforces</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Kaggle/">Kaggle</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/其余/">其余</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/分布式计算/">分布式计算</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/异常检测/">异常检测</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/投资/">投资</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/操作系统/">操作系统</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/时间序列/">时间序列</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/软件工程/">软件工程</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/量化交易/">量化交易</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/随想/">随想</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/大数据异常检测/">大数据异常检测</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/机器学习/">机器学习</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/大数据异常检测/" style="font-size: 10px;">大数据异常检测</a> <a href="/tags/机器学习/" style="font-size: 20px;">机器学习</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">三月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">二月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">一月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">十二月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">十一月 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018-03-01/2018-MetaTrade-网格交易简述/">MetaTrader-网格交易简述</a>
          </li>
        
          <li>
            <a href="/2018-02-26/异常检测-2018春季第一周周报/">异常检测-2018春季第一周周报</a>
          </li>
        
          <li>
            <a href="/2018-01-24/Contest-911-D-Inversion-Counting/">Contest-911-D-Inversion Counting</a>
          </li>
        
          <li>
            <a href="/2017-12-29/基于统计方法进行时序数据预测的异常检测模型/">基于统计方法进行时序数据预测的异常检测模型</a>
          </li>
        
          <li>
            <a href="/2017-12-27/数据之美-时间序列分析/">数据之美-时间序列分析</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 Luodian<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>