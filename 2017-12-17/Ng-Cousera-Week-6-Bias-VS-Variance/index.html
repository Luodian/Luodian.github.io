<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>Ng&#39;Cousera-Week 6-Bias vs Variance | Luodian.ink</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Diagnosing Bias vs. VarianceIn this section we examine the relationship between the degree of the polynomial d and the underfitting or overfitting of our hypoth">
<meta property="og:type" content="article">
<meta property="og:title" content="Ng&#39;Cousera-Week 6-Bias vs Variance">
<meta property="og:url" content="https://www.luodian.ink/2017-12-17/Ng-Cousera-Week-6-Bias-VS-Variance/index.html">
<meta property="og:site_name" content="Luodian.ink">
<meta property="og:description" content="Diagnosing Bias vs. VarianceIn this section we examine the relationship between the degree of the polynomial d and the underfitting or overfitting of our hypothesis.  We need to distinguish whether bi">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://ws2.sinaimg.cn/large/006tKfTcly1fmk9nubr83j308c073t8s.jpg">
<meta property="og:image" content="https://ws4.sinaimg.cn/large/006tKfTcly1fmk9pevgxgj30jj0ak74u.jpg">
<meta property="og:updated_time" content="2017-12-17T17:17:25.483Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Ng&#39;Cousera-Week 6-Bias vs Variance">
<meta name="twitter:description" content="Diagnosing Bias vs. VarianceIn this section we examine the relationship between the degree of the polynomial d and the underfitting or overfitting of our hypothesis.  We need to distinguish whether bi">
<meta name="twitter:image" content="https://ws2.sinaimg.cn/large/006tKfTcly1fmk9nubr83j308c073t8s.jpg">
  
    <link rel="alternate" href="/atom.xml" title="Luodian.ink" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  

</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Luodian.ink</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://www.luodian.ink"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Ng-Cousera-Week-6-Bias-VS-Variance" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017-12-17/Ng-Cousera-Week-6-Bias-VS-Variance/" class="article-date">
  <time datetime="2017-12-17T10:26:55.000Z" itemprop="datePublished">2017-12-17</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Ng&#39;Cousera-Week 6-Bias vs Variance
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Diagnosing-Bias-vs-Variance"><a href="#Diagnosing-Bias-vs-Variance" class="headerlink" title="Diagnosing Bias vs. Variance"></a>Diagnosing Bias vs. Variance</h1><p>In this section we examine the relationship between the degree of the polynomial d and the underfitting or overfitting of our hypothesis.</p>
<ul>
<li>We need to distinguish whether <strong>bias</strong> or <strong>variance</strong> is the problem contributing to bad predictions.</li>
<li>High bias is underfitting and high variance is overfitting. Ideally, we need to find a golden mean between these two.</li>
</ul>
<p>The training error will tend to <strong>decrease</strong> as we increase the degree d of the polynomial.</p>
<p>At the same time, the cross validation error will tend to <strong>decrease</strong> as we increase d up to a point, and then it will <strong>increase</strong> as d is increased, forming a convex curve.</p>
<p><strong>High bias (underfitting)</strong>: both Jtrain(Θ) and JCV(Θ) will be high. Also, JCV(Θ)≈Jtrain(Θ).</p>
<p><strong>High variance (overfitting)</strong>: Jtrain(Θ) will be low and JCV(Θ) will be much greater than Jtrain(Θ).</p>
<p>The is summarized in the figure below:</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1fmk9nubr83j308c073t8s.jpg" alt=""></p>
<h3 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h3><p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1fmk9pevgxgj30jj0ak74u.jpg" alt=""></p>
<p>In the figure above, we see that as $\lambda$ increases, our fit becomes more rigid. On the other hand, as $\lambda$ approaches 0, we tend to over overfit the data. So how do we choose our parameter $\lambda$ to get it ‘just right’ ? In order to choose the model and the regularization term $\lambda$, we need to:</p>
<ol>
<li>Create a list of lambdas (i.e. $\lambda \in {0,0.01,0.02,0.04,0.08,0.16,0.32,0.64,1.28,2.56,5.12,10.24})$;</li>
<li>Create a set of models with different degrees or any other variants.</li>
<li>Iterate through the λs and for each λ go through all the models to learn some  $\theta$  .</li>
<li>Compute the cross validation error using the learned  $\theta$   (computed with λ) on the $J_{CV}(\theta) $  <strong>without</strong> regularization or λ = 0.</li>
<li>Select the best combo that produces the lowest error on the cross validation set.</li>
<li>Using the best combo $\theta$  and λ, apply it on $J_{CV}(\theta) $ to see if it has a good generalization of the problem.</li>
</ol>
<h3 id="Decision"><a href="#Decision" class="headerlink" title="Decision"></a>Decision</h3><p>Our decision process can be broken down as follows:</p>
<ul>
<li><strong>Getting more training examples:</strong> Fixes high variance</li>
</ul>
<ul>
<li><strong>Trying smaller sets of features:</strong> Fixes high variance</li>
</ul>
<ul>
<li><strong>Adding features:</strong> Fixes high bias</li>
</ul>
<ul>
<li><strong>Adding polynomial features:</strong> Fixes high bias</li>
</ul>
<ul>
<li><strong>Decreasing λ:</strong> Fixes high bias</li>
</ul>
<ul>
<li><strong>Increasing λ:</strong> Fixes high variance.</li>
</ul>
<h1 id="Diagnosing-Neural-Networks"><a href="#Diagnosing-Neural-Networks" class="headerlink" title="Diagnosing Neural Networks"></a>Diagnosing Neural Networks</h1><ul>
<li>A neural network with fewer parameters is <strong>prone to underfitting</strong>. It is also <strong>computationally cheaper</strong>.</li>
<li>A large neural network with more parameters is <strong>prone to overfitting</strong>. It is also <strong>computationally expensive</strong>. In this case you can use regularization (increase λ) to address the overfitting.</li>
</ul>
<p>Using a single hidden layer is a good starting default. You can train your neural network on a number of hidden layers using your cross validation set. You can then select the one that performs best. </p>
<blockquote>
<p>网络越大越好，不要因噎废食怕过拟合就用小网络。上大网络加正则化肯定比小网络好，因为大网络加正则化后的损失函数更容易优化到一个更小的局部极值点，对随机初始化的依赖更小。</p>
</blockquote>
<p><strong>Model Complexity Effects:</strong></p>
<ul>
<li>Lower-order polynomials (low model complexity) have high bias and low variance. In this case, the model fits poorly consistently.</li>
<li>Higher-order polynomials (high model complexity) fit the training data extremely well and the test data extremely poorly. These have low bias on the training data, but very high variance.</li>
<li>In reality, we would want to choose a model somewhere in between, that can generalize well but also fits the data reasonably well.</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://www.luodian.ink/2017-12-17/Ng-Cousera-Week-6-Bias-VS-Variance/" data-id="cjeaokic5000ff51ypm1cg3ic" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2017-12-21/操作系统-文件系统/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          操作系统-文件系统
        
      </div>
    </a>
  
  
    <a href="/2017-12-12/软件工程-复习总结/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">软件工程-复习总结</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Codeforces/">Codeforces</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Kaggle/">Kaggle</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/其余/">其余</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/分布式计算/">分布式计算</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/异常检测/">异常检测</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/投资/">投资</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/操作系统/">操作系统</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/时间序列/">时间序列</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/软件工程/">软件工程</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/量化交易/">量化交易</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/随想/">随想</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/大数据异常检测/">大数据异常检测</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/机器学习/">机器学习</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/大数据异常检测/" style="font-size: 10px;">大数据异常检测</a> <a href="/tags/机器学习/" style="font-size: 20px;">机器学习</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">三月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">二月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">一月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">十二月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">十一月 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018-03-01/2018-MetaTrade-网格交易简述/">MetaTrader-网格交易简述</a>
          </li>
        
          <li>
            <a href="/2018-02-26/异常检测-2018春季第一周周报/">异常检测-2018春季第一周周报</a>
          </li>
        
          <li>
            <a href="/2018-01-24/Contest-911-D-Inversion-Counting/">Contest-911-D-Inversion Counting</a>
          </li>
        
          <li>
            <a href="/2017-12-29/基于统计方法进行时序数据预测的异常检测模型/">基于统计方法进行时序数据预测的异常检测模型</a>
          </li>
        
          <li>
            <a href="/2017-12-27/数据之美-时间序列分析/">数据之美-时间序列分析</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 Luodian<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>