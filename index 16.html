<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-CN">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta property="og:type" content="website">
<meta property="og:title" content="Luodian.ink">
<meta property="og:url" content="https://www.luodian.ink/index.html">
<meta property="og:site_name" content="Luodian.ink">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Luodian.ink">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://www.luodian.ink/"/>





  <title>Luodian.ink</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Luodian.ink</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.luodian.ink/2018-03-04/异常检测-面向大数据的异常检测算法设计分析/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Luodian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Luodian.ink">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018-03-04/异常检测-面向大数据的异常检测算法设计分析/" itemprop="url">异常检测-面向大数据的异常检测算法设计分析</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-03-04T10:50:26+08:00">
                2018-03-04
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/异常检测/" itemprop="url" rel="index">
                    <span itemprop="name">异常检测</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="面向大数据的异常检测问题分析"><a href="#面向大数据的异常检测问题分析" class="headerlink" title="面向大数据的异常检测问题分析"></a>面向大数据的异常检测问题分析</h1><blockquote>
<p>15-李博</p>
</blockquote>
<h3 id="时间序列"><a href="#时间序列" class="headerlink" title="时间序列"></a>时间序列</h3><p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fozk9gk6cgj30je0b4gmr.jpg" alt=""></p>
<p><strong>时间序列是指按照时间先后顺序排列的各个观测记录的有序集合</strong>，广泛存在于商业、经济、工程、社会科学和医学等领域。随着时间的推移 ，时问序列通常包含大量的信息，是建模和预测的主要依据。对时间序列进行分析，可以揭示事物运动、变化和发展的内在规律，对于人们正确认识事物并据此做出科学决策具有重要的现实意义。</p>
<p>时间序列的一个固有特征是相邻的观测值之间存在着相互的依赖性，这种相互的依赖性往往蕴含着被观测事物或现象在特定环境或特定时刻的大量信息，研究与分析这种相互的依赖性具有极大的实用价值。</p>
<h3 id="异常数据"><a href="#异常数据" class="headerlink" title="异常数据"></a>异常数据</h3><p>异常是数据中的特定模式，这些模式与事先定义的正常模式存在不一致。时间序列异常是时间序列上下文中与正常模式存在不一致的时间子序列。在时间序列中，数据每一时期都受到多种因素的共同作用，通常产生异常点的原因主要包括：</p>
<ol>
<li>数据受到新机制的作用，如欺诈、入侵、疾病的爆发、不寻常的实验结果等。这些异常点出现是因为有新事物出现或者新情况发生，比如经济领域时间序列研究中，某种经济政策的出台；地质模型中某种可能含有矿藏的地层的发现；由于罢工、广告促销、突发性政治或经济重大事件、物理系统的突变等，这些因素会造成不同于寻常模式的观测结果。这类异常点通常蕴涵着具体的意义，也往往是研究者感兴趣 的，异常点诊断旨在识别出这些现象背后的本质起因。</li>
<li>数据变化固有规律引起，这是自然发生的，反映了数据的分布特征，如气候变化、基因突变等。</li>
<li>数据测量收集误差引起，主要是由于人为差错、测量仪器故障。</li>
</ol>
<p>时间序列是受监测事物状态的具体表现，而异常数据同样也包含着不可忽略的重要信息，数据的异常表明着数据所表征的物理设备或者是统计信息在局部或者是周期出现了异常的波动，而这些波动是我们需要在生产生活中去检测到并加以避免的。</p>
<h3 id="基本算法"><a href="#基本算法" class="headerlink" title="基本算法"></a>基本算法</h3><p>针对于异常检测，前人已经做了很多相关的工作，这里我们列举一些异常检测的基本算法思路。</p>
<ol>
<li><p>基于假设检验的方法</p>
<p>假设检验是最早用来发现异常样本的基于统计学原理的方法，它基于对小概率事件的判别来实现对数据样本异 常性的鉴别，如 t 检验、Dixon 检验 、Grubs 检验等。</p>
<p>这种方法的难点在于对于分布特征未知的数据，使用先验假设具有很大的不确定性和局限性。</p>
</li>
<li><p>基于线性模型的统计学方法</p>
<p>对原始数据变换弱化原时间序列的相关性，使其满足经典线性回归的各项假设条件。在回归框架下又细分为<strong>残差分析方法</strong>和<strong>影响分析方法</strong>，前者是根据线性框架的拟合效果来判别数据是否异常，后者则是根据数据对于统计量的影响来判别。</p>
<p>这种方法的效率很高，但是对于数据选择有一定的局限性，大部分的经典的线性回归模型，如ARIMA等，都需要数据满足一些前提假设。</p>
</li>
<li><p>基于聚类的算法</p>
<p>这类算法将数据集分成若干类 ，不属于任何类的数据点就是异常点，比较典型的算法有 DBSCAN，Isolated Forest等。这类方法看似好用，但是却存在着算法效率较低，而且特定的算法对于数据集以及参数的要求较高，较难真正的普适到更多的应用场景。</p>
</li>
<li><p>基于密度的算法</p>
<p>基于密度的方法主要有（LOF：local outlier factor），LOF即为数据对象邻域的平均可达密度与其自身的可达密 度之比，LOF越大，其离群程度越高。LOF检测的效果不错，但是同样依赖于参数而且算法效率较低。</p>
</li>
<li><p>基于极值理论的算法</p>
<p>大道至简，近年来，很多学者开始将极值理论应用到时间序列异常诊断中，模型异常点诊断的关键就是决定检验统计量在一定的显著水平下是否超越某一临界值。这种方法可行且好用，可以作为 2 类方法设计的补充或者是一部分，且关于如何选取阈值大小，以及阈值种类，都是有着很多的学问以及相关研究。</p>
</li>
</ol>
<h3 id="工业级别大数据的异常检测"><a href="#工业级别大数据的异常检测" class="headerlink" title="工业级别大数据的异常检测"></a>工业级别大数据的异常检测</h3><p>随着技术的发展，可监测对象的种类越来越多，采集数据的设备数量越来越大。时间序列的多样性与规模化对时间序列异常检测方法提出了新的要求。</p>
<p>上述的算法在面向工业数据应用时，普遍存在着<strong>检测效果</strong>以及<strong>检测性能</strong>的问题。</p>
<ul>
<li>现有异常检测方法在检测效果方面无法适应时间序列多样化的要求，大多方法脱离了论文，应用到实战中，便需要结合对于数据的深刻理解，才能够调整出合适的参数，识别出异常。</li>
<li>另外大部分方法基于机器学习算法设计，算法检测效果虽然较好，但是一旦数据集过大，在内存和时间方面的效率远不能达到我们理想的要求。</li>
</ul>
<p>在结合大数据方面的相关文献以及我们对于异常检测问题的粗浅理解，在下面我们简单的分析针对于工业级别大数据的异常检测算法的设计思路。</p>
<ol>
<li><p><strong>通过降维减小数据维度</strong></p>
<p>通常，我们的时间序列数据是多维的，多维时间序列可用于描述受监测事物的多个方面状态与情况，然而随着维度的增长，多时间序列异常异常检测的计算时间会快速增加。通过观察发现当时间序列存在与异常发生原因无关的维度时，进行一些相关性分析，去除无关维度不会对异常检测的准确性产生决定性影响。</p>
</li>
<li><p><strong>使用简单的线性判别</strong></p>
<p>在时间序列的研究当中，很多时候少即是多，时间序列受随机性，趋势性影响较大，往往越多的参数，越复杂的模型意味着很难去长时间，更泛化的拟合真实的数据。而模型的复杂通常也意味着复杂度的提升，因此我们提倡在大数据算法的设计当中，可以适当的为了泛化能力以及时间效率，选择较为简单的线性方法进行粗略的异常判别，后续再使用更精确的算法对子区间进行判别。</p>
</li>
<li><p><strong>尽量设计在线的算法</strong></p>
<p>目前大多数异常检测方法均为静态方法，即对历史中特定段落的时间序列进行分析并得出结果。静态的时间序列方法不能应用于实时的时间序列异常检测。然而在许多应用场景中时间序列是不断增长的，因此我们对于实时获得的时间序列中的异常的需求同样迫切。而且在线的算法也意味着效率近似于线性，是一件非常让人愉悦的事情。</p>
</li>
<li><p><strong>通过并行的思想改善耗时部分的性能</strong></p>
<p>大数据的异常检测对于检测方法提出了存储能力与计算能力的新要求。单个计算结点的存储能力与计算能力无法满足这些要求，我们需要利用并行化计算的方法改善异常检测方法的检测性能。</p>
<p>如何设计 Master 和 Slaver 结点的算法，以及它们划分，合并的关系，将哪个部分正确的，有效的用于并行计算，是这个方向上的研究重点。</p>
</li>
<li><p><strong>做好时间与检测效果的 Trade Off</strong></p>
<p>针对于大数据所设计出的算法，应该有相应的调整系数，能够平衡效率和检测效果的不同侧重。对于某些不需要高精度检测，但是实时性较强的环境，可以通过调整参数来达到相应的需求。</p>
</li>
<li><p><strong>以框架的方式设计算法</strong></p>
<p>以上所提出的几点，均是这个方向上的算法的设计思路，或者说期望达到的目标，一个算法想要很好的结合这三点是很困难的。因此我们认为或许可以使用框架的方式，将各种手段或者技术进行合理的整合，比如异常序列的粗预警，细预警的分离，多维数据，多指标检测的并行分离，等等手段，都可以通过框架的方式进行有机的整合，最终形成一个良好可用的算法。</p>
</li>
</ol>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>总的来说，时间序列的异常检测是一个在当下 CV 和 NLP 等异常火热的时代下，看起来似乎不那么耀眼的问题，但是它对于这个世界的生产生活具有同等，似乎还有更重要的意义。</p>
<p>目前对于普通的异常检测可能研究相对较多，但是考虑大数据背景的时序数据的异常检测的相关研究目前还不是很充分，这是一个急需去占领的高地，希望我们能在未来，看到更多的相关问题的解决方案。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.luodian.ink/2018-01-24/Contest-911-D-Inversion-Counting/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Luodian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Luodian.ink">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018-01-24/Contest-911-D-Inversion-Counting/" itemprop="url">Contest-911-D-Inversion Counting</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-01-24T22:48:49+08:00">
                2018-01-24
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Codeforces/" itemprop="url" rel="index">
                    <span itemprop="name">Codeforces</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><a href="http://codeforces.com/contest/911/problem/D" target="_blank" rel="noopener">http://codeforces.com/contest/911/problem/D</a></p>
<p>题目大意为：逆序对问题，事先求出有多少个逆序对，只用知道是奇数个还是偶数个即可，然后现在我们对l,r区间的序列进行 reverse 之后再问序列的逆序对是奇数个还是偶数个。</p>
<p>因为 $l,r$ 区间反转之后，如果原来的全是顺序对，那么现在会造成总共 $\frac{(len(l,r) <em> len(l,r) - 1)}{2}$ 个逆序对，所以总的逆序对个数为 原有逆序对（区间外逆序对个数）+ 新逆序对，<em>*如果新逆序对个数为奇数，则总逆序对的奇偶性发生改变。</em></em></p>
<p>如果原来的区间里含有m个逆序对，区间外逆序对个数为 $p$ 个，那么反转之后，逆序对会变成顺序对，原有顺序对会变成逆序对，同样总共会有新的 $\frac{(len(l,r) <em> len(l,r) - 1)}{2} - m$ 个逆序对产生，总的逆序对数变为 $\frac{(len(l,r) </em> len(l,r) - 1)}{2} - m + p$ 个，原逆序对数为 $m + p$ 个，怎么在只知道 $m + p$ ，不知道 $m$ 的情况下，推出的奇偶 $\frac{(len(l,r) * len(l,r) - 1)}{2} - m + p$ 性呢？</p>
<p>可以利用  $\frac{(len(l,r) <em> len(l,r) - 1)}{2} - m + p =  \frac{(len(l,r) </em> len(l,r) - 1)}{2} + m + p - 2m$ ，然后就可以利用 $m + p$ 的奇偶性，以及 $\frac{(len(l,r) <em> len(l,r) - 1)}{2}$ 的奇偶性，推出 $\frac{(len(l,r) </em> len(l,r) - 1)}{2} - m + p$ 的奇偶性了。</p>
<p>代码很简单：</p>
<pre><code class="lang-java">#include &lt;iostream&gt;
#include &lt;cstdio&gt;
#include &lt;iomanip&gt;
#include &lt;string&gt;
#include &lt;cstring&gt;
#include &lt;algorithm&gt;
#include &lt;cstdlib&gt;
#include &lt;vector&gt;
#include &lt;queue&gt;
#include &lt;stack&gt;
#include &lt;cmath&gt;
#include &lt;bitset&gt;
#include &lt;unordered_set&gt;
#include &lt;numeric&gt;
#include &lt;set&gt;
#include &lt;list&gt;
#include &lt;map&gt;

using namespace std;
#define lower_bound LB
#define upper_bound UB
#define mem(a,x) memset(a,x,sizeof(a))
#define rep(i,a,n) for (int i=a;i&lt;n;i++)
#define per(i,a,n) for (int i=n-1;i&gt;=a;i--)
#define mp make_pair
#define all(x) (x).begin(),(x).end()
#define SZ(x) ((int)(x).size())
#define IT iterator
#define test puts(&quot;OK&quot;)
#define lowbit(x) x &amp; -x
#define PRQ priority_queue
#define PB push_back
#define gcd(a,b) _gcd(a,b)


typedef long long LL;
typedef unsigned long long uLL;
typedef pair&lt;int,int&gt; pii;
typedef vector&lt;int&gt; VI;
typedef pair&lt;int,int&gt; PII;
typedef vector&lt;PII&gt; VPII;

const LL mod=1000000007;
const double PI = acos(-1.0);
const double eps = 1e-8;
const int INF = 0x3f3f3f3f;

int main()
{
    #ifndef ONLINE_JUDGE
        freopen(&quot;D.txt&quot;,&quot;r&quot;,stdin);
    #endif
    ios::sync_with_stdio(false);
    cin.tie(nullptr);
    cout.tie(nullptr);
    int n,m;
    int l,r;
    vector&lt;int&gt; ar;
    ar.clear();
    while(cin&gt;&gt;n)
    {
        ar.clear();
        for (int i = 0; i &lt; n; ++i)
        {
            int temp;
            cin&gt;&gt;temp;
            ar.PB(temp);
        }
        bool ret = 0;
        for (int i = 0; i &lt; n; ++i)
        {
            for (int j = i; j &lt; n; ++j)
            {
                if (ar[j] &lt; ar[i])
                {
                    ret ^= 1;
                }
            }
        }
//        cout&lt;&lt;ret&lt;&lt;endl;
        cin&gt;&gt;m;
        for (int i = 0; i &lt; m; ++i)
        {
            cin&gt;&gt;l&gt;&gt;r;
            int permutations = (r - l) * (r - l + 1) / 2;
            if (permutations &amp; 1)
            {
                ret ^= 1;
            }
            if (ret &amp; 1)
            {
                cout&lt;&lt;&quot;odd\n&quot;;
            }
            else
            {
                cout&lt;&lt;&quot;even\n&quot;;
            }
        }
    }
    return 0;
}
</code></pre>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.luodian.ink/2017-12-29/基于统计方法进行时序数据预测的异常检测模型/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Luodian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Luodian.ink">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017-12-29/基于统计方法进行时序数据预测的异常检测模型/" itemprop="url">基于统计方法进行时序数据预测的异常检测模型</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-12-29T13:57:30+08:00">
                2017-12-29
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/时间序列/" itemprop="url" rel="index">
                    <span itemprop="name">时间序列</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="时间序列数据异常检测报告"><a href="#时间序列数据异常检测报告" class="headerlink" title="时间序列数据异常检测报告"></a>时间序列数据异常检测报告</h1><blockquote>
<p>15级-李博</p>
<p>2017-12-29</p>
</blockquote>
<h2 id="基于统计方法进行时序数据预测的异常检测模型"><a href="#基于统计方法进行时序数据预测的异常检测模型" class="headerlink" title="基于统计方法进行时序数据预测的异常检测模型"></a>基于统计方法进行时序数据预测的异常检测模型</h2><h3 id="简述"><a href="#简述" class="headerlink" title="简述"></a>简述</h3><p>基于统计的预测，无非是根据收集过去时间的数据，建立一个模型，来计算未来时间的数据，建立的是一种数学或者统计模型，它能表现出已有数据的变化规律，因为大数定理的存在，定义了世间所有的行为都可以通过数字表示，并且存在一定的客观规律。</p>
<p>对于股票市场中存在的量化交易这一概念，即是指以先进的数学模型替代人为的主观判断，利用计算机技术从庞大的历史数据中海选能带来超额收益的多种『大概率』事件以制定策略，极大地减少了投资者情绪波动的影响，避免在市场极度狂热或悲观的情况下作出非理性的投资决策。</p>
<p>在这里我们从这个方向入手，通过传统股票市场的预测分析工具来进行我们的工业传感器数据分析，首先我简要分析其关联性：</p>
<ol>
<li>股票数据和传感器数据都具有趋势性，以及一定程度的随机性，趋势性保证了两者的数值会按照一定的规律变化，并且从长时间数据的角度看，其是较为连续的，因此我们可以使用ARIMA，EA等模型进行平滑处理，分析异常点。</li>
<li>股票数据根据金融因素，考虑通货膨胀等原因，可能会存在不断起伏，但是大趋势增长的情况。但是对于传感器数据，大多会在一定范围内震荡（如温度，湿度等数据因为物理因素的原因，不会高出一定范围），所以我们可以在EA（适用于渐进上升型数据）或者是ARIMA模型（适用于周期波动性数据）中进行决策。</li>
<li>传感器数据可能存在一定的周期，但是股票数据不一定存在明显周期性，这一点也是需要对模型进行修正调整的考虑因素之一。</li>
</ol>
<h2 id="模型方法介绍"><a href="#模型方法介绍" class="headerlink" title="模型方法介绍"></a>模型方法介绍</h2><p>在上一次周报中，我详细介绍了这种方法，现在在这里简单略过。</p>
<p>基于预测的异常检测模型如下图所示，$O_{data}$ 是真实数据，通过预测器得到预测数据，然后 $O_{data}$ 和 $P_{data}$分别作为比较器的输入，比较器输出的是真实数据中被判别为异常值的下标 $Index$。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fmxgr3umhej30vy0iwq2z.jpg" alt=""></p>
<h3 id="预测器"><a href="#预测器" class="headerlink" title="预测器"></a>预测器</h3><p>时间序列分析一般假设我们获得的数据在时域上具有一定的相互依赖关系，通常，如果传感器数值在 $t$ 时刻很高，那么在 $t+1$ 时刻价格也有一定的概率会比较高，而时间序列分析的目的包含以下两个方面：</p>
<ul>
<li>发现这种隐含的依赖关系，并增加我们对此类时间序列的理解；</li>
<li>对未观测到的或者尚未发生的时间序列进行预测。</li>
</ul>
<p>在接下来的分析中，我们认为时间序列 $X$ 由两部分组成，即 $X_t=\hat{X}_t+\epsilon_t$. 其中$\hat{X}_t$ 是有规律的序列而$ \epsilon_t$ 则无规律的噪声。有规律的 $X_t$ 包含我们想要发现的依赖关系（pattern），而 $\epsilon_t$ 我们认为在时间域内不存在相互依赖的关系，即 $\epsilon_t$ 和 $\epsilon_{t+1}$ 之间是相互独立的。</p>
<p>一个最简单的模型就是我们假设 $\epsilon_t$ 是一个随机数，服从一定的概率分布 $f_t(\epsilon)$。</p>
<p>可以发现，我们想要找到 $\hat{X}_t$ 而对 $ϵ_t$不怎么感兴趣。为了使有规律的 $\hat{X}_t$ 更加明显，我们通常希望能过滤到噪声，而最简单的过滤噪声的方法就是『取平均』。</p>
<p>而问题来了，对于时间序列信号来说，我们该如何取平均呢？这里便引出了我们的基于历史数据平滑曲线的几种方法，也即我们的预测期。</p>
<p>我们使用的预测器主要有以下几种（还在等待其余方法的补充）。</p>
<h4 id="对于时序数据的-F-t-m-的预测方法"><a href="#对于时序数据的-F-t-m-的预测方法" class="headerlink" title="对于时序数据的 $F_{t+m}$ 的预测方法"></a>对于时序数据的 $F_{t+m}$ 的预测方法</h4><h5 id="MA-滑动平均模型"><a href="#MA-滑动平均模型" class="headerlink" title="MA(滑动平均模型)"></a>MA(滑动平均模型)</h5><p>这种方法并不考虑数据的趋势性，单纯根据历史信息来求得当前点的滑动平均数值，参数 T（也即WindowSize） 决定了依赖历史的程度。</p>
<p>我们用 $S$ 表示处理后的序列，那么 $S_t$ 等于 $X_{t−T+1}$ 到 $X_t$ 的平均值，即</p>
<p> $S_t=\frac{1}{T}\Sigma^t_{i=t−T+1}X_i$</p>
<p>我们使用 $S_t \simeq \hat{X_t}$，下面我们使用滑动平均来预测 windmachine 的第一列的数据，并根据预测值进行异常检测。</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1fmvmepv069j31hc140772.jpg" alt=""></p>
<h5 id="EA-指数平均模型"><a href="#EA-指数平均模型" class="headerlink" title="EA(指数平均模型)"></a>EA(指数平均模型)</h5><p>在这里我们使用二阶指数平均，二阶在一阶的基础上增加了对于趋势的考量，更符合我们的数据要求，而三阶需要依赖于周期性，这点和上述的 ARIMA 模型所依赖的周期性也是相同的，下一步我们也需要加入周期性的考量。</p>
<p>我们可以看到，虽然指数平均在产生新的数列的时候考虑了所有的历史数据，但是仅仅考虑其静态值，即没有考虑时间序列当前的变化趋势。如果当前的股票处于<strong>上升趋势</strong>，那么当我们对明天的股票进行预测的时候，好的预测值不仅仅是对历史数据进行『平均』，而且要考虑到当前数据变化的<em>上升趋势</em>。同时考虑历史平均和变化趋势，这边是<strong>二阶指数平均</strong>。<br>我们先给出二阶指数平均的两种方法，如下</p>
<ol>
<li><p>$initialize$<br>$S_1 = X_1$<br>$b_1 = X_1−X_0$<br>$for  t &gt; 1$<br>$S_t = αX_t + (1−α) ( S_t−1+b_t−1)$<br>$b_t = β(S_t−S_t−1)+(1−β)b_t−1$<br>$end  for$</p>
<p>如果我们对 $X_{t+m}$ 之后的数值进行预测，那么我们的预测值为<br>$\hat{X}_{t+m} = S_t + mb_t$</p>
</li>
<li><p>$S′_0=X_0$<br>$S^{′′}_0=X_0$<br>$for  t \geq 1$<br>$\quad S^{‘}_t = \alpha X_t+(1-\alpha)S_{t-1}^{‘} \quad S^{‘’}_t = \alpha S^{‘}_t +(1-\alpha)S_{t-1}^{‘’}\quad S_t = 2S^{‘}_t-S^{‘’}_t$</p>
<p>end for</p>
<p>在方法二中，只有一个参数 $α$ 。其中$S^{‘}_t$为最基本的指数平均得到的结果，而 $S^{‘}_t - S^{“}_t$ 为变化的趋势.</p>
<p>如果我们对 $X_{t+m}$ 之后的数值进行预测，那么我们的预测值为<br>$\hat{X}_{t+m} = S_t +(m\frac{\alpha}{1-\alpha})(S^{‘}_t-S^{‘’}_{t})$</p>
</li>
</ol>
<p>我们利用二阶指数平均对于数据进行处理及异常检测的结果如下：</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fmxhde15csj31hc140wgw.jpg" alt=""></p>
<h4 id="用于修正的方法"><a href="#用于修正的方法" class="headerlink" title="用于修正的方法"></a>用于修正的方法</h4><h5 id="布林通道"><a href="#布林通道" class="headerlink" title="布林通道"></a>布林通道</h5><p>布林通道是一个在股票市场中经常使用的概念，它在应用上结合了移动平均和标准差的概念，其基本的型态是由三条轨道线组成的带状通道（中轨和上、下轨各一条）。上下轨分别由平均值加减二倍标准差（<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d113484745294ddf53ff5589762d9565d63b7c36" alt="\pm 2\sigma ">）得到，<strong>中轨</strong>为股价的平均成本，<strong>上轨</strong>和<strong>下轨</strong>可分别视为股价的压力线和支撑线。</p>
<blockquote>
<p>下图中红线为上轨，绿线为下轨，蓝线为滑动平均值。</p>
</blockquote>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1fmxkgfdm6wj30je0fgmxo.jpg" alt=""></p>
<p>由大数定律以及高斯分布模型，我们可以获知在上下二倍标准差基本涵盖了数据变化的95%左右的情况，如果超出这个分布，那么极有可能是异常点，因此在我们的模型中我们结合布林通道进行了异常点的修正。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1fmxkmds0frj30me0asmx7.jpg" alt=""></p>
<h5 id="RSI指数"><a href="#RSI指数" class="headerlink" title="RSI指数"></a>RSI指数</h5><p>RSI指数在证券市场中适用于衡量一段周期内增长和下降强弱对比的一个指标，其计算公式如下：</p>
<ol>
<li>RSI = 100×RS / (1+RS)</li>
<li>RS = X天的平均上涨点数 / X天的平均下跌点数</li>
</ol>
<p>通俗的讲，RSI 指数过高代表上涨明显（超买现象），意味着有可能会存在潜在的下跌，RSI指数过低则反之。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fmxkr5mywfg30f009qwel.gif" alt=""></p>
<p>下面是我们使用布林通道进行异常检测的测试：</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1fmxkzutsmwj31hc140n0g.jpg" alt=""></p>
<p>下面是我们使用修正之后的模型结合EA方法进行异常检测的情况：</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fmxl1rstxaj31hc140whb.jpg" alt=""></p>
<h3 id="比较器"><a href="#比较器" class="headerlink" title="比较器"></a>比较器</h3><p>预测器预测出当前时刻传感器的预测值后，还需要与真实值比较来判断当前时刻数据是否异常。一般的比较器都是通过阈值法，比如实际值超过预测值的一定比例就认为该点出现异常，进行报警。这种方式错误率比较大。在传感器数值模型的报警检测中没有使用这种方式，而是使用了两个串联的 Filter，只有当两个 Fliter 都认为该点异常时，才进行报警，下面简单介绍一下两个 Filter 的实现。</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1fmxgr0c6roj30y20m674f.jpg" alt="@图4.1 比较器模型 | center | 500x0"></p>
<h4 id="离散度Filter"><a href="#离散度Filter" class="headerlink" title="离散度Filter"></a>离散度Filter</h4><p>根据预测误差曲线离散程度过滤出可能的异常点。一个序列的方差表示该序列离散的程度，方差越大，表明该序列波动越大。如果一个预测误差序列方差比较大，那么我们认为预测误差的报警阈值相对大一些才比较合理。离散度 filter 利用了这一特性，我们对于这个真实数据点的前 $N$ 个点求方差，下一步阈值 filter 的输入为方差 $\sigma$.</p>
<h4 id="阈值Filter"><a href="#阈值Filter" class="headerlink" title="阈值Filter"></a>阈值Filter</h4><p>根据误差绝对值是否超过某个阈值过滤出可能的异常点。利用离散度 Filter 进行过滤时，报警阈值随着误差序列波动程度变大而变大，但是在输入数据比较小时，误差序列方差比较小，报警阈值也很小，容易出现误报。所以设计了根据方差 $\sigma$ 进行过滤的阈值 filter。阈值 filter 设计了一个分段阈值函数 $y=f(x)$，对于实际值 $x$ 和预测值 $p$ ，只有当 $|x-p|&gt;f(x)$ 时报警。实际使用中，可以根据数据寻找一个对数函数替换分段阈值函数，更易于参数调优。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h3 id="创新性"><a href="#创新性" class="headerlink" title="创新性"></a>创新性</h3><p>目前少见有人使用预测器 + 判别器的方式结合金融统计方法进行异常检测，这种方式本身比较新颖。主要优势有如下几点：</p>
<ol>
<li>相对于我们之前采用的机器学习的方法，这种方法即使在大数据的情况下也能够顺利完成，因为根据选取方法的不同，基本都是在 $O(N)$ 级别的方法。</li>
<li>可以实现在线实时预测，可以将成套的算法写入传感器芯片内作为硬件级别的预测，芯片内只需要存储规定 $N$ 日内的数据即可。</li>
</ol>
<h3 id="不足"><a href="#不足" class="headerlink" title="不足"></a>不足</h3><ol>
<li>在预测器中其实我们也应该考虑ARIMA或者是三阶指数平滑（即Holt-winters）模型，但是对于传感器数据的先验信息我们并不了解，导致我们不能够手动的设置其周期值，对于周期性不明确的情况，我们暂时使用 fix 方法作为补偿。</li>
<li>下一步我计划使用RNN作为预测器，使用LSTM方法，直接对数据进行预测，但是这种方法可能会比现有的方法更耗时，但是有可能会有更高的准确性，而且目前我已经在尝试使用 LSTM 提取数据的周期性，效果还不错。</li>
</ol>
<h4 id="困难点分析"><a href="#困难点分析" class="headerlink" title="困难点分析"></a>困难点分析</h4><ol>
<li>对数据的先验知识不够，这近似于一个非监督学习，如果要对效率有更高的要求可能需要更多的标记。</li>
<li>对未来这个系统的使用方法，使用对象和项目雏形不是很了解。</li>
<li>目前尚未完成对于数据的周期性提取的高效算法（LSTM相对来说比较耗时，对于大数据可能不太适用）。</li>
<li>目前尚未完成对于模式异常的识别。</li>
</ol>
<h4 id="研究方向"><a href="#研究方向" class="headerlink" title="研究方向"></a>研究方向</h4><ol>
<li>正在学习使用 RNN 进行序列的预测，到时候会根据正确性以及效率来和现有的方法进行选择以及比较。</li>
<li>正在考虑是否需要将大段的点异常归类为段异常，从而进行模式异常的识别。</li>
<li>在目前我们的实验中，主要使用了两种预测方法+两种修正方法，但实际上时序数据还有许多可以增加的模型和修正方法（我们倾向于使用多修正方法进行参数投票，最终用拟合的方式找出一个最适合我们训练数据的函数），这些方法的最终目的就是能够更加根据历史信息平滑的预测变化量，从而为我们的异常检测提出建议的值。</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.luodian.ink/2017-12-24/17周周报-使用Holt-Winters模型通过比对预测值进行异常检测/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Luodian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Luodian.ink">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017-12-24/17周周报-使用Holt-Winters模型通过比对预测值进行异常检测/" itemprop="url">17周周报-使用Holt-Winters模型通过比对预测值进行异常检测</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-12-24T20:43:29+08:00">
                2017-12-24
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/异常检测/" itemprop="url" rel="index">
                    <span itemprop="name">异常检测</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="基于预测比较模型的异常检测"><a href="#基于预测比较模型的异常检测" class="headerlink" title="基于预测比较模型的异常检测"></a>基于预测比较模型的异常检测</h1><blockquote>
<p>16周时，开始尝试一些新的思路与原有方法的对比，在比较了传统的滑动平均和现有的指数平均方法之后，我们采用Holt Winters方法从预测的角度来做误差分析。</p>
</blockquote>
<h3 id="新的方法"><a href="#新的方法" class="headerlink" title="新的方法"></a>新的方法</h3><p>在序列数据的异常检测过程中，我们既可以直接使用对序列进行异常检测的算法，也可以先对序列数据进行特征提取然后转化为传统的离群点检测。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>离群点检测方法</th>
<th>方法描述</th>
<th>方法特点</th>
</tr>
</thead>
<tbody>
<tr>
<td>基于统计</td>
<td>大部分的基于统计的离群点检测方法是构建一个概率分布模型，并计算对象符合该模型的概率，把具有低概率的对象视为离群点</td>
<td>基于统计模型的离群点检测方法的前提是必须知道数据集服从什么分布；而对于高维的数据，可能每一维度服从的分布都不太一致，所以通常对高维数据来讲通常效果较差。</td>
</tr>
<tr>
<td>基于邻近度</td>
<td>通常可以在数据对象之间定义邻近性度量，把远离大部分点的对象视为离群点。</td>
<td>算法假定离群点是离散的，低维数据我们可以作图观察，而高维数据我们无法观察，所以难以确定有效的参数和全局阈值，效果较差。</td>
</tr>
<tr>
<td>基于聚类</td>
<td>一种利用聚类检测离群点的方法是直接丢弃远离其他簇的小簇；另一种是对数据点属于簇的程度进行评价，去除得分较低的点。</td>
<td>聚类算法产生的簇的质量对该算法产生的离群点的质量影响非常大，对数据的可分类性要求较高</td>
</tr>
</tbody>
</table>
</div>
<p>之前考虑的算法方向主要是在『基于统计』+『基于聚类』的这个方向来考量。</p>
<p>而如今我发现了一种新的方法可以作为采用与尝试，即上图中『基于临近度』，也是一种使用历史数据判断当前数据的方法。</p>
<p>基于预测的异常检测模型如下图所示，$x_t$ 是真实数据，通过预测器得到预测数据，然后 $x_t$ 和 $p_t$ 分别作为比较器的输入，最终得到输出 $y_t$，$y_t$ 是一个二元值，可以用+1（+1表示输入数据正常），-1（-1表示输入数据异常）表示。</p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fmroslheqbj31d00m2jrh.jpg" alt=""></p>
<p>如果说我们设置异常检测的模型如此，那么我们可以从两个以下方面入手，一是预测器的优化，二是比较器的优化。</p>
<h4 id="预测器优化"><a href="#预测器优化" class="headerlink" title="预测器优化"></a>预测器优化</h4><h5 id="同比环比预测器"><a href="#同比环比预测器" class="headerlink" title="同比环比预测器"></a>同比环比预测器</h5><p>同比环比是比较常用的异常检测方式，它是将当前时刻数据和前一时刻数据（环比）或者前一天同一时刻数据（同比）比较，超过一定阈值即认为该点异常。如果用图模型来表示，那么预测器就可以表示为用当前时刻前一时刻或者前一天同一时刻数据作为当前时刻的预测数据。</p>
<p>如果将不同日期、时刻的监控数据以矩阵方式存储，每一行表示一天内不同时刻的监控数据，每一列表示同一时刻不同日期的监控数据，那么存储矩阵如下图所示：</p>
<p><img src="https://ws4.sinaimg.cn/large/006tNc79ly1fmroz08dq2j30a207ua9x.jpg" alt=""></p>
<p>假如需要预测图中黄色数据，那么环比使用图中的蓝色数据作为预测黄点的源数据，同比使用图中红色数据作为预测黄点的源数据。</p>
<h5 id="基线预测器（MA方法）"><a href="#基线预测器（MA方法）" class="headerlink" title="基线预测器（MA方法）"></a>基线预测器（MA方法）</h5><p>同比环比使用历史上的单点数据来预测当前数据，误差比较大。$t$ 时刻的监控数据，与<br>$t-1,t-2,…$ 时刻的监控数据存在相关性。同时，与$t-k,t-2k,…$ 时刻的数据也存在相关性（<em>k</em>为周期），如果能利用上这些相关数据对<em>t</em>时刻进行预测，预测结果的误差将会更小。</p>
<p>比较常用的方式是对历史数据求平均，然后过滤噪声，可以得到一个平滑的曲线（基线），使用基线数据来预测当前时刻的数据。该方法预测 $t$ 时刻数据（图中黄色数据）使用到的历史数据如下图所示（图中红色数据）：</p>
<p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1fmrozw8uuij309s07e745.jpg" alt=""></p>
<h5 id="Holt-Winters预测器"><a href="#Holt-Winters预测器" class="headerlink" title="Holt-Winters预测器"></a>Holt-Winters预测器</h5><p>同比环比预测到基线数据预测，使用的相关数据变多，预测的效果也较好。但是基线数据预测器只使用了周期相关的历史数据，没有使用上同周期相邻时刻的历史数据，相邻时刻的历史数据对于当前时刻的预测影响是比较大的。对于 <strong>Holt-winters </strong>预测期模型，它建议使用黄色点左上方的所有数据。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fmrp7xumw7j309u07k745.jpg" alt=""></p>
<p>Holt-Winters是三次指数滑动平均算法，它将时间序列数据分为三部分：残差数据 $a(t)$，趋势性数据 $b(t)$，周期性数据 $s(t)$。使用Holt-Winters预测 $t$ 时刻数据，需要 $t$ 时刻前包含多个周期的历史数据。</p>
<p>详细信息看这里：<a href="https://www.otexts.org/fpp/7/5" target="_blank" rel="noopener">https://www.otexts.org/fpp/7/5</a></p>
<p>在实际的异常检测模型中，我们对Holt-Winters预测器进行了简化。预测器的趋势数据表示的是时间序列的总体变化趋势，经过分析，如果以天/小时为周期看待传感器数据的订单量时间序列，是没有明显的趋势性的，如下的分解图也证明了这一点。因此，我们可以去掉其中的趋势数据部分。</p>
<p>各部分迭代的简化计算公式如（其中 $k$ 为周期）：</p>
<ol>
<li>$a[t] = \alpha(Y[t] - s[t-k]) + (1-\alpha) a[t-1]$</li>
<li>$s[t] = \gamma(Y[t] - a[t]) + (1 - \gamma)(s[t-k])$</li>
</ol>
<p>预测值：$Y[t+h] = a[t] + s[t-k+1 + (h-1)  mod  k]$</p>
<p>为了将算法应用到线上的实时预测，我们可以将 Holt-Winters 算法拆分为两个独立的计算过程：</p>
<ol>
<li><p>定时任务计算序列的周期数 $s(t)$。</p>
<p>$S(t)$ 不需要实时计算，只用按照周期性更新即可，使用 Holt-Winters 公式计算出时间序列的周期性数据。</p>
</li>
<li><p>对残差序列做实时预测。</p>
<p>计算出周期数据后，下一个目标就是对残差数据的预测。使用下面的公式，实际监控数据与周期数据相减得到残差数据，对残差数据做一次滑动平均，预测出下一刻的残差，将该时刻的残差、周期数据相加即可得到该时刻的预测数据。对于分钟数据，则将残差序列的长度设为60，即可以得到比较准确的预测效果。</p>
<blockquote>
<p>红线为预测数据，蓝线为真实数据</p>
</blockquote>
<p><img src="https://tech.meituan.com/img/holtwinter/p1.png" alt="@ 图3.8a) | center | 500x0"></p>
<p>​</p>
</li>
</ol>
<h3 id="比较器优化"><a href="#比较器优化" class="headerlink" title="比较器优化"></a>比较器优化</h3><p>预测器预测出当前时刻传感器的预测值后，还需要与真实值比较来判断当前时刻数据是否异常。一般的比较器都是通过阈值法，比如实际值超过预测值的一定比例就认为该点出现异常，进行报警。这种方式错误率比较大。在传感器数值模型的报警检测中没有使用这种方式，而是使用了两个串联的Filter，只有当两个Fliter都认为该点异常时，才进行报警，下面简单介绍一下两个Filter的实现。</p>
<p><img src="https://tech.meituan.com/img/holtwinter/compaire.png" alt="@图4.1 比较器模型 | center | 500x0"></p>
<h4 id="离散度Filter"><a href="#离散度Filter" class="headerlink" title="离散度Filter"></a>离散度Filter</h4><p>根据预测误差曲线离散程度过滤出可能的异常点。一个序列的方差表示该序列离散的程度，方差越大，表明该序列波动越大。如果一个预测误差序列方差比较大，那么我们认为预测误差的报警阈值相对大一些才比较合理。离散度 Filter 利用了这一特性，取连续 15 分钟的预测误差序列，分为首尾两个序列（e1,e2），如果两个序列的均值差大于 e1 序列方差的某个倍数，我们就认为该点可能是异常点。</p>
<h4 id="阈值Filter"><a href="#阈值Filter" class="headerlink" title="阈值Filter"></a>阈值Filter</h4><p>根据误差绝对值是否超过某个阈值过滤出可能的异常点。利用离散度 Filter 进行过滤时，报警阈值随着误差序列波动程度变大而变大，但是在输入数据比较小时，误差序列方差比较小，报警阈值也很小，容易出现误报。所以设计了根据误差绝对值进行过滤的阈值 Filter。阈值 Filter 设计了一个分段阈值函数 $y=f(x)$，对于实际值 $x$ 和预测值 $p$ ，只有当 $|x-p|&gt;f(x)$ 时报警。实际使用中，可以寻找一个对数函数替换分段阈值函数，更易于参数调优。</p>
<h3 id="模型最终架构"><a href="#模型最终架构" class="headerlink" title="模型最终架构"></a>模型最终架构</h3><p>每天定时抽取历史10天数据，经过预处理模块，去除异常数据，经过周期数据计算模块得到周期性数据。对当前时刻预测时，取60分钟的真实数据和周期性数据，经过实时预测模块，预测出当前传感器数值。将连续15分钟的预测值和真实值通过比较器，判断当前时刻是否异常。</p>
<p><img src="https://tech.meituan.com/img/holtwinter/jiegoutu.png" alt="@图4.2 分段阈值filter | center | 500x0"></p>
<blockquote>
<p>参考来源：</p>
<ol>
<li><a href="https://www.jianshu.com/p/6fb0408b3f54" target="_blank" rel="noopener">https://www.jianshu.com/p/6fb0408b3f54</a></li>
<li><a href="https://www.otexts.org/fpp/7/5" target="_blank" rel="noopener">https://www.otexts.org/fpp/7/5</a></li>
</ol>
</blockquote>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.luodian.ink/2017-12-23/Mecari-Analysis-LB-0-4229-rank-17-1090/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Luodian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Luodian.ink">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017-12-23/Mecari-Analysis-LB-0-4229-rank-17-1090/" itemprop="url">Mecari-Analysis(LB=0.4229~rank 17 / 1090)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-12-23T21:17:16+08:00">
                2017-12-23
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Mecari"><a href="#Mecari" class="headerlink" title="Mecari"></a>Mecari</h1><p>其实从情理上来说这个比赛有一点奇怪，因为全凭给出的 feature 似乎并不能很好的去 fit 结果的 price。</p>
<p>所以如果不能从特征工程的角度去挖掘数据的信息的话，只拿已给出的信息扔进 xgboost 或者是 lgbm，似乎就会和大部分人在同一个水平线。</p>
<h2 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h2><h3 id="NLP-Related"><a href="#NLP-Related" class="headerlink" title="NLP-Related"></a>NLP-Related</h3><h5 id="Document-term-matrix"><a href="#Document-term-matrix" class="headerlink" title="Document-term matrix"></a>Document-term matrix</h5><p>A <strong>document-term matrix</strong> or <strong>term-document matrix</strong> is a mathematical <a href="https://en.wikipedia.org/wiki/Matrix_(mathematics" target="_blank" rel="noopener">matrix</a>) that describes the frequency of terms that occur in a collection of documents. In a document-term matrix, rows correspond to documents in the collection and columns correspond to terms. There are various schemes for determining the value that each entry in the matrix should take.</p>
<ul>
<li>D1 = “I like databases”</li>
<li>D2 = “I hate databases”</li>
</ul>
<p>then the document-term matrix would be:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>I</th>
<th>like</th>
<th>hate</th>
<th>databases</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>D1</strong></td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td><strong>D2</strong></td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>
</div>
<p>也可以使用tf-idf schema对其进行计数。</p>
<h5 id="Bags-of-words-model"><a href="#Bags-of-words-model" class="headerlink" title="Bags of words model"></a>Bags of words model</h5><p>下列文件可用词袋表示:</p>
<p>以下是两个简单的文件:</p>
<pre><code>(1) John likes to watch movies. Mary likes movies too.
</code></pre><pre><code>(2) John also likes to watch football games.
</code></pre><p>基于以上两个文件，可以建构出下列清单:</p>
<pre><code class="lang-python">[
    &quot;John&quot;,
    &quot;likes&quot;,
    &quot;to&quot;,
    &quot;watch&quot;,
    &quot;movies&quot;,
    &quot;also&quot;,
    &quot;football&quot;,
    &quot;games&quot;,
    &quot;Mary&quot;,
    &quot;too&quot;
]
</code></pre>
<p>此处有10个不同的词，使用清单的索引表示长度为10的向量:</p>
<pre><code>[1, 2, 1, 1, 2, 0, 0, 0, 1, 1] (2) [1, 1, 1, 1, 0, 1, 1, 1, 0, 0]
</code></pre><p>每个向量的索引内容对应到清单中词出现的次数。</p>
<h3 id="标签二值化"><a href="#标签二值化" class="headerlink" title="标签二值化"></a>标签二值化</h3><p><a href="http://sklearn.lzjqsdd.com/modules/generated/sklearn.preprocessing.LabelBinarizer.html#sklearn.preprocessing.LabelBinarizer" target="_blank" rel="noopener"><code>LabelBinarizer</code></a> 是一个用来从多类别列表创建标签矩阵的工具类:</p>
<pre><code class="lang-python">&gt;&gt;&gt; from sklearn import preprocessing
&gt;&gt;&gt; lb = preprocessing.LabelBinarizer()
&gt;&gt;&gt; lb.fit([1, 2, 6, 4, 2])
LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)
&gt;&gt;&gt; lb.classes_
array([1, 2, 4, 6])
&gt;&gt;&gt; lb.transform([1, 6])
array([[1, 0, 0, 0],
       [0, 0, 0, 1]])
</code></pre>
<p>在 <code>mecari</code> 中我们对 <code>brand_name</code> 进行二值化处理，生成了一个<code>item * brand_count</code> 大小的矩阵。</p>
<h3 id="One-hot-编码和-get-dummies"><a href="#One-hot-编码和-get-dummies" class="headerlink" title="One-hot 编码和 get_dummies"></a>One-hot 编码和 get_dummies</h3><p>离散特征的编码分为两种情况：</p>
<ol>
<li>离散特征的取值之间没有大小的意义，比如color：[red,blue],那么就使用one-hot编码</li>
<li>离散特征的取值有大小的意义，比如size:[X,XL,XXL],那么就使用数值的映射{X：1,XL：2,XXL：3}</li>
</ol>
<p>使用pandas可以很方便的对离散型特征进行one-hot编码。</p>
<pre><code class="lang-python">import pandas as pd  
df = pd.DataFrame([  
            [&#39;green&#39;, &#39;M&#39;, 10.1, &#39;class1&#39;],   
            [&#39;red&#39;, &#39;L&#39;, 13.5, &#39;class2&#39;],   
            [&#39;blue&#39;, &#39;XL&#39;, 15.3, &#39;class1&#39;]])  

df.columns = [&#39;color&#39;, &#39;size&#39;, &#39;prize&#39;, &#39;class label&#39;]  

size_mapping = {  
           &#39;XL&#39;: 3,  
           &#39;L&#39;: 2,  
           &#39;M&#39;: 1}  
df[&#39;size&#39;] = df[&#39;size&#39;].map(size_mapping)  

class_mapping = {label:idx for idx,label in enumerate(set(df[&#39;class label&#39;]))}  
df[&#39;class label&#39;] = df[&#39;class label&#39;].map(class_mapping)
</code></pre>
<blockquote>
<p>对于有大小意义的离散特征，直接使用映射就可以了，{‘XL’:3,’L’:2,’M’:1}</p>
</blockquote>
<p><img src="http://img.blog.csdn.net/20161017092849112?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="img"></p>
<p>Using the <code>get_dummies</code> will create a new column for every unique string in a certain column.</p>
<pre><code class="lang-python">pd.get_dummies(df)
</code></pre>
<p><img src="http://img.blog.csdn.net/20161017092944347?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="img"></p>
<h2 id="Tf-idf"><a href="#Tf-idf" class="headerlink" title="Tf-idf"></a>Tf-idf</h2><p><strong>TF</strong>：Term Frequency.</p>
<p>单词在文章中出现的频率。</p>
<p><strong>Idf</strong>：Inverse Document Frequency.</p>
<p>逆文档频率：为了衡量单词在该文章中的重要程度（在Mecari中我们是衡量单词在这条评论中的重要程度）。</p>
<p><img src="http://image.beekka.com/blog/201303/bg2013031506.png" alt="img"></p>
<p>如果一个词越常见，那么分母就越大，逆文档频率就越小越接近0。分母之所以要加1，是为了避免分母为0（即所有文档都不包含该词）。log表示对得到的值取对数。</p>
<p><img src="http://image.beekka.com/blog/201303/bg2013031507.png" alt="img"></p>
<p><strong>TF-IDF与一个词在文档中的出现次数成正比，与该词在整个语言中的出现次数成反比。</strong>所以，自动提取关键词的算法就很清楚了，就是计算出文档的每个词的TF-IDF值，然后按降序排列，取排在最前面的几个词。</p>
<h2 id="Boosting-思想"><a href="#Boosting-思想" class="headerlink" title="Boosting 思想"></a>Boosting 思想</h2><blockquote>
<p>不断的强化模型</p>
</blockquote>
<p>The term <code>Boosting</code> refers to a family of algorithms which converts weak learner to strong learners.</p>
<h4 id="Ada-Boost"><a href="#Ada-Boost" class="headerlink" title="Ada Boost"></a>Ada Boost</h4><p>Why often use decision tree?</p>
<p>Decision trees are non-linear. Boosting with linear models simply doesn’t work well.</p>
<p>The weak learner needs to be consistently better than random guessing. You don’t normal need to do any parameter tuning to a decision tree to get that behavior. Training an SVM really does need a parameter search. Since the data is re-weighted on each iteration, you likely need to do another parameter search on each iteration. So you are increasing the amount of work you have to do by a large margin. </p>
<p>Decision trees are reasonably fast to train. Since we are going to be building 100s or 1000s of them, thats a good property. They are also fast to classify, which is again important when you need 100s or 1000s to run before you can output your decision. </p>
<p>By changing the depth you have a simple and easy control over the bias/variance trade off, knowing that boosting can reduce bias but also significantly reduces variance. Boosting is known to overfit, so the easy nob to tune is helpful in that regard.</p>
<h4 id="GBM"><a href="#GBM" class="headerlink" title="GBM"></a>GBM</h4><p>回归树总体流程类似于分类树，区别在于，回归树的每一个节点都会得一个预测值，以年龄为例，该预测值等于属于这个节点的所有人年龄的平均值。分枝时穷举每一个feature的每个阈值找最好的分割点，但衡量最好的标准不再是最大熵，而是最小化平方误差。也就是被预测出错的人数越多，错的越离谱，平方误差就越大，通过最小化平方误差能够找到最可靠的分枝依据。分枝直到每个叶子节点上人的年龄都唯一或者达到预设的终止条件(如叶子个数上限)，若最终叶子节点上人的年龄不唯一，则以该节点上所有人的平均年龄做为该叶子节点的预测年龄。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/967544-81b3ff4fbf2c6afb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/541" alt="img"></p>
<h2 id="Lgbm-Light-Gradient-Boosting-Model"><a href="#Lgbm-Light-Gradient-Boosting-Model" class="headerlink" title="Lgbm(Light Gradient Boosting Model)"></a>Lgbm(Light Gradient Boosting Model)</h2><p><strong>Light GBM grows tree vertically </strong>while other algorithm grows trees horizontally meaning that Light GBM grows tree <strong>leaf-wise </strong>while other algorithm grows level-wise. It will choose the leaf with max delta loss to grow. When growing the same leaf, Leaf-wise algorithm can reduce more loss than a level-wise algorithm.</p>
<p>Below diagrams explain the implementation of LightGBM and other boosting algorithms.</p>
<p><img src="https://cdn-images-1.medium.com/max/1600/1*AZsSoXb8lc5N6mnhqX5JCg.png" alt="img"></p>
<p><img src="https://cdn-images-1.medium.com/max/1600/1*whSa8rY4sgFQj1rEcWr8Ag.png" alt="img"></p>
<h5 id="Parameters-Tunning"><a href="#Parameters-Tunning" class="headerlink" title="Parameters Tunning"></a>Parameters Tunning</h5><p> it is not advisable to use LGBM on small datasets. Light GBM is <strong>sensitive to overfitting</strong> and can easily overfit small data. Their is no threshold on the number of rows but my experience suggests me to use it only for data with 10,000+ rows.</p>
<p><strong>Control Parameters</strong></p>
<p><strong>max_depth:</strong> It describes the maximum depth of tree. This parameter is used to handle model overfitting. Any time you feel that your model is overfitted, my first advice will be to lower max_depth.</p>
<p><strong>min_data_in_leaf:</strong> It is the minimum number of the records a leaf may have. The default value is 20, optimum value. It is also used to deal over fitting</p>
<p><strong>feature_fraction:</strong> Used when your boosting(discussed later) is random forest. 0.8 feature fraction means LightGBM will select 80% of parameters randomly in each iteration for building trees.</p>
<p><strong>bagging_fraction:</strong> specifies the fraction of data to be used for each iteration and is generally used to speed up the training and avoid overfitting.</p>
<p><strong>early_stopping_round:</strong> This parameter can help you speed up your analysis. Model will stop training if one metric of one validation data doesn’t improve in last early_stopping_round rounds. This will reduce excessive iterations.</p>
<p><strong>lambda: </strong>lambda specifies regularization. Typical value ranges from 0 to 1.</p>
<p><strong>min_gain_to_split:</strong> This parameter will describe the minimum gain to make a split. It can used to control number of useful splits in tree.</p>
<p><strong>max_cat_group: </strong>When the number of category is large, finding the split point on it is easily over-fitting. So LightGBM merges them into ‘max_cat_group’ groups, and finds the split points on the group boundaries, default:64</p>
<p><strong>Core Parameters</strong></p>
<p><strong>Task: </strong>It specifies the task you want to perform on data. It may be either train or predict.</p>
<p><strong>application: </strong>This is the most important parameter and specifies the application of your model, whether it is a regression problem or classification problem. LightGBM will by default consider model as a regression model.</p>
<ul>
<li>regression: for regression</li>
<li>binary: for binary classification</li>
<li>multiclass: for multiclass classification problem</li>
</ul>
<p><strong>boosting:</strong> defines the type of algorithm you want to run, default=gdbt</p>
<ul>
<li>gbdt: traditional Gradient Boosting Decision Tree</li>
<li>rf: random forest</li>
<li>dart: Dropouts meet Multiple Additive Regression Trees</li>
<li>goss: Gradient-based One-Side Sampling</li>
</ul>
<p><strong>num_boost_round:</strong> Number of boosting iterations, typically 100+</p>
<p><strong>learning_rate: </strong>This determines the impact of each tree on the final outcome. GBM works by starting with an initial estimate which is updated using the output of each tree. The learning parameter controls the magnitude of this change in the estimates. Typical values: 0.1, 0.001, 0.003…</p>
<p><strong>num_leaves:</strong> number of leaves in full tree, default: 31</p>
<p><strong>device: </strong>default: cpu, can also pass gpu</p>
<p><strong>Metric parameter</strong></p>
<p><strong>metric：</strong> again one of the important parameter as it specifies loss for model building. Below are few general losses for regression and classification.</p>
<ul>
<li>mae: mean absolute error</li>
<li>mse: mean squared error</li>
<li>binary_logloss: loss for binary classification</li>
<li>multi_logloss: loss for multi classification</li>
</ul>
<p><strong>IO parameter</strong></p>
<p><strong>max_bin： </strong>it denotes the maximum number of bin that feature value will bucket in.</p>
<p><strong>categorical_feature:</strong> It denotes the index of categorical features. If categorical_features=0，1，2 then column 0， column 1 and column 2 are categorical variables.</p>
<p><strong>ignore_column：</strong> same as categorical_features just instead of considering specific columns as categorical, it will completely ignore them.</p>
<p><strong>save_binary：</strong> If you are really dealing with the memory size of your data file then specify this parameter as ‘True’. Specifying parameter true will save the dataset to binary file, this binary file will speed your data reading time for the next time.</p>
<p>Knowing and using above parameters will definitely help you implement the model. Remember I said that implementation of LightGBM is easy but parameter tuning is difficult. So let’s first start with implementation and then I will give idea about the parameter tuning.</p>
<h2 id="Ridge"><a href="#Ridge" class="headerlink" title="Ridge"></a>Ridge</h2><h4 id="线性最小二乘拟合解析解"><a href="#线性最小二乘拟合解析解" class="headerlink" title="线性最小二乘拟合解析解"></a>线性最小二乘拟合解析解</h4><p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1fmoltdbrsgj311q0qajsr.jpg" alt=""></p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1fmom4y06e8j31aa11cte1.jpg" alt=""></p>
<p>当XTX的行列式接近于0时，我们将其主对角元素都加上一个数k，可以使矩阵为奇异的风险大降低。于是：</p>
<p>B(k)=(XTX+kI)−1XTYB(k)=(XTX+kI)−1XTY (I是单位矩阵)</p>
<p>随着k的增大，B(k)中各元素bi(k)的绝对值均趋于不断变小，它们相对于正确值bi的偏差也越来越大。k趋于无穷大时，B(k)趋于0。b(k)随k的改变而变化的轨迹，就称为岭迹。实际计算中可选非常多的k值，做出一个岭迹图，看看这个图在取哪个值的时候变稳定了，那就确定k值了。</p>
<p>X不满足列满秩，换句话就是说样本向量之间具有高度的相关性（如果每一列是一个向量的话）。遇到列向量相关的情形，岭回归是一种处理方法，也可以用主成分分析PCA来进行降维。</p>
<p>岭回归的原理较为复杂。根据高斯马尔科夫定力，多重相关性并不影响最小二乘法估计量的无偏性和最小方差性，但是，虽然最小二乘估计量在所有线性估计量中是方差最小的，但是这个方差都不一定小，而实际上可以找到一个有偏估计量，这个估计量虽然有较小的偏差，但它的精度却能够大大高于无偏的估计量。岭回归分析就是根据这个原理，通过在正规方程中引入有偏常熟二求的回归估计量的。</p>
<h2 id="辅助函数"><a href="#辅助函数" class="headerlink" title="辅助函数"></a>辅助函数</h2><p><strong>preprocessing.MinMaxScaler</strong>：</p>
<p>The <code>MinMaxScaler</code> is the probably the most famous scaling algorithm, and follows the following formula for each feature:</p>
<p>xi–min(x)max(x)–min(x)</p>
<p>It essentially shrinks the range such that the range is now between 0 and 1 (or -1 to 1 if there are negative values).</p>
<p>This scaler works better for cases in which the standard scaler might not work so well. If the distribution is not Gaussian or the standard deviation is very small, the min-max scaler works better.</p>
<p>使用这种方法的目的包括：</p>
<ol>
<li>对于方差非常小的属性可以增强其稳定性。</li>
<li>维持稀疏矩阵中为0的条目。</li>
</ol>
<h2 id="Cross-Validation"><a href="#Cross-Validation" class="headerlink" title="Cross Validation"></a>Cross Validation</h2><p>在解决实际问题中，我们可以将所有的数据集 dataset ，划分为 train_set（例如70%）和test_set（30%），然后在 train_set 上做 cross_validation ，最后取平均之后，再使用test_set测试模型的准确度。</p>
<h4 id="K-Fold"><a href="#K-Fold" class="headerlink" title="K-Fold"></a>K-Fold</h4><ol>
<li>A model is trained using k-1 of the folds as training data; </li>
<li>the resulting model is validated on the remaining part of the data (i.e., it is used as a test set to compute a performance measure such as accuracy). </li>
</ol>
<p>The performance measure reported by k-fold cross-validation is then the average of the values computed in the loop.</p>
<h4 id="Grid-Search"><a href="#Grid-Search" class="headerlink" title="Grid Search"></a>Grid Search</h4><pre><code class="lang-python">import pandas as pd
from sklearn import svm, datasets
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report

iris = datasets.load_iris()
parameters = {&#39;kernel&#39;:(&#39;linear&#39;, &#39;rbf&#39;), &#39;C&#39;:[1, 2, 4], &#39;gamma&#39;:[0.125, 0.25, 0.5 ,1, 2, 4]}
svr = svm.SVC()
clf = GridSearchCV(svr, parameters, n_jobs=-1)
clf.fit(iris.data, iris.target)
cv_result = pd.DataFrame.from_dict(clf.cv_results_)
with open(&#39;cv_result.csv&#39;,&#39;w&#39;) as f:
    cv_result.to_csv(f)

print(&#39;The parameters of the best model are: &#39;)
print(clf.best_params_)

y_pred = clf.predict(iris.data)
print(classification_report(y_true=iris.target, y_pred=y_pred))
</code></pre>
<h2 id="Konstantin的建议"><a href="#Konstantin的建议" class="headerlink" title="Konstantin的建议"></a>Konstantin的建议</h2><p>Sure, let me give some examples:</p>
<ul>
<li>after looking at explained predictions, I see that “t-“ in word “t-shirt” is not highlighted, then I can check how scikit-learn vectorizer processes such words and see that it discards “t-“, so the model sees “shirt” - which may or may not be the problem, but it’s worth checking</li>
<li>after looking at the model features, I see that words like “16gb” and “32gb” are really important - I would check, maybe people also write “16 gb” too, and it’s better to normalize such cases to give the model a better job</li>
<li>I see “item_description__regimen” as a positive feature, this looks strange - is it a german word and so any german descriptions make the product more expensive? Or something else?</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.luodian.ink/2017-12-17/Ng-Cousera-Week-6-Bias-VS-Variance/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Luodian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Luodian.ink">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017-12-17/Ng-Cousera-Week-6-Bias-VS-Variance/" itemprop="url">Ng'Cousera-Week 6-Bias vs Variance</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-12-17T18:26:55+08:00">
                2017-12-17
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Diagnosing-Bias-vs-Variance"><a href="#Diagnosing-Bias-vs-Variance" class="headerlink" title="Diagnosing Bias vs. Variance"></a>Diagnosing Bias vs. Variance</h1><p>In this section we examine the relationship between the degree of the polynomial d and the underfitting or overfitting of our hypothesis.</p>
<ul>
<li>We need to distinguish whether <strong>bias</strong> or <strong>variance</strong> is the problem contributing to bad predictions.</li>
<li>High bias is underfitting and high variance is overfitting. Ideally, we need to find a golden mean between these two.</li>
</ul>
<p>The training error will tend to <strong>decrease</strong> as we increase the degree d of the polynomial.</p>
<p>At the same time, the cross validation error will tend to <strong>decrease</strong> as we increase d up to a point, and then it will <strong>increase</strong> as d is increased, forming a convex curve.</p>
<p><strong>High bias (underfitting)</strong>: both Jtrain(Θ) and JCV(Θ) will be high. Also, JCV(Θ)≈Jtrain(Θ).</p>
<p><strong>High variance (overfitting)</strong>: Jtrain(Θ) will be low and JCV(Θ) will be much greater than Jtrain(Θ).</p>
<p>The is summarized in the figure below:</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1fmk9nubr83j308c073t8s.jpg" alt=""></p>
<h3 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h3><p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1fmk9pevgxgj30jj0ak74u.jpg" alt=""></p>
<p>In the figure above, we see that as $\lambda$ increases, our fit becomes more rigid. On the other hand, as $\lambda$ approaches 0, we tend to over overfit the data. So how do we choose our parameter $\lambda$ to get it ‘just right’ ? In order to choose the model and the regularization term $\lambda$, we need to:</p>
<ol>
<li>Create a list of lambdas (i.e. $\lambda \in {0,0.01,0.02,0.04,0.08,0.16,0.32,0.64,1.28,2.56,5.12,10.24})$;</li>
<li>Create a set of models with different degrees or any other variants.</li>
<li>Iterate through the λs and for each λ go through all the models to learn some  $\theta$  .</li>
<li>Compute the cross validation error using the learned  $\theta$   (computed with λ) on the $J_{CV}(\theta) $  <strong>without</strong> regularization or λ = 0.</li>
<li>Select the best combo that produces the lowest error on the cross validation set.</li>
<li>Using the best combo $\theta$  and λ, apply it on $J_{CV}(\theta) $ to see if it has a good generalization of the problem.</li>
</ol>
<h3 id="Decision"><a href="#Decision" class="headerlink" title="Decision"></a>Decision</h3><p>Our decision process can be broken down as follows:</p>
<ul>
<li><strong>Getting more training examples:</strong> Fixes high variance</li>
</ul>
<ul>
<li><strong>Trying smaller sets of features:</strong> Fixes high variance</li>
</ul>
<ul>
<li><strong>Adding features:</strong> Fixes high bias</li>
</ul>
<ul>
<li><strong>Adding polynomial features:</strong> Fixes high bias</li>
</ul>
<ul>
<li><strong>Decreasing λ:</strong> Fixes high bias</li>
</ul>
<ul>
<li><strong>Increasing λ:</strong> Fixes high variance.</li>
</ul>
<h1 id="Diagnosing-Neural-Networks"><a href="#Diagnosing-Neural-Networks" class="headerlink" title="Diagnosing Neural Networks"></a>Diagnosing Neural Networks</h1><ul>
<li>A neural network with fewer parameters is <strong>prone to underfitting</strong>. It is also <strong>computationally cheaper</strong>.</li>
<li>A large neural network with more parameters is <strong>prone to overfitting</strong>. It is also <strong>computationally expensive</strong>. In this case you can use regularization (increase λ) to address the overfitting.</li>
</ul>
<p>Using a single hidden layer is a good starting default. You can train your neural network on a number of hidden layers using your cross validation set. You can then select the one that performs best. </p>
<blockquote>
<p>网络越大越好，不要因噎废食怕过拟合就用小网络。上大网络加正则化肯定比小网络好，因为大网络加正则化后的损失函数更容易优化到一个更小的局部极值点，对随机初始化的依赖更小。</p>
</blockquote>
<p><strong>Model Complexity Effects:</strong></p>
<ul>
<li>Lower-order polynomials (low model complexity) have high bias and low variance. In this case, the model fits poorly consistently.</li>
<li>Higher-order polynomials (high model complexity) fit the training data extremely well and the test data extremely poorly. These have low bias on the training data, but very high variance.</li>
<li>In reality, we would want to choose a model somewhere in between, that can generalize well but also fits the data reasonably well.</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.luodian.ink/2017-12-07/机器学习-拉格朗日函数与KKT条件/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Luodian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Luodian.ink">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017-12-07/机器学习-拉格朗日函数与KKT条件/" itemprop="url">机器学习-拉格朗日函数与KKT条件</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-12-07T09:35:03+08:00">
                2017-12-07
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.luodian.ink/2017-12-05/天算计划-为什么使用Docker/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Luodian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Luodian.ink">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017-12-05/天算计划-为什么使用Docker/" itemprop="url">天算计划-为什么使用Docker</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-12-05T13:31:17+08:00">
                2017-12-05
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/分布式计算/" itemprop="url" rel="index">
                    <span itemprop="name">分布式计算</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口。</p>
<h3 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h3><p>Docker运行Linux上可以原生无压力，Windows上需要装插件虚化一个Linux环境，感觉很麻烦。</p>
<ol>
<li><p>在 Docker 下安装镜像</p>
<pre><code class="lang-shell">docker pull uhopper/hadoop-spark
</code></pre>
</li>
<li><p>在 Docker 中移除镜像</p>
<pre><code class="lang-shell">docker rm [container_id]
docker rmi [image_id]
</code></pre>
<p>​</p>
</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.luodian.ink/2017-12-05/天算计划-虚拟化与云计算/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Luodian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Luodian.ink">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017-12-05/天算计划-虚拟化与云计算/" itemprop="url">天算计划-虚拟化与云计算</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-12-05T09:21:55+08:00">
                2017-12-05
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/分布式计算/" itemprop="url" rel="index">
                    <span itemprop="name">分布式计算</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>摘录于知乎<a href="https://www.zhihu.com/question/22793847" target="_blank" rel="noopener">https://www.zhihu.com/question/22793847</a></p>
<p>组合了一些优秀答案</p>
<p>咱们需要实现的也是虚拟化（Docker）+分布式计算（Hadoop）</p>
</blockquote>
<h3 id="虚拟化"><a href="#虚拟化" class="headerlink" title="虚拟化"></a>虚拟化</h3><p>对于主机上的虚拟化技术，其中一个可行的定义就是可以让IT系统的物理拓扑图与逻辑拓扑图无关，即解耦，我们暂时以商用虚拟化系统vmware举例为了实现拓扑解耦，它做的第一点就是让一台机器可以同时跑多个操作系统，即虚拟机，而且虚拟机还可以在物理机间来回转移，高可用，这样我们的操作系统就从物理机上彻底解放出来了，你可以把同一个虚拟机随时放到其他物理机上，实现了对硬件的高效资源利用，和系统的高度灵活，解除了大量人工劳动，便于实现大规模系统的方便管理，这种就是服务器虚拟化</p>
<p>通过虚拟化技术将一台计算机虚拟为多台逻辑计算机。在一台计算机上同时运行多个逻辑计算机，每个逻辑计算机可运行不同的操作系统，并且应用程序都可以在相互独立的空间内运行而互不影响，从而显著提高计算机的工作效率。</p>
<p>虚拟化使用软件的方法重新定义划分IT资源，可以实现IT资源的动态分配、灵活调度、跨域共享，提高IT资源利用率，使IT资源能够真正成为社会基础设施，服务于各行各业中灵活多变的应用需求。</p>
<p>虚拟化是一个广义的术语，是指计算元件在虚拟的基础上而不是真实的基础上运行，是一个为了简化管理，优化资源的解决方案。如同空旷、通透的写字楼，整个楼层没有固定的墙壁，用户可以用同样的成本构建出更加自主适用的办公空间，进而节省成本，发挥空间最大利用率。这种把有限的固定的资源根据不同需求进行重新规划以达到最大利用率的思路，在IT领域就叫做虚拟化技术。</p>
<p>虚拟化技术可以扩大硬件的容量，简化软件的重新配置过程。CPU的虚拟化技术可以单CPU模拟多CPU并行，允许一个平台同时运行多个操作系统，并且应用程序都可以在相互独立的空间内运行而互不影响，从而显著提高计算机的工作效率。</p>
<p>虚拟化技术与多任务以及超线程技术是完全不同的。多任务是指在一个操作系统中多个程序同时并行运行，而在虚拟化技术中，则可以同时运行多个操作系统，而且每一个操作系统中都有多个程序运行，每一个操作系统都运行在一个虚拟的CPU或者是虚拟主机上；而超线程技术只是单CPU模拟双CPU来平衡程序运行性能，这两个模拟出来的CPU是不能分离的，只能协同工作。</p>
<h3 id="云计算"><a href="#云计算" class="headerlink" title="云计算"></a>云计算</h3><p>云计算 （Cloud Computing）是基于互联网的相关服务的增加、使用和交付模式，通常涉及通过互联网来提供动态易扩展且经常是虚拟化的资源。云是网络、互联网的一种比喻说法。过去在图中往往用云来表示电信网，后来也用来表示互联网和底层基础设施的抽象。因此，云计算甚至可以让你体验每秒10万亿次的运算能力，拥有这么强大的计算能力可以模拟核爆炸、预测气候变化和市场发展趋势。用户通过电脑、笔记本、手机等方式接入数据中心，按自己的需求进行运算。</p>
<p><strong>超大规模</strong></p>
<p>“云”具有相当的规模，Google云计算已经拥有100多万台服务器， Amazon、IBM、微软、Yahoo等的“云”均拥有几十万台服务器。企业私有云一般拥有数百上千台服务器。“云”能赋予用户前所未有的计算能力。</p>
<p><strong>虚拟化</strong></p>
<p>云计算支持用户在任意位置、使用各种终端获取应用服务。所请求的资源来自“云”，而不是固定的有形的实体。应用在“云”中某处运行，但实际上用户无需了解、也不用担心应用运行的具体位置。只需要一台笔记本或者一个手机，就可以通过网络服务来实现我们需要的一切，甚至包括超级计算这样的任务。</p>
<p><strong>高可靠性</strong></p>
<p>“云”使用了数据多副本容错、计算节点同构可互换等措施来保障服务的高可靠性，使用云计算比使用本地计算机可靠。</p>
<p><strong>通用性</strong></p>
<p>云计算不针对特定的应用，在“云”的支撑下可以构造出千变万化的应用，同一个“云”可以同时支撑不同的应用运行。</p>
<p><strong>高可扩展性</strong></p>
<p>“云”的规模可以动态伸缩，满足应用和用户规模增长的需要。</p>
<p><strong>按需服务</strong></p>
<p>“云”是一个庞大的资源池，你按需购买，云可以像自来水，电，煤气那样计费。其还强调一个动态分配的特点，比如双11前后几天，电商部门需要比平时10倍的访问量，那就可以在那几天增加10倍的资源，过完又释放相关资源，而不是以前按最高性能要求来购买硬件，减少浪费，借助虚拟化（但不是必须）可以更加方便实现此目的； 其它特性，如服务自助，服务计量化，包括不同包装特性（IaaS,PaaS,Saas）只是在此基础上的增强派生而已。</p>
<p><strong>极其廉价</strong></p>
<p>由于“云”的特殊容错措施可以采用极其廉价的节点来构成云，“云”的自动化集中式管理使大量企业无需负担日益高昂的数据中心管理成本，“云”的通用性使资源的利用率较之传统系统大幅提升，因此用户可以充分享受“云”的低成本优势，经常只要花费几百美元、几天时间就能完成以前需要数万美元、数月时间才能完成的任务。</p>
<p>云计算可以彻底改变人们未来的生活，但同时也要重视环境问题，这样才能真正为人类进步做贡献,而不是简单的技术提升。</p>
<p><strong>潜在的危险性</strong></p>
<p>云计算服务除了提供计算服务外，还必然提供了存储服务。但是云计算服务当前垄断在私人机构（企业）手中，而他们仅仅能够提供商业信用。对于政府机构、商业机构（特别像银行这样持有敏感数据的商业机构）对于选择云计算服务应保持足够的警惕。一旦商业用户大规模使用私人机构提供的云计算服务，无论其技术优势有多强，都不可避免地让这些私人机构以“数据（信息）”的重要性挟制整个社会。对于信息社会而言，“信息”是至关重要的。另一方面，云计算中的数据对于数据所有者以外的其他用户云计算用户是保密的，但是对于提供云计算的商业机构而言确实毫无秘密可言。所有这些潜在的危险，是商业机构和政府机构选择云计算服务、特别是国外机构提供的云计算服务时，不得不考虑的一个重要的前提。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.luodian.ink/2017-12-04/Linux：一些常用命令 /">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Luodian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Luodian.ink">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017-12-04/Linux：一些常用命令 /" itemprop="url">Linux：一些常用的Linux命令</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-12-04T22:22:50+08:00">
                2017-12-04
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Linux/" itemprop="url" rel="index">
                    <span itemprop="name">Linux</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="CP"><a href="#CP" class="headerlink" title="CP"></a>CP</h3><p>操作格式：<code>cp [选项]... 源… 目录</code></p>
<p>命令作用：将源文件复制至目标文件，或将多个源文件复制至目标目录。</p>
<p>命令参数：</p>
<pre><code class="lang-shell">-a, --archive    等于-dR --preserve=all
    --backup[=CONTROL    为每个已存在的目标文件创建备份
-b                类似--backup 但不接受参数
   --copy-contents        在递归处理是复制特殊文件内容
-d                等于--no-dereference --preserve=links
-f, --force        如果目标文件无法打开则将其移除并重试(当 -n 选项
                    存在时则不需再选此项)
-i, --interactive        覆盖前询问(使前面的 -n 选项失效)
-H                跟随源文件中的命令行符号链接
-l, --link            链接文件而不复制
-L, --dereference   总是跟随符号链接
-n, --no-clobber   不要覆盖已存在的文件(使前面的 -i 选项失效)
-P, --no-dereference   不跟随源文件中的符号链接
-p                等于--preserve=模式,所有权,时间戳
    --preserve[=属性列表   保持指定的属性(默认：模式,所有权,时间戳)，如果
               可能保持附加属性：环境、链接、xattr 等
-R, -r, --recursive  复制目录及目录内的所有项目
</code></pre>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Luodian</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">22</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">9</span>
                  <span class="site-state-item-name">categories</span>
                
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">tags</span>
                
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Luodian</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
