<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>Luodian.ink</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Luodian.ink">
<meta property="og:url" content="https://www.luodian.ink/index.html">
<meta property="og:site_name" content="Luodian.ink">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Luodian.ink">
  
    <link rel="alternate" href="/atom.xml" title="Luodian.ink" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  

</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Luodian.ink</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://www.luodian.ink"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-2018-MetaTrade-网格交易简述" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018-03-01/2018-MetaTrade-网格交易简述/" class="article-date">
  <time datetime="2018-03-01T03:21:10.000Z" itemprop="datePublished">2018-03-01</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/量化交易/">量化交易</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018-03-01/2018-MetaTrade-网格交易简述/">MetaTrader-网格交易简述</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
      
    </div>
    <footer class="article-footer">
      <a data-url="https://www.luodian.ink/2018-03-01/2018-MetaTrade-网格交易简述/" data-id="cjeaoysu20007ni1yj5h6mdz1" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Contest-911-D-Inversion-Counting" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018-01-24/Contest-911-D-Inversion-Counting/" class="article-date">
  <time datetime="2018-01-24T14:48:49.000Z" itemprop="datePublished">2018-01-24</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Codeforces/">Codeforces</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018-01-24/Contest-911-D-Inversion-Counting/">Contest-911-D-Inversion Counting</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="D-Inversion-Counting"><a href="#D-Inversion-Counting" class="headerlink" title="D - Inversion Counting"></a>D - Inversion Counting</h1><p><a href="http://codeforces.com/contest/911/problem/D" target="_blank" rel="noopener">http://codeforces.com/contest/911/problem/D</a></p>
<p>题目大意为：逆序对问题，事先求出有多少个逆序对，只用知道是奇数个还是偶数个即可，然后现在我们对l,r区间的序列进行 reverse 之后再问序列的逆序对是奇数个还是偶数个。</p>
<p>因为 $l,r$ 区间反转之后，如果原来的全是顺序对，那么现在会造成总共 $\frac{(len(l,r) <em> len(l,r) - 1)}{2}$ 个逆序对，所以总的逆序对个数为 原有逆序对（区间外逆序对个数）+ 新逆序对，<em>*如果新逆序对个数为奇数，则总逆序对的奇偶性发生改变。</em></em></p>
<p>如果原来的区间里含有m个逆序对，区间外逆序对个数为 $p$ 个，那么反转之后，逆序对会变成顺序对，原有顺序对会变成逆序对，同样总共会有新的 $\frac{(len(l,r) <em> len(l,r) - 1)}{2} - m$ 个逆序对产生，总的逆序对数变为 $\frac{(len(l,r) </em> len(l,r) - 1)}{2} - m + p$ 个，原逆序对数为 $m + p$ 个，怎么在只知道 $m + p$ ，不知道 $m$ 的情况下，推出的奇偶 $\frac{(len(l,r) * len(l,r) - 1)}{2} - m + p$ 性呢？</p>
<p>可以利用  $\frac{(len(l,r) <em> len(l,r) - 1)}{2} - m + p =  \frac{(len(l,r) </em> len(l,r) - 1)}{2} + m + p - 2m$ ，然后就可以利用 $m + p$ 的奇偶性，以及 $\frac{(len(l,r) <em> len(l,r) - 1)}{2}$ 的奇偶性，推出 $\frac{(len(l,r) </em> len(l,r) - 1)}{2} - m + p$ 的奇偶性了。</p>
<p>代码很简单：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iomanip&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cstdlib&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;queue&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stack&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cmath&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;bitset&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unordered_set&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;numeric&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;set&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;list&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;map&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> lower_bound LB</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> upper_bound UB</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> mem(a,x) memset(a,x,sizeof(a))</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> rep(i,a,n) for (int i=a;i&lt;n;i++)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> per(i,a,n) for (int i=n-1;i&gt;=a;i--)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> mp make_pair</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> all(x) (x).begin(),(x).end()</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> SZ(x) ((int)(x).size())</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> IT iterator</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> test puts(<span class="meta-string">"OK"</span>)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> lowbit(x) x &amp; -x</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> PRQ priority_queue</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> PB push_back</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> gcd(a,b) _gcd(a,b)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">long</span> <span class="keyword">long</span> LL;</span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">unsigned</span> <span class="keyword">long</span> <span class="keyword">long</span> uLL;</span><br><span class="line"><span class="keyword">typedef</span> pair&lt;<span class="keyword">int</span>,<span class="keyword">int</span>&gt; pii;</span><br><span class="line"><span class="keyword">typedef</span> <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; VI;</span><br><span class="line"><span class="keyword">typedef</span> pair&lt;<span class="keyword">int</span>,<span class="keyword">int</span>&gt; PII;</span><br><span class="line"><span class="keyword">typedef</span> <span class="built_in">vector</span>&lt;PII&gt; VPII;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> LL mod=<span class="number">1000000007</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">double</span> PI = <span class="built_in">acos</span>(<span class="number">-1.0</span>);</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">double</span> eps = <span class="number">1e-8</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> INF = <span class="number">0x3f3f3f3f</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="meta">#<span class="meta-keyword">ifndef</span> ONLINE_JUDGE</span></span><br><span class="line">        freopen(<span class="string">"D.txt"</span>,<span class="string">"r"</span>,<span class="built_in">stdin</span>);</span><br><span class="line">    <span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    ios::sync_with_stdio(<span class="literal">false</span>);</span><br><span class="line">    <span class="built_in">cin</span>.tie(<span class="literal">nullptr</span>);</span><br><span class="line">    <span class="built_in">cout</span>.tie(<span class="literal">nullptr</span>);</span><br><span class="line">	<span class="keyword">int</span> n,m;</span><br><span class="line">	<span class="keyword">int</span> l,r;</span><br><span class="line">	<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; ar;</span><br><span class="line">	ar.clear();</span><br><span class="line">	<span class="keyword">while</span>(<span class="built_in">cin</span>&gt;&gt;n)</span><br><span class="line">	&#123;</span><br><span class="line">		ar.clear();</span><br><span class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; ++i)</span><br><span class="line">		&#123;</span><br><span class="line">			<span class="keyword">int</span> temp;</span><br><span class="line">			<span class="built_in">cin</span>&gt;&gt;temp;</span><br><span class="line">			ar.PB(temp);</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">bool</span> ret = <span class="number">0</span>;</span><br><span class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; ++i)</span><br><span class="line">		&#123;</span><br><span class="line">			<span class="keyword">for</span> (<span class="keyword">int</span> j = i; j &lt; n; ++j)</span><br><span class="line">			&#123;</span><br><span class="line">				<span class="keyword">if</span> (ar[j] &lt; ar[i])</span><br><span class="line">				&#123;</span><br><span class="line">					ret ^= <span class="number">1</span>;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line"><span class="comment">//		cout&lt;&lt;ret&lt;&lt;endl;</span></span><br><span class="line">		<span class="built_in">cin</span>&gt;&gt;m;</span><br><span class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; m; ++i)</span><br><span class="line">		&#123;</span><br><span class="line">			<span class="built_in">cin</span>&gt;&gt;l&gt;&gt;r;</span><br><span class="line">			<span class="keyword">int</span> permutations = (r - l) * (r - l + <span class="number">1</span>) / <span class="number">2</span>;</span><br><span class="line">			<span class="keyword">if</span> (permutations &amp; <span class="number">1</span>)</span><br><span class="line">			&#123;</span><br><span class="line">				ret ^= <span class="number">1</span>;</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">if</span> (ret &amp; <span class="number">1</span>)</span><br><span class="line">			&#123;</span><br><span class="line">				<span class="built_in">cout</span>&lt;&lt;<span class="string">"odd\n"</span>;</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">else</span></span><br><span class="line">			&#123;</span><br><span class="line">				<span class="built_in">cout</span>&lt;&lt;<span class="string">"even\n"</span>;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://www.luodian.ink/2018-01-24/Contest-911-D-Inversion-Counting/" data-id="cjeaoysu40008ni1y1m28qanv" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-基于统计方法进行时序数据预测的异常检测模型" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017-12-29/基于统计方法进行时序数据预测的异常检测模型/" class="article-date">
  <time datetime="2017-12-29T05:57:30.000Z" itemprop="datePublished">2017-12-29</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/时间序列/">时间序列</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017-12-29/基于统计方法进行时序数据预测的异常检测模型/">基于统计方法进行时序数据预测的异常检测模型</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="时间序列数据异常检测报告"><a href="#时间序列数据异常检测报告" class="headerlink" title="时间序列数据异常检测报告"></a>时间序列数据异常检测报告</h1><blockquote>
<p>15级-李博</p>
<p>2017-12-29</p>
</blockquote>
<h2 id="基于统计方法进行时序数据预测的异常检测模型"><a href="#基于统计方法进行时序数据预测的异常检测模型" class="headerlink" title="基于统计方法进行时序数据预测的异常检测模型"></a>基于统计方法进行时序数据预测的异常检测模型</h2><h3 id="简述"><a href="#简述" class="headerlink" title="简述"></a>简述</h3><p>基于统计的预测，无非是根据收集过去时间的数据，建立一个模型，来计算未来时间的数据，建立的是一种数学或者统计模型，它能表现出已有数据的变化规律，因为大数定理的存在，定义了世间所有的行为都可以通过数字表示，并且存在一定的客观规律。</p>
<p>对于股票市场中存在的量化交易这一概念，即是指以先进的数学模型替代人为的主观判断，利用计算机技术从庞大的历史数据中海选能带来超额收益的多种『大概率』事件以制定策略，极大地减少了投资者情绪波动的影响，避免在市场极度狂热或悲观的情况下作出非理性的投资决策。</p>
<p>在这里我们从这个方向入手，通过传统股票市场的预测分析工具来进行我们的工业传感器数据分析，首先我简要分析其关联性：</p>
<ol>
<li>股票数据和传感器数据都具有趋势性，以及一定程度的随机性，趋势性保证了两者的数值会按照一定的规律变化，并且从长时间数据的角度看，其是较为连续的，因此我们可以使用ARIMA，EA等模型进行平滑处理，分析异常点。</li>
<li>股票数据根据金融因素，考虑通货膨胀等原因，可能会存在不断起伏，但是大趋势增长的情况。但是对于传感器数据，大多会在一定范围内震荡（如温度，湿度等数据因为物理因素的原因，不会高出一定范围），所以我们可以在EA（适用于渐进上升型数据）或者是ARIMA模型（适用于周期波动性数据）中进行决策。</li>
<li>传感器数据可能存在一定的周期，但是股票数据不一定存在明显周期性，这一点也是需要对模型进行修正调整的考虑因素之一。</li>
</ol>
<h2 id="模型方法介绍"><a href="#模型方法介绍" class="headerlink" title="模型方法介绍"></a>模型方法介绍</h2><p>在上一次周报中，我详细介绍了这种方法，现在在这里简单略过。</p>
<p>基于预测的异常检测模型如下图所示，$O_{data}$ 是真实数据，通过预测器得到预测数据，然后 $O_{data}$ 和 $P_{data}$分别作为比较器的输入，比较器输出的是真实数据中被判别为异常值的下标 $Index$。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fmxgr3umhej30vy0iwq2z.jpg" alt=""></p>
<h3 id="预测器"><a href="#预测器" class="headerlink" title="预测器"></a>预测器</h3><p>时间序列分析一般假设我们获得的数据在时域上具有一定的相互依赖关系，通常，如果传感器数值在 $t$ 时刻很高，那么在 $t+1$ 时刻价格也有一定的概率会比较高，而时间序列分析的目的包含以下两个方面：</p>
<ul>
<li>发现这种隐含的依赖关系，并增加我们对此类时间序列的理解；</li>
<li>对未观测到的或者尚未发生的时间序列进行预测。</li>
</ul>
<p>在接下来的分析中，我们认为时间序列 $X$ 由两部分组成，即 $X_t=\hat{X}_t+\epsilon_t$. 其中$\hat{X}_t$ 是有规律的序列而$ \epsilon_t$ 则无规律的噪声。有规律的 $X_t$ 包含我们想要发现的依赖关系（pattern），而 $\epsilon_t$ 我们认为在时间域内不存在相互依赖的关系，即 $\epsilon_t$ 和 $\epsilon_{t+1}$ 之间是相互独立的。</p>
<p>一个最简单的模型就是我们假设 $\epsilon_t$ 是一个随机数，服从一定的概率分布 $f_t(\epsilon)$。</p>
<p>可以发现，我们想要找到 $\hat{X}_t$ 而对 $ϵ_t$不怎么感兴趣。为了使有规律的 $\hat{X}_t$ 更加明显，我们通常希望能过滤到噪声，而最简单的过滤噪声的方法就是『取平均』。</p>
<p>而问题来了，对于时间序列信号来说，我们该如何取平均呢？这里便引出了我们的基于历史数据平滑曲线的几种方法，也即我们的预测期。</p>
<p>我们使用的预测器主要有以下几种（还在等待其余方法的补充）。</p>
<h4 id="对于时序数据的-F-t-m-的预测方法"><a href="#对于时序数据的-F-t-m-的预测方法" class="headerlink" title="对于时序数据的 $F_{t+m}$ 的预测方法"></a>对于时序数据的 $F_{t+m}$ 的预测方法</h4><h5 id="MA-滑动平均模型"><a href="#MA-滑动平均模型" class="headerlink" title="MA(滑动平均模型)"></a>MA(滑动平均模型)</h5><p>这种方法并不考虑数据的趋势性，单纯根据历史信息来求得当前点的滑动平均数值，参数 T（也即WindowSize） 决定了依赖历史的程度。</p>
<p>我们用 $S$ 表示处理后的序列，那么 $S_t$ 等于 $X_{t−T+1}$ 到 $X_t$ 的平均值，即</p>
<p> $S_t=\frac{1}{T}\Sigma^t_{i=t−T+1}X_i$</p>
<p>我们使用 $S_t \simeq \hat{X_t}$，下面我们使用滑动平均来预测 windmachine 的第一列的数据，并根据预测值进行异常检测。</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1fmvmepv069j31hc140772.jpg" alt=""></p>
<h5 id="EA-指数平均模型"><a href="#EA-指数平均模型" class="headerlink" title="EA(指数平均模型)"></a>EA(指数平均模型)</h5><p>在这里我们使用二阶指数平均，二阶在一阶的基础上增加了对于趋势的考量，更符合我们的数据要求，而三阶需要依赖于周期性，这点和上述的 ARIMA 模型所依赖的周期性也是相同的，下一步我们也需要加入周期性的考量。</p>
<p>我们可以看到，虽然指数平均在产生新的数列的时候考虑了所有的历史数据，但是仅仅考虑其静态值，即没有考虑时间序列当前的变化趋势。如果当前的股票处于<strong>上升趋势</strong>，那么当我们对明天的股票进行预测的时候，好的预测值不仅仅是对历史数据进行『平均』，而且要考虑到当前数据变化的<em>上升趋势</em>。同时考虑历史平均和变化趋势，这边是<strong>二阶指数平均</strong>。<br>我们先给出二阶指数平均的两种方法，如下</p>
<ol>
<li><p>$initialize$<br>$S_1 = X_1$<br>$b_1 = X_1−X_0$<br>$for  t &gt; 1$<br>$S_t = αX_t + (1−α) ( S_t−1+b_t−1)$<br>$b_t = β(S_t−S_t−1)+(1−β)b_t−1$<br>$end  for$</p>
<p>如果我们对 $X_{t+m}$ 之后的数值进行预测，那么我们的预测值为<br>$\hat{X}_{t+m} = S_t + mb_t$</p>
</li>
<li><p>$S′_0=X_0$<br>$S^{′′}_0=X_0$<br>$for  t \geq 1$<br>$\quad S^{‘}_t = \alpha X_t+(1-\alpha)S_{t-1}^{‘} \quad S^{‘’}_t = \alpha S^{‘}_t +(1-\alpha)S_{t-1}^{‘’}\quad S_t = 2S^{‘}_t-S^{‘’}_t$</p>
<p>end for</p>
<p>在方法二中，只有一个参数 $α$ 。其中$S^{‘}_t$为最基本的指数平均得到的结果，而 $S^{‘}_t - S^{“}_t$ 为变化的趋势.</p>
<p>如果我们对 $X_{t+m}$ 之后的数值进行预测，那么我们的预测值为<br>$\hat{X}_{t+m} = S_t +(m\frac{\alpha}{1-\alpha})(S^{‘}_t-S^{‘’}_{t})$</p>
</li>
</ol>
<p>我们利用二阶指数平均对于数据进行处理及异常检测的结果如下：</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fmxhde15csj31hc140wgw.jpg" alt=""></p>
<h4 id="用于修正的方法"><a href="#用于修正的方法" class="headerlink" title="用于修正的方法"></a>用于修正的方法</h4><h5 id="布林通道"><a href="#布林通道" class="headerlink" title="布林通道"></a>布林通道</h5><p>布林通道是一个在股票市场中经常使用的概念，它在应用上结合了移动平均和标准差的概念，其基本的型态是由三条轨道线组成的带状通道（中轨和上、下轨各一条）。上下轨分别由平均值加减二倍标准差（<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d113484745294ddf53ff5589762d9565d63b7c36" alt="\pm 2\sigma ">）得到，<strong>中轨</strong>为股价的平均成本，<strong>上轨</strong>和<strong>下轨</strong>可分别视为股价的压力线和支撑线。</p>
<blockquote>
<p>下图中红线为上轨，绿线为下轨，蓝线为滑动平均值。</p>
</blockquote>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1fmxkgfdm6wj30je0fgmxo.jpg" alt=""></p>
<p>由大数定律以及高斯分布模型，我们可以获知在上下二倍标准差基本涵盖了数据变化的95%左右的情况，如果超出这个分布，那么极有可能是异常点，因此在我们的模型中我们结合布林通道进行了异常点的修正。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1fmxkmds0frj30me0asmx7.jpg" alt=""></p>
<h5 id="RSI指数"><a href="#RSI指数" class="headerlink" title="RSI指数"></a>RSI指数</h5><p>RSI指数在证券市场中适用于衡量一段周期内增长和下降强弱对比的一个指标，其计算公式如下：</p>
<ol>
<li>RSI = 100×RS / (1+RS)</li>
<li>RS = X天的平均上涨点数 / X天的平均下跌点数</li>
</ol>
<p>通俗的讲，RSI 指数过高代表上涨明显（超买现象），意味着有可能会存在潜在的下跌，RSI指数过低则反之。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fmxkr5mywfg30f009qwel.gif" alt=""></p>
<p>下面是我们使用布林通道进行异常检测的测试：</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1fmxkzutsmwj31hc140n0g.jpg" alt=""></p>
<p>下面是我们使用修正之后的模型结合EA方法进行异常检测的情况：</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fmxl1rstxaj31hc140whb.jpg" alt=""></p>
<h3 id="比较器"><a href="#比较器" class="headerlink" title="比较器"></a>比较器</h3><p>预测器预测出当前时刻传感器的预测值后，还需要与真实值比较来判断当前时刻数据是否异常。一般的比较器都是通过阈值法，比如实际值超过预测值的一定比例就认为该点出现异常，进行报警。这种方式错误率比较大。在传感器数值模型的报警检测中没有使用这种方式，而是使用了两个串联的 Filter，只有当两个 Fliter 都认为该点异常时，才进行报警，下面简单介绍一下两个 Filter 的实现。</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1fmxgr0c6roj30y20m674f.jpg" alt="@图4.1 比较器模型 | center | 500x0"></p>
<h4 id="离散度Filter"><a href="#离散度Filter" class="headerlink" title="离散度Filter"></a>离散度Filter</h4><p>根据预测误差曲线离散程度过滤出可能的异常点。一个序列的方差表示该序列离散的程度，方差越大，表明该序列波动越大。如果一个预测误差序列方差比较大，那么我们认为预测误差的报警阈值相对大一些才比较合理。离散度 filter 利用了这一特性，我们对于这个真实数据点的前 $N$ 个点求方差，下一步阈值 filter 的输入为方差 $\sigma$.</p>
<h4 id="阈值Filter"><a href="#阈值Filter" class="headerlink" title="阈值Filter"></a>阈值Filter</h4><p>根据误差绝对值是否超过某个阈值过滤出可能的异常点。利用离散度 Filter 进行过滤时，报警阈值随着误差序列波动程度变大而变大，但是在输入数据比较小时，误差序列方差比较小，报警阈值也很小，容易出现误报。所以设计了根据方差 $\sigma$ 进行过滤的阈值 filter。阈值 filter 设计了一个分段阈值函数 $y=f(x)$，对于实际值 $x$ 和预测值 $p$ ，只有当 $|x-p|&gt;f(x)$ 时报警。实际使用中，可以根据数据寻找一个对数函数替换分段阈值函数，更易于参数调优。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h3 id="创新性"><a href="#创新性" class="headerlink" title="创新性"></a>创新性</h3><p>目前少见有人使用预测器 + 判别器的方式结合金融统计方法进行异常检测，这种方式本身比较新颖。主要优势有如下几点：</p>
<ol>
<li>相对于我们之前采用的机器学习的方法，这种方法即使在大数据的情况下也能够顺利完成，因为根据选取方法的不同，基本都是在 $O(N)$ 级别的方法。</li>
<li>可以实现在线实时预测，可以将成套的算法写入传感器芯片内作为硬件级别的预测，芯片内只需要存储规定 $N$ 日内的数据即可。</li>
</ol>
<h3 id="不足"><a href="#不足" class="headerlink" title="不足"></a>不足</h3><ol>
<li>在预测器中其实我们也应该考虑ARIMA或者是三阶指数平滑（即Holt-winters）模型，但是对于传感器数据的先验信息我们并不了解，导致我们不能够手动的设置其周期值，对于周期性不明确的情况，我们暂时使用 fix 方法作为补偿。</li>
<li>下一步我计划使用RNN作为预测器，使用LSTM方法，直接对数据进行预测，但是这种方法可能会比现有的方法更耗时，但是有可能会有更高的准确性，而且目前我已经在尝试使用 LSTM 提取数据的周期性，效果还不错。</li>
</ol>
<h4 id="困难点分析"><a href="#困难点分析" class="headerlink" title="困难点分析"></a>困难点分析</h4><ol>
<li>对数据的先验知识不够，这近似于一个非监督学习，如果要对效率有更高的要求可能需要更多的标记。</li>
<li>对未来这个系统的使用方法，使用对象和项目雏形不是很了解。</li>
<li>目前尚未完成对于数据的周期性提取的高效算法（LSTM相对来说比较耗时，对于大数据可能不太适用）。</li>
<li>目前尚未完成对于模式异常的识别。</li>
</ol>
<h4 id="研究方向"><a href="#研究方向" class="headerlink" title="研究方向"></a>研究方向</h4><ol>
<li>正在学习使用 RNN 进行序列的预测，到时候会根据正确性以及效率来和现有的方法进行选择以及比较。</li>
<li>正在考虑是否需要将大段的点异常归类为段异常，从而进行模式异常的识别。</li>
<li>在目前我们的实验中，主要使用了两种预测方法+两种修正方法，但实际上时序数据还有许多可以增加的模型和修正方法（我们倾向于使用多修正方法进行参数投票，最终用拟合的方式找出一个最适合我们训练数据的函数），这些方法的最终目的就是能够更加根据历史信息平滑的预测变化量，从而为我们的异常检测提出建议的值。</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://www.luodian.ink/2017-12-29/基于统计方法进行时序数据预测的异常检测模型/" data-id="cjeaoysuj000nni1ybaumijqg" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-数据之美-时间序列分析" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017-12-27/数据之美-时间序列分析/" class="article-date">
  <time datetime="2017-12-27T07:10:53.000Z" itemprop="datePublished">2017-12-27</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/异常检测/">异常检测</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017-12-27/数据之美-时间序列分析/">数据之美-时间序列分析</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="时间序列分析"><a href="#时间序列分析" class="headerlink" title="时间序列分析"></a>时间序列分析</h3><blockquote>
<p>部分内容整理自：<a href="https://www.ricequant.com/community/topic/567/" target="_blank" rel="noopener">https://www.ricequant.com/community/topic/567/</a></p>
<p>但是在这上面做了扩充，而且也纠正了它的排版和公式等。</p>
</blockquote>
<p>时间序列是指一个数据序列，特别是之由一段时间内采集的信号组成的序列，序列前面的信号表示采集的时间较早。比如一只股票（000056）在2015年一月一号到2015年12月一号的收盘价就是一个时间序列，我们用X表示这个序列并把它画在下图中。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fmvd266cd3j30a607k74a.jpg" alt=""></p>
<p>与其他的数据分析技术不同，时间序列分析一般假设我们获得的数据在时域上具有一定的相互依赖关系，如果股票价格在t时刻很高，那么在t+1时刻价格也会比较高（跌停才10%）；在比如如果股票价格在一段时间内获得稳定的上升，那么在接下来的一段时间内延续上升趋势的概率也会比较大。而时间序列分析的目的包含以下两个方面：</p>
<ul>
<li>发现这种隐含的依赖关系，并增加我们对此类时间序列的理解；</li>
<li>对未观测到的或者尚未发生的时间序列进行预测。</li>
</ul>
<p>在接下来的分析中，我们认为时间序列 $X$ 由两部分组成，即 $X_t=\hat{X}_t+\epsilon_t$. 其中$\hat{X}_t$ 是有规律的序列而$ \epsilon_t$ 则无规律的噪声。有规律的 $X_t$ 包含我们想要发现的依赖关系（pattern），而 $\epsilon_t$ 我们认为在时间域内不存在相互依赖的关系，即 $\epsilon_t$ 和$\epsilon_{t+1}$ 之间是相互独立的。</p>
<p>一个最简单的模型就是我们假设 $\epsilon_t$ 是一个随机数，服从一定的概率分布 $f_t(\epsilon)$。</p>
<p>可以发现，我们想要找到 $\hat{X}_t$ 而对 $ϵ_t$不怎么感兴趣。为了使有规律的 $\hat{X}_t$ 更加明显，我们通常希望能过滤到噪声，而最简单的过滤噪声的方法就是『取平均』。</p>
<p>而问题来了，对于时间序列信号来说，我们该如何取平均呢？</p>
<p>目前主要有以下两种方式：</p>
<ol>
<li><p>滑动平均（Moving Average）</p>
<p>并不考虑数据的趋势性，单纯根据历史信息来求得当前点的滑动平均数值，参数 windowSize 决定了依赖历史的程度。</p>
<p>我们用 $S$ 表示处理后的序列，那么 $S_t$ 等于 $X_{t−T+1}$ 到 $X_t$ 的平均值，即</p>
<p> $S_t=\frac{1}{T}\Sigma^t_{i=t−T+1}X_i$</p>
<p>我们使用 $S_t \simeq \hat{X_t}​$，下面我们使用滑动平均来预测 windmachine 的第一列的数据，并根据预测值进行异常检测。</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1fmvmepv069j31hc140772.jpg" alt=""></p>
</li>
<li><p>指数平均（Exponent Average）</p>
<ol>
<li><p>一阶指数平均</p>
<p>$S_0 = X_0$</p>
<p>$S_t = \alpha X_t + (1−α)S_{t−1}  ,  for   t≥1$</p>
<p>其中参数$\alpha \in (0,1)$</p>
<p>可以看到 $S_t​$ 是某种 weighted averaging，而使用的权重服从几何分布，这也是这种平均方法被称为指数平均的原因（指数分布是几何分布的连续形式）。这种平均方法的一个重要特征就是，St用之前产生的所有信号有关，并且距离越近的信号所占权重越大。我们使用两个不同参数 $α=0.8​$ 和 $α=0.3​$对以上的股票价格序列进行处理，得到的结果如下图所示</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1fmvduyt3ovj30a607kmx7.jpg" alt=""></p>
<p>同时，我们也可以使用指数平均对未来进行预测。在这里我们用当前得到的指数平均作为下一个时间的预测，假如对t+1时刻的预测用 $\hat{X}_{t+1}$ 表示，那么 $\hat{X}_{t+1} = S_t.$<br>为了更清楚地说明问题，我们画出一段时间的图像，如下图所示</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1fmvf171aq1j30ap08it8n.jpg" alt=""></p>
</li>
<li><p>二阶指数平均</p>
<p>我们可以看到，虽然指数平均在产生新的数列的时候考虑了所有的历史数据，但是仅仅考虑其静态值，即没有考虑时间序列当前的变化趋势。如果当前的股票处于<strong>上升趋势</strong>，那么当我们对明天的股票进行预测的时候，好的预测值不仅仅是对历史数据进行『平均』，而且要考虑到当前数据变化的<em>上升趋势</em>。同时考虑历史平均和变化趋势，这边是<strong>二阶指数平均</strong>。<br>我们先给出二阶指数平均的两种方法，如下</p>
<ol>
<li><p>$initialize$<br>$S_1 = X_1$<br>$b_1 = X_1−X_0$<br>$for  t &gt; 1​$<br>$S_t = αX_t + (1−α) ( S_t−1+b_t−1)$<br>$b_t = β(S_t−S_t−1)+(1−β)b_t−1$<br>$end  for$</p>
<p>如果我们对 $X_{t+m}$ 之后的数值进行预测，那么我们的预测值为<br>$\hat{X}_{t+m} = S_t + mb_t$</p>
</li>
<li><p>$S′_0=X_0$<br>$S^{′′}_0=X_0$<br>$for  t \geq 1$<br>$\quad S^{‘}_t = \alpha X_t+(1-\alpha)S_{t-1}^{‘} \quad S^{‘’}_t = \alpha S^{‘}_t +(1-\alpha)S_{t-1}^{‘’}\quad S_t = 2S^{‘}_t-S^{‘’}_t$</p>
<p>end for</p>
<p>在方法二中，只有一个参数α。其中S′t为最基本的指数平均得到的结果，而S′t−S′′t为变化的趋势.</p>
<p>如果我们对 $X_{t+m}$ 之后的数值进行预测，那么我们的预测值为<br>$\hat{X}_{t+m} = S^{‘}_t +(1+m\frac{\alpha}{1-\alpha})(S^{‘}_t-S^{‘’}_{t})$</p>
</li>
</ol>
</li>
<li><p>三阶指数平均</p>
<p>就是我们在17周周报里提到过的啦~</p>
</li>
</ol>
<h3 id="Wind-Machine-Data异常检测"><a href="#Wind-Machine-Data异常检测" class="headerlink" title="Wind Machine Data异常检测"></a>Wind Machine Data异常检测</h3><p>​</p>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://www.luodian.ink/2017-12-27/数据之美-时间序列分析/" data-id="cjeaoysut0010ni1yeum563pi" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-股票技术资料" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017-12-27/股票技术资料/" class="article-date">
  <time datetime="2017-12-27T05:47:59.000Z" itemprop="datePublished">2017-12-27</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/投资/">投资</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017-12-27/股票技术资料/">股票技术资料</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="时机度量"><a href="#时机度量" class="headerlink" title="时机度量"></a>时机度量</h2><ol>
<li><p>乖离率（物极必反的原理体现）</p>
<ul>
<li><p>公式：当前收盘价减去移动平均（MA）的差值</p>
<p>$乖离率 = \frac{收盘价 - 均线值}{均线值}$。</p>
</li>
<li><p>应用：</p>
<p>5日，6日均线对应5日，6日乖离率，常用5，6，12，30日乖离。</p>
</li>
<li><p>正乖离越大，市场就越可能继续修正向下，负的亦然，总的来说股票市场更多的会向移动平均线靠拢。</p>
<p>值得参考的乖离率参数如下：</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fmvaie5fmej31kw0qa774.jpg" alt=""></p>
<blockquote>
<p>注意：对于长期处于缓涨缓跌，整理区间，其乖离率参考价值不大（因为数值始终会很小）。</p>
</blockquote>
</li>
</ul>
<p>​</p>
<p>​</p>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://www.luodian.ink/2017-12-27/股票技术资料/" data-id="cjeaoysv2001bni1ymlgx9zu9" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-17周周报-使用Holt-Winters模型通过比对预测值进行异常检测" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017-12-24/17周周报-使用Holt-Winters模型通过比对预测值进行异常检测/" class="article-date">
  <time datetime="2017-12-24T12:43:29.000Z" itemprop="datePublished">2017-12-24</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/异常检测/">异常检测</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017-12-24/17周周报-使用Holt-Winters模型通过比对预测值进行异常检测/">17周周报-使用Holt-Winters模型通过比对预测值进行异常检测</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="基于预测比较模型的异常检测"><a href="#基于预测比较模型的异常检测" class="headerlink" title="基于预测比较模型的异常检测"></a>基于预测比较模型的异常检测</h1><blockquote>
<p>16周时，开始尝试一些新的思路与原有方法的对比，在比较了传统的滑动平均和现有的指数平均方法之后，我们采用Holt Winters方法从预测的角度来做误差分析。</p>
</blockquote>
<h3 id="新的方法"><a href="#新的方法" class="headerlink" title="新的方法"></a>新的方法</h3><p>在序列数据的异常检测过程中，我们既可以直接使用对序列进行异常检测的算法，也可以先对序列数据进行特征提取然后转化为传统的离群点检测。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>离群点检测方法</th>
<th>方法描述</th>
<th>方法特点</th>
</tr>
</thead>
<tbody>
<tr>
<td>基于统计</td>
<td>大部分的基于统计的离群点检测方法是构建一个概率分布模型，并计算对象符合该模型的概率，把具有低概率的对象视为离群点</td>
<td>基于统计模型的离群点检测方法的前提是必须知道数据集服从什么分布；而对于高维的数据，可能每一维度服从的分布都不太一致，所以通常对高维数据来讲通常效果较差。</td>
</tr>
<tr>
<td>基于邻近度</td>
<td>通常可以在数据对象之间定义邻近性度量，把远离大部分点的对象视为离群点。</td>
<td>算法假定离群点是离散的，低维数据我们可以作图观察，而高维数据我们无法观察，所以难以确定有效的参数和全局阈值，效果较差。</td>
</tr>
<tr>
<td>基于聚类</td>
<td>一种利用聚类检测离群点的方法是直接丢弃远离其他簇的小簇；另一种是对数据点属于簇的程度进行评价，去除得分较低的点。</td>
<td>聚类算法产生的簇的质量对该算法产生的离群点的质量影响非常大，对数据的可分类性要求较高</td>
</tr>
</tbody>
</table>
</div>
<p>之前考虑的算法方向主要是在『基于统计』+『基于聚类』的这个方向来考量。</p>
<p>而如今我发现了一种新的方法可以作为采用与尝试，即上图中『基于临近度』，也是一种使用历史数据判断当前数据的方法。</p>
<p>基于预测的异常检测模型如下图所示，$x_t$ 是真实数据，通过预测器得到预测数据，然后 $x_t$ 和 $p_t$ 分别作为比较器的输入，最终得到输出 $y_t$，$y_t$ 是一个二元值，可以用+1（+1表示输入数据正常），-1（-1表示输入数据异常）表示。</p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fmroslheqbj31d00m2jrh.jpg" alt=""></p>
<p>如果说我们设置异常检测的模型如此，那么我们可以从两个以下方面入手，一是预测器的优化，二是比较器的优化。</p>
<h4 id="预测器优化"><a href="#预测器优化" class="headerlink" title="预测器优化"></a>预测器优化</h4><h5 id="同比环比预测器"><a href="#同比环比预测器" class="headerlink" title="同比环比预测器"></a>同比环比预测器</h5><p>同比环比是比较常用的异常检测方式，它是将当前时刻数据和前一时刻数据（环比）或者前一天同一时刻数据（同比）比较，超过一定阈值即认为该点异常。如果用图模型来表示，那么预测器就可以表示为用当前时刻前一时刻或者前一天同一时刻数据作为当前时刻的预测数据。</p>
<p>如果将不同日期、时刻的监控数据以矩阵方式存储，每一行表示一天内不同时刻的监控数据，每一列表示同一时刻不同日期的监控数据，那么存储矩阵如下图所示：</p>
<p><img src="https://ws4.sinaimg.cn/large/006tNc79ly1fmroz08dq2j30a207ua9x.jpg" alt=""></p>
<p>假如需要预测图中黄色数据，那么环比使用图中的蓝色数据作为预测黄点的源数据，同比使用图中红色数据作为预测黄点的源数据。</p>
<h5 id="基线预测器（MA方法）"><a href="#基线预测器（MA方法）" class="headerlink" title="基线预测器（MA方法）"></a>基线预测器（MA方法）</h5><p>同比环比使用历史上的单点数据来预测当前数据，误差比较大。$t$ 时刻的监控数据，与<br>$t-1,t-2,…$ 时刻的监控数据存在相关性。同时，与$t-k,t-2k,…$ 时刻的数据也存在相关性（<em>k</em>为周期），如果能利用上这些相关数据对<em>t</em>时刻进行预测，预测结果的误差将会更小。</p>
<p>比较常用的方式是对历史数据求平均，然后过滤噪声，可以得到一个平滑的曲线（基线），使用基线数据来预测当前时刻的数据。该方法预测 $t$ 时刻数据（图中黄色数据）使用到的历史数据如下图所示（图中红色数据）：</p>
<p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1fmrozw8uuij309s07e745.jpg" alt=""></p>
<h5 id="Holt-Winters预测器"><a href="#Holt-Winters预测器" class="headerlink" title="Holt-Winters预测器"></a>Holt-Winters预测器</h5><p>同比环比预测到基线数据预测，使用的相关数据变多，预测的效果也较好。但是基线数据预测器只使用了周期相关的历史数据，没有使用上同周期相邻时刻的历史数据，相邻时刻的历史数据对于当前时刻的预测影响是比较大的。对于 <strong>Holt-winters </strong>预测期模型，它建议使用黄色点左上方的所有数据。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fmrp7xumw7j309u07k745.jpg" alt=""></p>
<p>Holt-Winters是三次指数滑动平均算法，它将时间序列数据分为三部分：残差数据 $a(t)$，趋势性数据 $b(t)$，周期性数据 $s(t)$。使用Holt-Winters预测 $t$ 时刻数据，需要 $t$ 时刻前包含多个周期的历史数据。</p>
<p>详细信息看这里：<a href="https://www.otexts.org/fpp/7/5" target="_blank" rel="noopener">https://www.otexts.org/fpp/7/5</a></p>
<p>在实际的异常检测模型中，我们对Holt-Winters预测器进行了简化。预测器的趋势数据表示的是时间序列的总体变化趋势，经过分析，如果以天/小时为周期看待传感器数据的订单量时间序列，是没有明显的趋势性的，如下的分解图也证明了这一点。因此，我们可以去掉其中的趋势数据部分。</p>
<p>各部分迭代的简化计算公式如（其中 $k$ 为周期）：</p>
<ol>
<li>$a[t] = \alpha(Y[t] - s[t-k]) + (1-\alpha) a[t-1]$</li>
<li>$s[t] = \gamma(Y[t] - a[t]) + (1 - \gamma)(s[t-k])$</li>
</ol>
<p>预测值：$Y[t+h] = a[t] + s[t-k+1 + (h-1)  mod  k]$</p>
<p>为了将算法应用到线上的实时预测，我们可以将 Holt-Winters 算法拆分为两个独立的计算过程：</p>
<ol>
<li><p>定时任务计算序列的周期数 $s(t)$。</p>
<p>$S(t)$ 不需要实时计算，只用按照周期性更新即可，使用 Holt-Winters 公式计算出时间序列的周期性数据。</p>
</li>
<li><p>对残差序列做实时预测。</p>
<p>计算出周期数据后，下一个目标就是对残差数据的预测。使用下面的公式，实际监控数据与周期数据相减得到残差数据，对残差数据做一次滑动平均，预测出下一刻的残差，将该时刻的残差、周期数据相加即可得到该时刻的预测数据。对于分钟数据，则将残差序列的长度设为60，即可以得到比较准确的预测效果。</p>
<blockquote>
<p>红线为预测数据，蓝线为真实数据</p>
</blockquote>
<p><img src="https://tech.meituan.com/img/holtwinter/p1.png" alt="@ 图3.8a) | center | 500x0"></p>
<p>​</p>
</li>
</ol>
<h3 id="比较器优化"><a href="#比较器优化" class="headerlink" title="比较器优化"></a>比较器优化</h3><p>预测器预测出当前时刻传感器的预测值后，还需要与真实值比较来判断当前时刻数据是否异常。一般的比较器都是通过阈值法，比如实际值超过预测值的一定比例就认为该点出现异常，进行报警。这种方式错误率比较大。在传感器数值模型的报警检测中没有使用这种方式，而是使用了两个串联的Filter，只有当两个Fliter都认为该点异常时，才进行报警，下面简单介绍一下两个Filter的实现。</p>
<p><img src="https://tech.meituan.com/img/holtwinter/compaire.png" alt="@图4.1 比较器模型 | center | 500x0"></p>
<h4 id="离散度Filter"><a href="#离散度Filter" class="headerlink" title="离散度Filter"></a>离散度Filter</h4><p>根据预测误差曲线离散程度过滤出可能的异常点。一个序列的方差表示该序列离散的程度，方差越大，表明该序列波动越大。如果一个预测误差序列方差比较大，那么我们认为预测误差的报警阈值相对大一些才比较合理。离散度 Filter 利用了这一特性，取连续 15 分钟的预测误差序列，分为首尾两个序列（e1,e2），如果两个序列的均值差大于 e1 序列方差的某个倍数，我们就认为该点可能是异常点。</p>
<h4 id="阈值Filter"><a href="#阈值Filter" class="headerlink" title="阈值Filter"></a>阈值Filter</h4><p>根据误差绝对值是否超过某个阈值过滤出可能的异常点。利用离散度 Filter 进行过滤时，报警阈值随着误差序列波动程度变大而变大，但是在输入数据比较小时，误差序列方差比较小，报警阈值也很小，容易出现误报。所以设计了根据误差绝对值进行过滤的阈值 Filter。阈值 Filter 设计了一个分段阈值函数 $y=f(x)$，对于实际值 $x$ 和预测值 $p$ ，只有当 $|x-p|&gt;f(x)$ 时报警。实际使用中，可以寻找一个对数函数替换分段阈值函数，更易于参数调优。</p>
<h3 id="模型最终架构"><a href="#模型最终架构" class="headerlink" title="模型最终架构"></a>模型最终架构</h3><p>每天定时抽取历史10天数据，经过预处理模块，去除异常数据，经过周期数据计算模块得到周期性数据。对当前时刻预测时，取60分钟的真实数据和周期性数据，经过实时预测模块，预测出当前传感器数值。将连续15分钟的预测值和真实值通过比较器，判断当前时刻是否异常。</p>
<p><img src="https://tech.meituan.com/img/holtwinter/jiegoutu.png" alt="@图4.2 分段阈值filter | center | 500x0"></p>
<blockquote>
<p>参考来源：</p>
<ol>
<li><a href="https://www.jianshu.com/p/6fb0408b3f54" target="_blank" rel="noopener">https://www.jianshu.com/p/6fb0408b3f54</a></li>
<li><a href="https://www.otexts.org/fpp/7/5" target="_blank" rel="noopener">https://www.otexts.org/fpp/7/5</a></li>
</ol>
</blockquote>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://www.luodian.ink/2017-12-24/17周周报-使用Holt-Winters模型通过比对预测值进行异常检测/" data-id="cjeaoysty0005ni1y4dkwaidq" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Mecari-Analysis-LB-0-4229-rank-17-1090" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017-12-23/Mecari-Analysis-LB-0-4229-rank-17-1090/" class="article-date">
  <time datetime="2017-12-23T13:17:16.000Z" itemprop="datePublished">2017-12-23</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017-12-23/Mecari-Analysis-LB-0-4229-rank-17-1090/">Mecari-Analysis(LB=0.4229~rank 17 / 1090)</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Mecari"><a href="#Mecari" class="headerlink" title="Mecari"></a>Mecari</h1><p>其实从情理上来说这个比赛有一点奇怪，因为全凭给出的 feature 似乎并不能很好的去 fit 结果的 price。</p>
<p>所以如果不能从特征工程的角度去挖掘数据的信息的话，只拿已给出的信息扔进 xgboost 或者是 lgbm，似乎就会和大部分人在同一个水平线。</p>
<h2 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h2><h3 id="NLP-Related"><a href="#NLP-Related" class="headerlink" title="NLP-Related"></a>NLP-Related</h3><h5 id="Document-term-matrix"><a href="#Document-term-matrix" class="headerlink" title="Document-term matrix"></a>Document-term matrix</h5><p>A <strong>document-term matrix</strong> or <strong>term-document matrix</strong> is a mathematical <a href="https://en.wikipedia.org/wiki/Matrix_(mathematics" target="_blank" rel="noopener">matrix</a>) that describes the frequency of terms that occur in a collection of documents. In a document-term matrix, rows correspond to documents in the collection and columns correspond to terms. There are various schemes for determining the value that each entry in the matrix should take.</p>
<ul>
<li>D1 = “I like databases”</li>
<li>D2 = “I hate databases”</li>
</ul>
<p>then the document-term matrix would be:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>I</th>
<th>like</th>
<th>hate</th>
<th>databases</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>D1</strong></td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td><strong>D2</strong></td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>
</div>
<p>也可以使用tf-idf schema对其进行计数。</p>
<h5 id="Bags-of-words-model"><a href="#Bags-of-words-model" class="headerlink" title="Bags of words model"></a>Bags of words model</h5><p>下列文件可用词袋表示:</p>
<p>以下是两个简单的文件:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(1) John likes to watch movies. Mary likes movies too.</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(2) John also likes to watch football games.</span><br></pre></td></tr></table></figure>
<p>基于以上两个文件，可以建构出下列清单:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">    <span class="string">"John"</span>,</span><br><span class="line">    <span class="string">"likes"</span>,</span><br><span class="line">    <span class="string">"to"</span>,</span><br><span class="line">    <span class="string">"watch"</span>,</span><br><span class="line">    <span class="string">"movies"</span>,</span><br><span class="line">    <span class="string">"also"</span>,</span><br><span class="line">    <span class="string">"football"</span>,</span><br><span class="line">    <span class="string">"games"</span>,</span><br><span class="line">    <span class="string">"Mary"</span>,</span><br><span class="line">    <span class="string">"too"</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>此处有10个不同的词，使用清单的索引表示长度为10的向量:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[1, 2, 1, 1, 2, 0, 0, 0, 1, 1] (2) [1, 1, 1, 1, 0, 1, 1, 1, 0, 0]</span><br></pre></td></tr></table></figure>
<p>每个向量的索引内容对应到清单中词出现的次数。</p>
<h3 id="标签二值化"><a href="#标签二值化" class="headerlink" title="标签二值化"></a>标签二值化</h3><p><a href="http://sklearn.lzjqsdd.com/modules/generated/sklearn.preprocessing.LabelBinarizer.html#sklearn.preprocessing.LabelBinarizer" target="_blank" rel="noopener"><code>LabelBinarizer</code></a> 是一个用来从多类别列表创建标签矩阵的工具类:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lb = preprocessing.LabelBinarizer()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lb.fit([<span class="number">1</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">4</span>, <span class="number">2</span>])</span><br><span class="line">LabelBinarizer(neg_label=<span class="number">0</span>, pos_label=<span class="number">1</span>, sparse_output=<span class="keyword">False</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lb.classes_</span><br><span class="line">array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lb.transform([<span class="number">1</span>, <span class="number">6</span>])</span><br><span class="line">array([[<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>]])</span><br></pre></td></tr></table></figure>
<p>在 <code>mecari</code> 中我们对 <code>brand_name</code> 进行二值化处理，生成了一个<code>item * brand_count</code> 大小的矩阵。</p>
<h3 id="One-hot-编码和-get-dummies"><a href="#One-hot-编码和-get-dummies" class="headerlink" title="One-hot 编码和 get_dummies"></a>One-hot 编码和 get_dummies</h3><p>离散特征的编码分为两种情况：</p>
<ol>
<li>离散特征的取值之间没有大小的意义，比如color：[red,blue],那么就使用one-hot编码</li>
<li>离散特征的取值有大小的意义，比如size:[X,XL,XXL],那么就使用数值的映射{X：1,XL：2,XXL：3}</li>
</ol>
<p>使用pandas可以很方便的对离散型特征进行one-hot编码。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd  </span><br><span class="line">df = pd.DataFrame([  </span><br><span class="line">            [<span class="string">'green'</span>, <span class="string">'M'</span>, <span class="number">10.1</span>, <span class="string">'class1'</span>],   </span><br><span class="line">            [<span class="string">'red'</span>, <span class="string">'L'</span>, <span class="number">13.5</span>, <span class="string">'class2'</span>],   </span><br><span class="line">            [<span class="string">'blue'</span>, <span class="string">'XL'</span>, <span class="number">15.3</span>, <span class="string">'class1'</span>]])  </span><br><span class="line">  </span><br><span class="line">df.columns = [<span class="string">'color'</span>, <span class="string">'size'</span>, <span class="string">'prize'</span>, <span class="string">'class label'</span>]  </span><br><span class="line">  </span><br><span class="line">size_mapping = &#123;  </span><br><span class="line">           <span class="string">'XL'</span>: <span class="number">3</span>,  </span><br><span class="line">           <span class="string">'L'</span>: <span class="number">2</span>,  </span><br><span class="line">           <span class="string">'M'</span>: <span class="number">1</span>&#125;  </span><br><span class="line">df[<span class="string">'size'</span>] = df[<span class="string">'size'</span>].map(size_mapping)  </span><br><span class="line">  </span><br><span class="line">class_mapping = &#123;label:idx <span class="keyword">for</span> idx,label <span class="keyword">in</span> enumerate(set(df[<span class="string">'class label'</span>]))&#125;  </span><br><span class="line">df[<span class="string">'class label'</span>] = df[<span class="string">'class label'</span>].map(class_mapping)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>对于有大小意义的离散特征，直接使用映射就可以了，{‘XL’:3,’L’:2,’M’:1}</p>
</blockquote>
<p><img src="http://img.blog.csdn.net/20161017092849112?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="img"></p>
<p>Using the <code>get_dummies</code> will create a new column for every unique string in a certain column.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.get_dummies(df)</span><br></pre></td></tr></table></figure>
<p><img src="http://img.blog.csdn.net/20161017092944347?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="img"></p>
<h2 id="Tf-idf"><a href="#Tf-idf" class="headerlink" title="Tf-idf"></a>Tf-idf</h2><p><strong>TF</strong>：Term Frequency.</p>
<p>单词在文章中出现的频率。</p>
<p><strong>Idf</strong>：Inverse Document Frequency.</p>
<p>逆文档频率：为了衡量单词在该文章中的重要程度（在Mecari中我们是衡量单词在这条评论中的重要程度）。</p>
<p><img src="http://image.beekka.com/blog/201303/bg2013031506.png" alt="img"></p>
<p>如果一个词越常见，那么分母就越大，逆文档频率就越小越接近0。分母之所以要加1，是为了避免分母为0（即所有文档都不包含该词）。log表示对得到的值取对数。</p>
<p><img src="http://image.beekka.com/blog/201303/bg2013031507.png" alt="img"></p>
<p><strong>TF-IDF与一个词在文档中的出现次数成正比，与该词在整个语言中的出现次数成反比。</strong>所以，自动提取关键词的算法就很清楚了，就是计算出文档的每个词的TF-IDF值，然后按降序排列，取排在最前面的几个词。</p>
<h2 id="Boosting-思想"><a href="#Boosting-思想" class="headerlink" title="Boosting 思想"></a>Boosting 思想</h2><blockquote>
<p>不断的强化模型</p>
</blockquote>
<p>The term <code>Boosting</code> refers to a family of algorithms which converts weak learner to strong learners.</p>
<h4 id="Ada-Boost"><a href="#Ada-Boost" class="headerlink" title="Ada Boost"></a>Ada Boost</h4><p>Why often use decision tree?</p>
<p>Decision trees are non-linear. Boosting with linear models simply doesn’t work well.</p>
<p>The weak learner needs to be consistently better than random guessing. You don’t normal need to do any parameter tuning to a decision tree to get that behavior. Training an SVM really does need a parameter search. Since the data is re-weighted on each iteration, you likely need to do another parameter search on each iteration. So you are increasing the amount of work you have to do by a large margin. </p>
<p>Decision trees are reasonably fast to train. Since we are going to be building 100s or 1000s of them, thats a good property. They are also fast to classify, which is again important when you need 100s or 1000s to run before you can output your decision. </p>
<p>By changing the depth you have a simple and easy control over the bias/variance trade off, knowing that boosting can reduce bias but also significantly reduces variance. Boosting is known to overfit, so the easy nob to tune is helpful in that regard.</p>
<h4 id="GBM"><a href="#GBM" class="headerlink" title="GBM"></a>GBM</h4><p>回归树总体流程类似于分类树，区别在于，回归树的每一个节点都会得一个预测值，以年龄为例，该预测值等于属于这个节点的所有人年龄的平均值。分枝时穷举每一个feature的每个阈值找最好的分割点，但衡量最好的标准不再是最大熵，而是最小化平方误差。也就是被预测出错的人数越多，错的越离谱，平方误差就越大，通过最小化平方误差能够找到最可靠的分枝依据。分枝直到每个叶子节点上人的年龄都唯一或者达到预设的终止条件(如叶子个数上限)，若最终叶子节点上人的年龄不唯一，则以该节点上所有人的平均年龄做为该叶子节点的预测年龄。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/967544-81b3ff4fbf2c6afb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/541" alt="img"></p>
<h2 id="Lgbm-Light-Gradient-Boosting-Model"><a href="#Lgbm-Light-Gradient-Boosting-Model" class="headerlink" title="Lgbm(Light Gradient Boosting Model)"></a>Lgbm(Light Gradient Boosting Model)</h2><p><strong>Light GBM grows tree vertically </strong>while other algorithm grows trees horizontally meaning that Light GBM grows tree <strong>leaf-wise </strong>while other algorithm grows level-wise. It will choose the leaf with max delta loss to grow. When growing the same leaf, Leaf-wise algorithm can reduce more loss than a level-wise algorithm.</p>
<p>Below diagrams explain the implementation of LightGBM and other boosting algorithms.</p>
<p><img src="https://cdn-images-1.medium.com/max/1600/1*AZsSoXb8lc5N6mnhqX5JCg.png" alt="img"></p>
<p><img src="https://cdn-images-1.medium.com/max/1600/1*whSa8rY4sgFQj1rEcWr8Ag.png" alt="img"></p>
<h5 id="Parameters-Tunning"><a href="#Parameters-Tunning" class="headerlink" title="Parameters Tunning"></a>Parameters Tunning</h5><p> it is not advisable to use LGBM on small datasets. Light GBM is <strong>sensitive to overfitting</strong> and can easily overfit small data. Their is no threshold on the number of rows but my experience suggests me to use it only for data with 10,000+ rows.</p>
<p><strong>Control Parameters</strong></p>
<p><strong>max_depth:</strong> It describes the maximum depth of tree. This parameter is used to handle model overfitting. Any time you feel that your model is overfitted, my first advice will be to lower max_depth.</p>
<p><strong>min_data_in_leaf:</strong> It is the minimum number of the records a leaf may have. The default value is 20, optimum value. It is also used to deal over fitting</p>
<p><strong>feature_fraction:</strong> Used when your boosting(discussed later) is random forest. 0.8 feature fraction means LightGBM will select 80% of parameters randomly in each iteration for building trees.</p>
<p><strong>bagging_fraction:</strong> specifies the fraction of data to be used for each iteration and is generally used to speed up the training and avoid overfitting.</p>
<p><strong>early_stopping_round:</strong> This parameter can help you speed up your analysis. Model will stop training if one metric of one validation data doesn’t improve in last early_stopping_round rounds. This will reduce excessive iterations.</p>
<p><strong>lambda: </strong>lambda specifies regularization. Typical value ranges from 0 to 1.</p>
<p><strong>min_gain_to_split:</strong> This parameter will describe the minimum gain to make a split. It can used to control number of useful splits in tree.</p>
<p><strong>max_cat_group: </strong>When the number of category is large, finding the split point on it is easily over-fitting. So LightGBM merges them into ‘max_cat_group’ groups, and finds the split points on the group boundaries, default:64</p>
<p><strong>Core Parameters</strong></p>
<p><strong>Task: </strong>It specifies the task you want to perform on data. It may be either train or predict.</p>
<p><strong>application: </strong>This is the most important parameter and specifies the application of your model, whether it is a regression problem or classification problem. LightGBM will by default consider model as a regression model.</p>
<ul>
<li>regression: for regression</li>
<li>binary: for binary classification</li>
<li>multiclass: for multiclass classification problem</li>
</ul>
<p><strong>boosting:</strong> defines the type of algorithm you want to run, default=gdbt</p>
<ul>
<li>gbdt: traditional Gradient Boosting Decision Tree</li>
<li>rf: random forest</li>
<li>dart: Dropouts meet Multiple Additive Regression Trees</li>
<li>goss: Gradient-based One-Side Sampling</li>
</ul>
<p><strong>num_boost_round:</strong> Number of boosting iterations, typically 100+</p>
<p><strong>learning_rate: </strong>This determines the impact of each tree on the final outcome. GBM works by starting with an initial estimate which is updated using the output of each tree. The learning parameter controls the magnitude of this change in the estimates. Typical values: 0.1, 0.001, 0.003…</p>
<p><strong>num_leaves:</strong> number of leaves in full tree, default: 31</p>
<p><strong>device: </strong>default: cpu, can also pass gpu</p>
<p><strong>Metric parameter</strong></p>
<p><strong>metric：</strong> again one of the important parameter as it specifies loss for model building. Below are few general losses for regression and classification.</p>
<ul>
<li>mae: mean absolute error</li>
<li>mse: mean squared error</li>
<li>binary_logloss: loss for binary classification</li>
<li>multi_logloss: loss for multi classification</li>
</ul>
<p><strong>IO parameter</strong></p>
<p><strong>max_bin： </strong>it denotes the maximum number of bin that feature value will bucket in.</p>
<p><strong>categorical_feature:</strong> It denotes the index of categorical features. If categorical_features=0，1，2 then column 0， column 1 and column 2 are categorical variables.</p>
<p><strong>ignore_column：</strong> same as categorical_features just instead of considering specific columns as categorical, it will completely ignore them.</p>
<p><strong>save_binary：</strong> If you are really dealing with the memory size of your data file then specify this parameter as ‘True’. Specifying parameter true will save the dataset to binary file, this binary file will speed your data reading time for the next time.</p>
<p>Knowing and using above parameters will definitely help you implement the model. Remember I said that implementation of LightGBM is easy but parameter tuning is difficult. So let’s first start with implementation and then I will give idea about the parameter tuning.</p>
<h2 id="Ridge"><a href="#Ridge" class="headerlink" title="Ridge"></a>Ridge</h2><h4 id="线性最小二乘拟合解析解"><a href="#线性最小二乘拟合解析解" class="headerlink" title="线性最小二乘拟合解析解"></a>线性最小二乘拟合解析解</h4><p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1fmoltdbrsgj311q0qajsr.jpg" alt=""></p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1fmom4y06e8j31aa11cte1.jpg" alt=""></p>
<p>当XTX的行列式接近于0时，我们将其主对角元素都加上一个数k，可以使矩阵为奇异的风险大降低。于是：</p>
<p>B(k)=(XTX+kI)−1XTYB(k)=(XTX+kI)−1XTY (I是单位矩阵)</p>
<p>随着k的增大，B(k)中各元素bi(k)的绝对值均趋于不断变小，它们相对于正确值bi的偏差也越来越大。k趋于无穷大时，B(k)趋于0。b(k)随k的改变而变化的轨迹，就称为岭迹。实际计算中可选非常多的k值，做出一个岭迹图，看看这个图在取哪个值的时候变稳定了，那就确定k值了。</p>
<p>X不满足列满秩，换句话就是说样本向量之间具有高度的相关性（如果每一列是一个向量的话）。遇到列向量相关的情形，岭回归是一种处理方法，也可以用主成分分析PCA来进行降维。</p>
<p>岭回归的原理较为复杂。根据高斯马尔科夫定力，多重相关性并不影响最小二乘法估计量的无偏性和最小方差性，但是，虽然最小二乘估计量在所有线性估计量中是方差最小的，但是这个方差都不一定小，而实际上可以找到一个有偏估计量，这个估计量虽然有较小的偏差，但它的精度却能够大大高于无偏的估计量。岭回归分析就是根据这个原理，通过在正规方程中引入有偏常熟二求的回归估计量的。</p>
<h2 id="辅助函数"><a href="#辅助函数" class="headerlink" title="辅助函数"></a>辅助函数</h2><p><strong>preprocessing.MinMaxScaler</strong>：</p>
<p>The <code>MinMaxScaler</code> is the probably the most famous scaling algorithm, and follows the following formula for each feature:</p>
<p>xi–min(x)max(x)–min(x)</p>
<p>It essentially shrinks the range such that the range is now between 0 and 1 (or -1 to 1 if there are negative values).</p>
<p>This scaler works better for cases in which the standard scaler might not work so well. If the distribution is not Gaussian or the standard deviation is very small, the min-max scaler works better.</p>
<p>使用这种方法的目的包括：</p>
<ol>
<li>对于方差非常小的属性可以增强其稳定性。</li>
<li>维持稀疏矩阵中为0的条目。</li>
</ol>
<h2 id="Cross-Validation"><a href="#Cross-Validation" class="headerlink" title="Cross Validation"></a>Cross Validation</h2><p>在解决实际问题中，我们可以将所有的数据集 dataset ，划分为 train_set（例如70%）和test_set（30%），然后在 train_set 上做 cross_validation ，最后取平均之后，再使用test_set测试模型的准确度。</p>
<h4 id="K-Fold"><a href="#K-Fold" class="headerlink" title="K-Fold"></a>K-Fold</h4><ol>
<li>A model is trained using k-1 of the folds as training data; </li>
<li>the resulting model is validated on the remaining part of the data (i.e., it is used as a test set to compute a performance measure such as accuracy). </li>
</ol>
<p>The performance measure reported by k-fold cross-validation is then the average of the values computed in the loop.</p>
<h4 id="Grid-Search"><a href="#Grid-Search" class="headerlink" title="Grid Search"></a>Grid Search</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm, datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">parameters = &#123;<span class="string">'kernel'</span>:(<span class="string">'linear'</span>, <span class="string">'rbf'</span>), <span class="string">'C'</span>:[<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>], <span class="string">'gamma'</span>:[<span class="number">0.125</span>, <span class="number">0.25</span>, <span class="number">0.5</span> ,<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>]&#125;</span><br><span class="line">svr = svm.SVC()</span><br><span class="line">clf = GridSearchCV(svr, parameters, n_jobs=<span class="number">-1</span>)</span><br><span class="line">clf.fit(iris.data, iris.target)</span><br><span class="line">cv_result = pd.DataFrame.from_dict(clf.cv_results_)</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'cv_result.csv'</span>,<span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    cv_result.to_csv(f)</span><br><span class="line">    </span><br><span class="line">print(<span class="string">'The parameters of the best model are: '</span>)</span><br><span class="line">print(clf.best_params_)</span><br><span class="line"></span><br><span class="line">y_pred = clf.predict(iris.data)</span><br><span class="line">print(classification_report(y_true=iris.target, y_pred=y_pred))</span><br></pre></td></tr></table></figure>
<h2 id="Konstantin的建议"><a href="#Konstantin的建议" class="headerlink" title="Konstantin的建议"></a>Konstantin的建议</h2><p>Sure, let me give some examples:</p>
<ul>
<li>after looking at explained predictions, I see that “t-“ in word “t-shirt” is not highlighted, then I can check how scikit-learn vectorizer processes such words and see that it discards “t-“, so the model sees “shirt” - which may or may not be the problem, but it’s worth checking</li>
<li>after looking at the model features, I see that words like “16gb” and “32gb” are really important - I would check, maybe people also write “16 gb” too, and it’s better to normalize such cases to give the model a better job</li>
<li>I see “item_description__regimen” as a positive feature, this looks strange - is it a german word and so any german descriptions make the product more expensive? Or something else?</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://www.luodian.ink/2017-12-23/Mecari-Analysis-LB-0-4229-rank-17-1090/" data-id="cjeaoysue000gni1yt4j4kb2k" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-操作系统-文件系统" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017-12-21/操作系统-文件系统/" class="article-date">
  <time datetime="2017-12-21T02:35:53.000Z" itemprop="datePublished">2017-12-21</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/操作系统/">操作系统</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017-12-21/操作系统-文件系统/">操作系统-文件系统</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>思考：</p>
<ol>
<li>拷贝一个1G的文件 对比 1M 个 1K 的文件。</li>
<li>拷贝无数个空的文件夹？</li>
<li>无数个小文件总大小和占用磁盘空间大小不一致。</li>
<li>压缩后文件大小和占用磁盘空间大小更接近？</li>
<li>同磁盘剪切和跨磁盘剪切耗时对比。</li>
<li>对U盘格式化是在干什么？</li>
<li>磁盘碎片清理是在干什么？（不停的挪位置，挪到尽量连续的位置）</li>
</ol>
<h2 id="内部文件结构"><a href="#内部文件结构" class="headerlink" title="内部文件结构"></a>内部文件结构</h2><ul>
<li>树状结构：层级顺序路径解析</li>
<li>DAG结构</li>
</ul>
<p>磁盘按照：引导区，文件头数组，数据盘块集合这三个顺序组织。</p>
<h2 id="效率"><a href="#效率" class="headerlink" title="效率"></a>效率</h2><ul>
<li>磁盘缓存</li>
<li>某些目录的FCB可以常驻内存<ul>
<li>根目录</li>
<li>当前目录</li>
</ul>
</li>
<li>同一个目录下文件的FCB存储于同一个柱面。</li>
</ul>
<p>FCB是什么？：<a href="https://en.wikipedia.org/wiki/File_Control_Block" target="_blank" rel="noopener">File Control Block</a></p>
<h2 id="容错"><a href="#容错" class="headerlink" title="容错"></a>容错</h2><ul>
<li>RAID：利用便宜的磁盘组成存储阵列进行冗余存储。<ul>
<li>利用冗余磁盘进行备份。</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://www.luodian.ink/2017-12-21/操作系统-文件系统/" data-id="cjeaoysus000yni1yvryyh00a" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Ng-Cousera-Week-6-Bias-VS-Variance" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017-12-17/Ng-Cousera-Week-6-Bias-VS-Variance/" class="article-date">
  <time datetime="2017-12-17T10:26:55.000Z" itemprop="datePublished">2017-12-17</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017-12-17/Ng-Cousera-Week-6-Bias-VS-Variance/">Ng&#39;Cousera-Week 6-Bias vs Variance</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Diagnosing-Bias-vs-Variance"><a href="#Diagnosing-Bias-vs-Variance" class="headerlink" title="Diagnosing Bias vs. Variance"></a>Diagnosing Bias vs. Variance</h1><p>In this section we examine the relationship between the degree of the polynomial d and the underfitting or overfitting of our hypothesis.</p>
<ul>
<li>We need to distinguish whether <strong>bias</strong> or <strong>variance</strong> is the problem contributing to bad predictions.</li>
<li>High bias is underfitting and high variance is overfitting. Ideally, we need to find a golden mean between these two.</li>
</ul>
<p>The training error will tend to <strong>decrease</strong> as we increase the degree d of the polynomial.</p>
<p>At the same time, the cross validation error will tend to <strong>decrease</strong> as we increase d up to a point, and then it will <strong>increase</strong> as d is increased, forming a convex curve.</p>
<p><strong>High bias (underfitting)</strong>: both Jtrain(Θ) and JCV(Θ) will be high. Also, JCV(Θ)≈Jtrain(Θ).</p>
<p><strong>High variance (overfitting)</strong>: Jtrain(Θ) will be low and JCV(Θ) will be much greater than Jtrain(Θ).</p>
<p>The is summarized in the figure below:</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1fmk9nubr83j308c073t8s.jpg" alt=""></p>
<h3 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h3><p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1fmk9pevgxgj30jj0ak74u.jpg" alt=""></p>
<p>In the figure above, we see that as $\lambda$ increases, our fit becomes more rigid. On the other hand, as $\lambda$ approaches 0, we tend to over overfit the data. So how do we choose our parameter $\lambda$ to get it ‘just right’ ? In order to choose the model and the regularization term $\lambda$, we need to:</p>
<ol>
<li>Create a list of lambdas (i.e. $\lambda \in {0,0.01,0.02,0.04,0.08,0.16,0.32,0.64,1.28,2.56,5.12,10.24})$;</li>
<li>Create a set of models with different degrees or any other variants.</li>
<li>Iterate through the λs and for each λ go through all the models to learn some  $\theta$  .</li>
<li>Compute the cross validation error using the learned  $\theta$   (computed with λ) on the $J_{CV}(\theta) $  <strong>without</strong> regularization or λ = 0.</li>
<li>Select the best combo that produces the lowest error on the cross validation set.</li>
<li>Using the best combo $\theta$  and λ, apply it on $J_{CV}(\theta) $ to see if it has a good generalization of the problem.</li>
</ol>
<h3 id="Decision"><a href="#Decision" class="headerlink" title="Decision"></a>Decision</h3><p>Our decision process can be broken down as follows:</p>
<ul>
<li><strong>Getting more training examples:</strong> Fixes high variance</li>
</ul>
<ul>
<li><strong>Trying smaller sets of features:</strong> Fixes high variance</li>
</ul>
<ul>
<li><strong>Adding features:</strong> Fixes high bias</li>
</ul>
<ul>
<li><strong>Adding polynomial features:</strong> Fixes high bias</li>
</ul>
<ul>
<li><strong>Decreasing λ:</strong> Fixes high bias</li>
</ul>
<ul>
<li><strong>Increasing λ:</strong> Fixes high variance.</li>
</ul>
<h1 id="Diagnosing-Neural-Networks"><a href="#Diagnosing-Neural-Networks" class="headerlink" title="Diagnosing Neural Networks"></a>Diagnosing Neural Networks</h1><ul>
<li>A neural network with fewer parameters is <strong>prone to underfitting</strong>. It is also <strong>computationally cheaper</strong>.</li>
<li>A large neural network with more parameters is <strong>prone to overfitting</strong>. It is also <strong>computationally expensive</strong>. In this case you can use regularization (increase λ) to address the overfitting.</li>
</ul>
<p>Using a single hidden layer is a good starting default. You can train your neural network on a number of hidden layers using your cross validation set. You can then select the one that performs best. </p>
<blockquote>
<p>网络越大越好，不要因噎废食怕过拟合就用小网络。上大网络加正则化肯定比小网络好，因为大网络加正则化后的损失函数更容易优化到一个更小的局部极值点，对随机初始化的依赖更小。</p>
</blockquote>
<p><strong>Model Complexity Effects:</strong></p>
<ul>
<li>Lower-order polynomials (low model complexity) have high bias and low variance. In this case, the model fits poorly consistently.</li>
<li>Higher-order polynomials (high model complexity) fit the training data extremely well and the test data extremely poorly. These have low bias on the training data, but very high variance.</li>
<li>In reality, we would want to choose a model somewhere in between, that can generalize well but also fits the data reasonably well.</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://www.luodian.ink/2017-12-17/Ng-Cousera-Week-6-Bias-VS-Variance/" data-id="cjeaoysug000jni1ydsuakx1z" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-软件工程-复习总结" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017-12-12/软件工程-复习总结/" class="article-date">
  <time datetime="2017-12-12T11:59:28.000Z" itemprop="datePublished">2017-12-12</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/软件工程/">软件工程</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017-12-12/软件工程-复习总结/">软件工程-复习总结</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="概论"><a href="#概论" class="headerlink" title="概论"></a>概论</h3><p>软件工程：没有严格的数学模型，实践才是最正确的方式，前人只能告诉我们不能怎么做，并不能告诉我们应该怎么做。但是，建立原则，规范，开发者即使偏离，也不会有太多的误差。</p>
<p>只有开发真实可用的软件时，遇到的困难，解决问题的方法，获取的经验才是真实有效的。</p>
<h3 id="过程模型"><a href="#过程模型" class="headerlink" title="过程模型"></a>过程模型</h3><ol>
<li>code-and-fix（泥瓦工式的搭房子，无文档，无测试）</li>
<li>黑盒过程：需求会不断变化，最终结果可能会不容易满意。</li>
<li>白盒过程：开发过程暴露给用户，允许用户拓展和变动，但是用户需求变动可能会导致工作量很大，开发团队效率降低。</li>
<li>瀑布模型：<ul>
<li>每个阶段有明确的文档和产出物；</li>
<li>上一个阶段输出是下一个阶段的输入；</li>
<li>上一个阶段结束下一个阶段才能开始；</li>
</ul>
</li>
<li>增量模型：<ul>
<li><img src="https://ws4.sinaimg.cn/large/006tNc79ly1fmeagde01mj30v60hi0wm.jpg" alt=""></li>
</ul>
</li>
<li>RAD 模型</li>
</ol>
<h3 id="GIT"><a href="#GIT" class="headerlink" title="GIT"></a>GIT</h3><p>文件的三种状态：commited, modified, staged. </p>
<p>基本指令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">git add *// 跟踪文件，放入暂存区，文件处于暂存状态</span><br><span class="line">git commit -m "commit message" // 提交一个版本</span><br><span class="line">git clone url // 从远程仓库拉下分支</span><br><span class="line">git status // 列出当前目录下的文件状态</span><br><span class="line">git diff // 比较的是工作区域当前文件和已经被缓存了的文件的差异</span><br></pre></td></tr></table></figure>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fmf559ardzj31300maqfn.jpg" alt=""></p>
<p><strong>git diff</strong></p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fmf4uysritj30z40m6n78.jpg" alt=""></p>
<p><strong>撤销与回退</strong></p>
<p><img src="https://ws4.sinaimg.cn/large/006tNc79ly1fmf54wm44cj31460kwaqv.jpg" alt=""></p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fmf559ardzj31300maqfn.jpg" alt=""></p>
<p><strong>分支管理</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git fetch // 从远程仓库获取最新的数据</span><br><span class="line">git pull == git fetch + git merge(慎用)</span><br><span class="line">git log -decorate 查看当前各个分支的commit对象</span><br></pre></td></tr></table></figure>
<p>分支切换，暂存区和工作目录文件跟着变动</p>
<p><img src="https://ws4.sinaimg.cn/large/006tNc79ly1fmfb4adjrkj312m0pewhg.jpg" alt=""></p>
<p><strong>git merge 和 rebase</strong></p>
<p><strong>实例</strong></p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fmfbc8espaj313q0o20wj.jpg" alt=""></p>
<h3 id="白盒测试"><a href="#白盒测试" class="headerlink" title="白盒测试"></a>白盒测试</h3><blockquote>
<p>以内部逻辑来进行覆盖测试。</p>
</blockquote>
<p><strong>逻辑测试</strong></p>
<ol>
<li>语句覆盖</li>
<li>判定覆盖</li>
<li>条件覆盖</li>
<li>判定/条件覆盖</li>
<li>条件组合覆盖（主要是在测试条件语句的判定过程）</li>
</ol>
<h3 id="软件架构设计"><a href="#软件架构设计" class="headerlink" title="软件架构设计"></a>软件架构设计</h3><p>设计一个系统，自顶向下我们需要考虑如下的几种选择。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fmgs3ekwyij31a40pgwiz.jpg" alt=""></p>
<p>软件架构四大设计方案</p>
<ol>
<li>异步：层与层之间通过异步调用提升吞吐量。</li>
<li>分层：各层次职责单一，提升可维护性。</li>
<li>缓存：层与层之间通过缓存提高存取效率。</li>
<li>并行：各层内通过分布式提升性能。</li>
</ol>
<h3 id="软件需求"><a href="#软件需求" class="headerlink" title="软件需求"></a>软件需求</h3><blockquote>
<p>并非设计实现方案。</p>
</blockquote>
<ul>
<li>业务需求</li>
<li>用户需求</li>
<li>功能需求（详细软件实现需求）</li>
<li>非功能需求（效率，功能的需求）</li>
</ul>
<h3 id="软件工程前沿"><a href="#软件工程前沿" class="headerlink" title="软件工程前沿"></a>软件工程前沿</h3><h4 id="服务化"><a href="#服务化" class="headerlink" title="服务化"></a>服务化</h4><ul>
<li><p>互联网驱动的IT企业所从事的创新业务。</p>
<ul>
<li>Internet 成为软件运行和软件发布的主体平台。</li>
<li>Apple, Google, Amazon, Facebook.</li>
</ul>
</li>
<li><p>政府及经济学家眼中的一种经济形态。</p>
<ul>
<li>针对特定的服务领域，业务驱动的特征更加明显。</li>
<li>物流，仓储，医疗，教育，交通，金融。</li>
</ul>
</li>
<li><p>新的软件架构和编程范式。</p>
<ul>
<li>从开发角度，软件本身的服务化能够引发新的SE技术。</li>
<li>Web Services, ESB, SaaS</li>
</ul>
</li>
</ul>
<h4 id="面向服务的软件工程"><a href="#面向服务的软件工程" class="headerlink" title="面向服务的软件工程"></a>面向服务的软件工程</h4><ul>
<li><p>Internet 环境下的协同开发。</p>
<ul>
<li>软件外包（高速度，高效率）</li>
<li>开源团队开发（众包平台，群体智慧）</li>
</ul>
</li>
<li><p>集成开发环境（软件全生命周期的管理平台）</p>
<blockquote>
<p>实时高效的协助团队开发流程。</p>
</blockquote>
<ul>
<li>Visual Studio Team Foundation</li>
</ul>
</li>
</ul>
<h3 id="OOA-与-OOD"><a href="#OOA-与-OOD" class="headerlink" title="OOA 与 OOD"></a>OOA 与 OOD</h3><p>用例图的4个基本组件：参与者(Actor)、用例(Use Case)、关系(Relationship)和系统。 </p>
<ul>
<li><p>泛化(generalization)：泛化关系是一种继承关系，子用例将继承基用例的所有行为，关系和通信关系，也就是说在任何使用基用例的地方都可以用子用例来代替。泛化关系在用例图中使用空心的箭头表示，箭头方向从子用例指向基用例。 </p>
</li>
<li><p>扩展(extend)： extend关系是对基用例的扩展，基用例是一个完整的用例，即使没有子用例的参与，也可以完成一个完整的功能。</p>
<p>extend的基用例中将存在一个扩展点，只有当扩展点被激活时，子用例才会被执行。 extend关系在用例图中使用带箭头的虚线表示(在线上标注&lt;<extend>&gt;)，箭头从子用例指向基用例。 </extend></p>
</li>
<li><p>包含(include)： include为包含关系，当两个或多个用例中共用一组相同的动作，这时可以将这组相同的动作抽出来作为一个独立的子用例，供多个基用例所共享。因为子用例被抽出，基用例并非一个完整的用例，所以include关系中的基用例必须和子用例一起使用才够完整，子用例也必然被执行。include关系在用例图中使用带箭头的虚线表示(在线上标注&lt;<include>&gt;)，箭头从基用例指向子用例。</include></p>
</li>
</ul>
<h2 id="讨论题目"><a href="#讨论题目" class="headerlink" title="讨论题目"></a>讨论题目</h2><ol>
<li><p>软件架构的目标</p>
<p>正如同软件本身有其要达到的目标一样，<a href="https://baike.baidu.com/item/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1" target="_blank" rel="noopener">架构设计</a>要达到的目标是什么呢？一般而言，<a href="https://baike.baidu.com/item/%E8%BD%AF%E4%BB%B6%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1" target="_blank" rel="noopener">软件架构设计</a>要达到如下的目标： 可靠性（Reliable）。软件系统对于用户的商业经营和管理来说极为重要，因此软件系统必须非常可靠。 安全性（Secure）。软件系统所承担的交易的商业价值极高，系统的安全性非常重要。 可伸缩性（SCAlable）。软件必须能够在用户的使用率、用户的数目增加很快的情况下，保持合理的性能。只有这样，才能适应用户的市场扩展得可能性。 可定制化（CuSTomizable）。同样的一套软件，可以根据客户群的不同和市场需求的变化进行调整。 可扩展性（Extensible）。在新技术出现的时候，一个软件系统应当允许导入新技术，从而对现有系统进行功能和性能的扩展。 可维护性（MAIntainable）。软件系统的维护包括两方面，一是排除现有的错误，二是将新的<a href="https://baike.baidu.com/item/%E8%BD%AF%E4%BB%B6%E9%9C%80%E6%B1%82" target="_blank" rel="noopener">软件需求</a>反映到现有系统中去。一个易于维护的系统可以有效地降低技术支持的花费。 客户体验（Customer Experience）。<a href="https://baike.baidu.com/item/%E8%BD%AF%E4%BB%B6%E7%B3%BB%E7%BB%9F" target="_blank" rel="noopener">软件系统</a>必须易于使用。 市场时机（Time to Market）。软件用户要面临同业竞争，软件提供商也要面临同业竞争。以最快的速度争夺市场先机非常重要。</p>
</li>
<li><p>黑盒测试的优劣</p>
<p>优点</p>
<ol>
<li>适用于各阶段的测试</li>
<li>从产品功能角度的测试</li>
<li>容易入手生成测试数据</li>
</ol>
<p>缺点</p>
<ol>
<li>某些代码得不到测试</li>
<li>如果规格说明有误则无法发现</li>
<li>不易进行充分性测试</li>
</ol>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://www.luodian.ink/2017-12-12/软件工程-复习总结/" data-id="cjeaoysv6001ini1yysmcs140" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/">__('next') &raquo;</a>
  </nav>
</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Codeforces/">Codeforces</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Kaggle/">Kaggle</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/其余/">其余</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/分布式计算/">分布式计算</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/异常检测/">异常检测</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/投资/">投资</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/操作系统/">操作系统</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/时间序列/">时间序列</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/软件工程/">软件工程</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/量化交易/">量化交易</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/随想/">随想</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/大数据异常检测/">大数据异常检测</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/机器学习/">机器学习</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/大数据异常检测/" style="font-size: 10px;">大数据异常检测</a> <a href="/tags/机器学习/" style="font-size: 20px;">机器学习</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">三月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">一月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">十二月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">十一月 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018-03-01/2018-MetaTrade-网格交易简述/">MetaTrader-网格交易简述</a>
          </li>
        
          <li>
            <a href="/2018-01-24/Contest-911-D-Inversion-Counting/">Contest-911-D-Inversion Counting</a>
          </li>
        
          <li>
            <a href="/2017-12-29/基于统计方法进行时序数据预测的异常检测模型/">基于统计方法进行时序数据预测的异常检测模型</a>
          </li>
        
          <li>
            <a href="/2017-12-27/数据之美-时间序列分析/">数据之美-时间序列分析</a>
          </li>
        
          <li>
            <a href="/2017-12-27/股票技术资料/">股票技术资料</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 Luodian<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>