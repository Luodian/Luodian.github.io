<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>Luodian.ink</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Luodian.ink">
<meta property="og:url" content="https://www.luodian.ink/page/3/index.html">
<meta property="og:site_name" content="Luodian.ink">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Luodian.ink">
  
    <link rel="alternate" href="/atom.xml" title="Luodian.ink" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  

</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Luodian.ink</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://www.luodian.ink"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-机器学习-第二章-概率" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017-11-25/机器学习-第二章-概率/" class="article-date">
  <time datetime="2017-11-25T02:22:10.000Z" itemprop="datePublished">2017-11-25</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017-11-25/机器学习-第二章-概率/">机器学习复习-第二章-概率</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="几个公式"><a href="#几个公式" class="headerlink" title="几个公式"></a>几个公式</h3><ul>
<li>贝叶斯公式：$P(B \mid A) = \frac{P(B)  \cdot  P(A \mid B)}{P(A)}$</li>
<li>全概率公式：$P(A) = \Sigma_{n} P(A \mid B_n) \cdot P(B_n)$.</li>
</ul>
<h3 id="生成模型与判别模型"><a href="#生成模型与判别模型" class="headerlink" title="生成模型与判别模型"></a>生成模型与判别模型</h3><p>监督学习的任务就是学习一个模型，应用这一模型，对给定的输入预测相应的输出，这个模型的一般形式为决策函数：$Y = f(x)$，或者条件概率分布：$P(Y \mid X)$</p>
<p>监督学习方法又可以分为生成方法（Generative Approach）和判别方法（Discriminative Approach），所学习到的模型分别称为生成模型和判别模型。</p>
<h4 id="生成方法"><a href="#生成方法" class="headerlink" title="生成方法"></a><strong>生成方法</strong></h4><p>生成方法由数据学习联合概率分布 $P(X,Y)$，然后求出条件概率分布 $P(Y \mid X)$ 作为预测的模型.</p>
<p>即生成模型：$P(Y \mid X) = \frac{P(X,Y)}{P(X)}$</p>
<p>这样的方法之所以称为生成方法，是因为模型表示了给定输入 $X$ 产生输出 $Y$ 的生成关系，典型的生成模型有：朴素贝叶斯方法和隐马尔科夫模型。</p>
<h4 id="判别方法"><a href="#判别方法" class="headerlink" title="判别方法"></a><strong>判别方法</strong></h4><p>判别方法由数据直接学习决策函数 $f(X)$ 或者条件概率分布 $P(Y \mid X)$ 作为预测的模型，即判别模型。判别方法关心的是对给定的输入 $X$，应该预测什么样的输出 $Y$。典型的判别模型包括：$k$ 近邻法，感知机，决策树，逻辑斯蒂回归模型，最大熵模型，支持向量机，提升方法和条件随机场等。</p>
<h4 id="评价分类指标"><a href="#评价分类指标" class="headerlink" title="评价分类指标"></a>评价分类指标</h4><p><strong>准确率（accuracy）</strong></p>
<p><strong>精确率（precision）</strong></p>
<p><strong>召回率（recall）</strong></p>
<h3 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h3><p>医生对病人进行诊断就是一个典型的分类过程，任何一个医生都无法直接看到病人的病情，只能观察病人表现出的症状和各种化验检测数据来推断病情，这时医生就好比一个分类器，而这个医生诊断的准确率，与他当初受到的教育方式（构造方法）、病人的症状是否突出（待分类数据的特性）以及医生的经验多少（训练样本数量）都有密切关系。</p>
<p>回忆朴素贝叶斯中的公式 $P(Y = y_k \mid X_1,X_2,\ldots X_n) = \frac{P(Y = y_k)\prod_i P(X_i \mid Y = y_k)}{\Sigma_j ( P(Y = y_j)\prod_i P(X_i \mid Y = y_j))}$</p>
<p>对比与医生看病，就是医生利用他已知的发病的征兆，结合病人的征兆去获取这个 $\prod_i P(X_i \mid Y = y_k)$，然后再结合发病的概率，去推断病人现在身上的征兆，有多大的可能发病。</p>
<p>朴素贝叶斯学习和分类器与其他相比可以非常快。在条件独立的假设下，类条件特征分布的解耦意味着 每个分布可以独立估计为一个一维分布，这反过来又有助于缓解维灾难问题。</p>
<p><strong>高斯朴素贝叶斯的训练过程</strong></p>
<ul>
<li><p>训练：对于每个 $y_k$：</p>
<ol>
<li>估计 $\pi_k (即P(Y = y_k))$</li>
<li>对于 $X$ 的每一个属性 $X_i$，估计类条件均值和方差 $\mu_{i,k},\sigma_{i,k}$.</li>
</ol>
</li>
<li><p>分类：</p>
<ol>
<li><p>$Y_{new} \leftarrow argmax_{y_k} \prod_i {P(X^{new}_i \mid Y = y_k)}$</p>
</li>
<li><p>$Y_{new} \leftarrow argmax_{y_k} \pi_k \prod_i N(X^{new}_i,\mu_{i,k},\sigma_{i,k}) $</p>
</li>
<li><p>对于均值和方差的计算如下：</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1flvkhkdjluj315o0m20wb.jpg" alt=""><strong>一些问题</strong></p>
<ol>
<li>怎么对两组数据进行独立性检验？<ul>
<li>皮尔森卡方检验</li>
</ul>
</li>
<li>标准的朴素贝叶斯分类器的决策面看起来是什么样的？<ul>
<li>对于高斯分布的话，如果两个类的协方差相同，决策面是线性的超平面</li>
</ul>
</li>
</ol>
</li>
</ol>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://www.luodian.ink/2017-11-25/机器学习-第二章-概率/" data-id="cjeaozqd60015pi1yj28v1ao1" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-机器学习-第一章-决策树" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017-11-24/机器学习-第一章-决策树/" class="article-date">
  <time datetime="2017-11-24T11:00:13.000Z" itemprop="datePublished">2017-11-24</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017-11-24/机器学习-第一章-决策树/">机器学习复习-第一章-决策树（Updating）</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>在这里我记录下在学习决策树之后，我自己的思考以及重点，不会包含太多介绍性的内容。</p>
<p>新手入门的话推荐周志华的《机器学习》和李航的《统计学习方法》。</p>
<h3 id="信息熵，基尼系数，分类误差定义"><a href="#信息熵，基尼系数，分类误差定义" class="headerlink" title="信息熵，基尼系数，分类误差定义"></a>信息熵，基尼系数，分类误差定义</h3><h3 id="关于过拟合"><a href="#关于过拟合" class="headerlink" title="关于过拟合"></a>关于过拟合</h3><p>决策树十分容易产生<strong>过拟合</strong>的情况，也就是说当前的决策树有很多的节点，整个决策树很大，此时会把样本中一些并不需要拿来作为分类的属性学习到，因此学习的决策树模型并不是最优的模型，这就是机器学习中的过拟合现象，与此相关的概念就是欠拟合，欠拟合主要是因为当前的样本不够，导致实际在学习的时候可以用来学习的信息很少，因此也会出现学习不好的现象。</p>
<h3 id="预处理（Pre-Prunning）"><a href="#预处理（Pre-Prunning）" class="headerlink" title="预处理（Pre-Prunning）"></a>预处理（Pre-Prunning）</h3><ol>
<li>在树已经成长成为完全树之后停止算法。</li>
<li>对于结点的剪枝规则<ul>
<li>当所有类可以被分到一个类别时。</li>
<li>当某些类别的数量小于用户设定的阈值。</li>
<li>当某个结点并不能带来显著（高于阈值）的基尼系数（这里可以参考CART算法）或者信息熵的增长时。</li>
</ul>
</li>
</ol>
<h3 id="后处理（Post-Prunning）"><a href="#后处理（Post-Prunning）" class="headerlink" title="后处理（Post-Prunning）"></a>后处理（Post-Prunning）</h3><p>使用MDL的思想，对于决策树自底向上逐层扫描剪枝。</p>
<p>注意预剪枝和后剪枝都可以使用验证集作为是否分裂的标准，与决策树的构建先后无关。<br>但两者所获得的结果是有区别的，往往后剪枝获得的决策树要比预剪枝获得的大，且欠拟合风险很小，泛化性能往往更优，但毫无疑问的是，后剪枝的开销更大。</p>
<h3 id="斜决策树"><a href="#斜决策树" class="headerlink" title="斜决策树"></a>斜决策树</h3><p>单变量决策树的每个节点都是使用一个属性，这样生成的决策树如果用坐标空间来刻画（属性即坐标轴），划分的边界都是平行于坐标轴的。 但有时候单一的属性很难刻画分类的边缘，会造成抖动，而这个抖动只需要一条斜边就可以很好的解决了，其实所谓的斜边就是属性的线性组合，即节点使用多个属性的线性表达式来作为评判标准。</p>
<h3 id="缺失值"><a href="#缺失值" class="headerlink" title="缺失值"></a>缺失值</h3><p>对于缺失值需要考虑两个问题： </p>
<ol>
<li><p>样本集属性缺失，如何根据缺失的属性来选择划分节点？</p>
<p>在不做缺失值填充的情况下，显然只能使用在该节点没有确实值的子样本集进行计算，然后信息增益的计算最后需要乘上一个不缺失系数（即该节点不缺失的样本集数与总样本的比） 。</p>
<p>假如你使用 ID3 算法，那么选择分类属性时，就要计算所有属性的熵增(信息增益，Gain)。假设10个样本，属性是 $a,b,c$。在计算 $a$ 属性熵时发现，第10个样本的 $a$ 属性缺失，那么就把第10个样本去掉，前9个样本组成新的样本集，在新样本集上按正常方法计算 $a$ 属性的熵增。然后结果乘 0.9（新样本占raw样本的比例），就是 $a$ 属性最终的熵。</p>
<p>这里给出一个课程 handouts 中的图示。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fltohlpn1aj315o0pmgwf.jpg" alt=""></p>
</li>
<li><p>预测集属性缺失 </p>
<p>若预测时，某个属性缺失，则以一定概率将该样本划分到该节点的各个取值中。至于这个概率如何选取，参考资料决策树是如何处理不完整数据的？</p>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://www.luodian.ink/2017-11-24/机器学习-第一章-决策树/" data-id="cjeaozqd10010pi1y2ey4s43g" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-11-24-异常检测周报" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017-11-24/11-24-异常检测周报/" class="article-date">
  <time datetime="2017-11-23T18:54:39.000Z" itemprop="datePublished">2017-11-24</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/异常检测/">异常检测</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017-11-24/11-24-异常检测周报/">11-24-异常检测周报</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>这周的工作主要有了两个方向的进展，下面的报告分以下两个方面阐述。</p>
<h3 id="一、异常点的识别"><a href="#一、异常点的识别" class="headerlink" title="一、异常点的识别"></a><strong>一、异常点的识别</strong></h3><p>首先要解释下，其实单一维度和多维度异常点识别可以看成是两类异常情况的识别，并不能简单的将单一维度看成是多维度的简化版本，对于我们手里的这组传感器数据，理性的思考，多维度的异常其实并不容易发生，很多时候其实就只是某个传感器的数据出了问题，但是我们利用多维的异常检测，比如iforest，DBSCAN聚类去扫描的方法，其实是不容易看出这点异常的，而且也有可能存在，本来就是单点异常，但是我们却把这个时段的所有点标记成异常，导致可能工人需要去检查所有的传感器，这样实际操作中费时费力且算法层面并不高效（iforest还好，但是DBSCAN最少都是nlogn的）。</p>
<p>因此目前我认为，不能先入为主的拿多维去做异常检测，而是首先对单一维度做异常的检测，也可以对多个强相关的维度进行协同检测。</p>
<p>下面首先讲述下我对于单一维度异常检测的一些思考和实验结果。</p>
<ol>
<li><p><strong>单一维度：差分方法</strong></p>
<p><strong>思路</strong></p>
<p>利用多阶段的差分，我们可以识别出单点以及模式的异常。这个idea来自于梯度，当函数突然出现了一个异常的峰值点，或者是出现了突然地连续下降时，这个点的领域的梯度一定是有别于周围的其他点的，但是对于求区间的梯度（或者是斜率），我们首先要知道我们怎么去划分这个区间，但是这个区间的长度却会因数据的变化而动态变化（注意这里跟周期不是一个概念，虽然周期也是动态变化的），我们不容易确定这个值，因此我们选择利用差分，我们初始的差分可以从前后两个点开始，然后逐渐的调整差分的参数（实际上也就是去动态的找这个区间），显然单点异常一定会在差分之后的结果中突出出来，而模式的的异常，我们在增加差分的区间长度之后，也会显示出来。</p>
<p>下面的图中，第一行是原始数据，第二行是diff(1)的结果，第二行是diff(100)的结果。</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1flsjizl61rj31kw0ub7a8.jpg" alt="Figure_2"></p>
<p>从图中可以看出在diff（1）的时候，已经可以看出异常点了，而在diff（100）的时候，我们成功的检测到了梯度的突然下降。</p>
<p>再回到差分这个方法，虽然这个思想简单，比不得高大上的其他机器学习算法，但是目前这是我能够想到的效果不错，且效率最高的算法，因为这是一个在线的算法，它不需要累计一段时间的数据然后统一的进行处理（我使用过isolation forest和lof，效果不如差分好，且它们并不能实时的计算），我们可以部署到传感器上，自己就能轻松的实现报警。</p>
<p><strong>还需改进的地方</strong></p>
<p>目前差分对于简单异常点的识别非常暴力且轻松，但是对于比如某个区间梯度突然地变化这种异常情况，会比较依赖于差分参数的选择，而这个差分参数怎么自动化调整，是一个需要进一步解决的问题，我也在思考，目前有些思路比如『每个点统计前后n个点的均值方差，然后判断这个点究竟是需要进行一阶差分还是需要更高阶的差分』，这些思路其实也可以和聚类结合起来，因为最终我们的目的是<strong>去识别出函数断层的地方！</strong>，能够实现这个，我们的异常检测就能够粗略的达到了要求。</p>
</li>
<li><p><strong>多维协同：孤立森林方法</strong></p>
<p>这个方法对于单维数据，我并不推荐，我认为它的用处可以用作多维协同（多维一定要选取强相关的维度，否则一定会出错，而自动判定维度之间是否强相关是一个复杂度很高的问题！）的异常检测，这里我就不再赘述。</p>
</li>
</ol>
<h3 id="二、异常模式的识别"><a href="#二、异常模式的识别" class="headerlink" title="二、异常模式的识别"></a>二、异常模式的识别</h3><p>首先也需要解释，我对于异常模式识别的理解，首先我们的目标是要识别出正常的模式，然后有别于这种模式的其他段就是异常。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1flsjky0cjrj31640gygno.jpg" alt="187EB725735840F8C13A1C65EA598139"></p>
<p>​        </p>
<p>而识别正常模式的第一个阶段，我认为需要去对总的数据进行分类（不能拿整体数据进行模式的识别），对于上面的数据，如果我们能够大致的判断出其中包括了三类区间，就能够用神经网络（LSTM）对小区间的模式进行识别，那么我们针对于这种情况，能够想到的只有聚类这个方式。目前常用的聚类方法我认为可行的只有K-Means和DBSCAN，下面分别对这两种方法进行说明。</p>
<ol>
<li><p><strong>K-Means</strong></p>
<p>对于kmeans其实效果都还挺好，但是这个方法的局限性在于我们需要为我们的数据指定固定的cluster的个数。</p>
<p>下面是对15，16，17，18列的数据进行协同的模式分析（这里也要说明，如果要对多维数据协同分析，一定要利用先验知识或者是互相的拟合关系说明他们是强相关的，在下面的四组数据中实际上我为了观察聚类效果能否将其他维度的非模式段拉到本维度的正常模式，而放松了这个界限）</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1flsjltrz88j31hc140dm2.jpg" alt="k-means-cluster5-with-time"></p>
</li>
<li><p><strong>DBSCAN</strong></p>
<p>DBSCAN相比如K-MEANS最具有优势的两点在于，其一，其不用指定数据的聚类，其二，其可以对于非凸的cluster进行较好的聚类，大致效果就是这个意思。</p>
<div align="center">![这里写图片描述](https://ws4.sinaimg.cn/large/006tKfTcly1flsjmxbcr4j309b0l1djr.jpg)</div>

<p>显然DBSCAN聚类的效果才是我们希望达到的目标，但是需要注意的是，这里的eps的选取对聚类效果影响很    大，同样这里也是影响到我对于windmachine数据测试的聚类效果一大关键的点。</p>
<p>在我调整参数的过程中出现了两个极端的情况。</p>
<p>第一种则是所有数据聚成一类</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1flsjnqw423j31kw16otng.jpg" alt="dbscan"></p>
<p>第二种情况则是算法自动将1000多个点分为了700多个类，效果五彩斑斓</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1flsjnzbp7gj31kw0ub78c.jpg" alt="Figure_2"></p>
<p>目前这个问题还没有解决，但是我有两个还没有实验的想法。</p>
<ol>
<li>我推测是没有正确的使用时间这个属性，权重？或者是对于已知异常点动态的加入参数。</li>
<li>对于1000个点分为了700类的情况，在图中实际可以看出类与类之间也有相似度的区别（从颜色就可以看出来），那么再对这个类的质心进行一次聚类，是否可以能够划分为更少的大类？</li>
</ol>
<p>后者方法其实我认为非常可行与可解，最近时间比较紧凑，但是我会尽快去做相应的尝试。</p>
</li>
</ol>
<ol>
<li><p><strong>聚类之后</strong></p>
<p>说完了聚类之后，那么对于较小区间的模式识别其实已经是有了现成的方法（但是时间复杂度很高，因此我们必须要尽可能多的去进行区间的识别，去划分有可能存在周期函数的区间出来再往上并行的套神经网络，不能对所有的层都做一遍线性的神经网络，复杂度太高了！）</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1flsjwmvzi7j31kw0ubq8a.jpg" alt="Figure_1"></p>
<p>如上图，我使用周期函数加了高斯噪声，并在中间这个地方加入了人工的异常点，进行了一组测试，LSTM是可以找出异常的模式并加以权重十分高的Error，我认为这个效果非常的好，所以我们只要能打通聚类的那一步，我认为对于区间函数下异常模式，其实是可以很好解决的。</p>
</li>
</ol>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ol>
<li><strong>差分</strong>目前主要的问题在于需要去细化差分的参数，使其不仅能够找出异常点，而也能够对区间的异常有一定的检测作用，这方面得去看一些金融时间序列的东西，希望能够从统计这里得到一些信息。</li>
<li>对于聚类，目前认为DBSCAN以及其各种改进，比如OPTICS，SNN是一些较好的方法，但是聚类我认为应该结合具有相关性的几个维度去做，然后做模式的区分，目前使用K-Means已经有了一个较可观的实现，希望能够有一定的效果。</li>
<li>我之后的方向是希望去细化研究上述1，2点，能够通过对DBSCAN的细化研究，希望能够将DBSCAN在特定的数据集上做一些自己的优化，然后还能够研究下DBSCAN在时间序列下的更适配的应用（要注意时间序列的时间这一维特性，是否完全不用？我认为不行，但是要怎么用，我也不太清楚）</li>
<li>LSTM是否是唯一最好的用于这种区间函数下异常模式识别的方法？我对神经网络了解的不多，我不太清楚，还需要请教一些高人。</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://www.luodian.ink/2017-11-24/11-24-异常检测周报/" data-id="cjeaozqbe0000pi1ybgyd5d8n" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/大数据异常检测/">大数据异常检测</a></li></ul>

    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    <a class="extend prev" rel="prev" href="/page/2/">&laquo; __('prev')</a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span>
  </nav>
</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Codeforces/">Codeforces</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Kaggle/">Kaggle</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/其余/">其余</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/分布式计算/">分布式计算</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/异常检测/">异常检测</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/时间序列/">时间序列</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/量化交易/">量化交易</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/随想/">随想</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/大数据异常检测/">大数据异常检测</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/机器学习/">机器学习</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/大数据异常检测/" style="font-size: 10px;">大数据异常检测</a> <a href="/tags/机器学习/" style="font-size: 20px;">机器学习</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">三月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">一月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">十二月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">十一月 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018-03-01/2018-MetaTrade-网格交易简述/">MetaTrader-网格交易简述</a>
          </li>
        
          <li>
            <a href="/2018-01-24/Contest-911-D-Inversion-Counting/">Contest-911-D-Inversion Counting</a>
          </li>
        
          <li>
            <a href="/2017-12-29/基于统计方法进行时序数据预测的异常检测模型/">基于统计方法进行时序数据预测的异常检测模型</a>
          </li>
        
          <li>
            <a href="/2017-12-27/数据之美-时间序列分析/">数据之美-时间序列分析</a>
          </li>
        
          <li>
            <a href="/2017-12-24/17周周报-使用Holt-Winters模型通过比对预测值进行异常检测/">17周周报-使用Holt-Winters模型通过比对预测值进行异常检测</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 Luodian<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>