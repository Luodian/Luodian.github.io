<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>Luodian.ink</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Luodian.ink">
<meta property="og:url" content="https://www.luodian.ink/page/3/index.html">
<meta property="og:site_name" content="Luodian.ink">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Luodian.ink">
  
    <link rel="alternate" href="/atom.xml" title="Luodian.ink" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  

</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Luodian.ink</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://www.luodian.ink"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-随想-同谋（Complicit）" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017-12-01/随想-同谋（Complicit）/" class="article-date">
  <time datetime="2017-12-01T04:56:53.000Z" itemprop="datePublished">2017-12-01</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/随想/">随想</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017-12-01/随想-同谋（Complicit）/">随想-同谋（Complicit）</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="2017年度词汇-——-同谋"><a href="#2017年度词汇-——-同谋" class="headerlink" title="2017年度词汇 —— 同谋"></a>2017年度词汇 —— 同谋</h2><blockquote>
<p>“ 2017 年度词汇：同谋（Complicit）” —— dictionary.com</p>
</blockquote>
<p>这个词的来源是：</p>
<ul>
<li>4月5日，美国总统特朗普的女儿伊万卡· 特朗普接受《CBS 今晨秀》采访时，被问到她与丈夫是否是特朗普总统的同谋，她回答说 『我不知道同谋是什么意思』。</li>
<li>10月24日，参议员杰夫·弗莱克宣布辞职，并表示『我不会成为共谋』。</li>
</ul>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1fm16ktlqv3j310g0pdq4h.jpg" alt=""></p>
<p>Dictionary.com 在公布年度词汇时表示</p>
<blockquote>
<p>我们所选择的年度词汇既指那些看得见的行为，也指看些看不见的行为。这个词汇提醒我们，即使不作为也是一种行动。沉默地接受了错误的行为，是我们落到这般境地的原因。我们不能让这种情况继续变成一种常态。如果我们这样做，我们都是共谋。</p>
</blockquote>
<p>用一种更通俗的话来讲，或许它在表达：人们越来越沉浸在社交网络的娱乐氛围当中，缺少对时事的严肃讨论和关切，人们倾向于看到事情更让滑稽，更戏剧性，或者说更愿意让自己相信的那一面，而沉默或者是不理智的发声，有时候也是错误的帮凶。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://www.luodian.ink/2017-12-01/随想-同谋（Complicit）/" data-id="cjeaokidn0024f51y5weeidzz" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-操作系统-内存" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017-11-30/操作系统-内存/" class="article-date">
  <time datetime="2017-11-30T02:37:08.000Z" itemprop="datePublished">2017-11-30</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/操作系统/">操作系统</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017-11-30/操作系统-内存/">操作系统-内存管理</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="重要概念"><a href="#重要概念" class="headerlink" title="重要概念"></a>重要概念</h3><p><strong>虚拟地址</strong>：用户编程时将代码（或数据）分为若干个段，每条代码或每个数据的地址由段名称+段内相对地址构成，这样的程序地址称为虚拟地址。</p>
<p><strong>逻辑地址</strong>：虚拟地址中，段内相对地址部分称为逻辑地址。</p>
<p><strong>物理地址</strong>：实际物理内存中所看到的存储地址称为物理地址。</p>
<blockquote>
<p>比较：虚拟地址由用户编写程序时定义的全局地址；逻辑地址是用户定义的局部地址，是虚拟地址的组成部分；物理地址就是实际存在的以Byte为单位的存储单元的编号。</p>
</blockquote>
<p><strong>逻辑地址空间</strong>：在实际应用中，将虚拟地址和逻辑地址经常不加区分，通称为逻辑地址。逻辑地址的集合称为逻辑地址空间。</p>
<p><strong>线性地址空间</strong>：CPU地址总线可以访问的所有地址空间。</p>
<p><strong>物理地址空间</strong>：实际存在的可访问的物理内存地址集合称为物理地址空间。</p>
<p><strong>MMU（内存管理单元）</strong>：</p>
<p>实现将用户程序的虚拟地址（逻辑地址）映射到物理地址的CPU中的硬件电路。</p>
<p><strong>基地址</strong>：</p>
<p>在进行地址映射时，经常以段或页为单位并以其最小地址（即起始地址）为基值来进行计算。</p>
<p><strong>偏移量</strong>：</p>
<p>在以段或页为单位进行地址映射时，相对于基地址的地址值。</p>
<h3 id="碎片"><a href="#碎片" class="headerlink" title="碎片"></a>碎片</h3><p>在以段或页为单位进行地址映射时，相对于基地址的地址值。</p>
<p><strong>外部碎片</strong>：随着进程不断的装入和移出，对分区不断的分割，使得内存中产生许多特别小的分区，它们并不连续可用。</p>
<p><strong>内部碎片</strong>：对固定分区来说，只要分区被分配给某进程使用，其中并未占用的空间不能分给其他进程。</p>
<blockquote>
<p>可以使用内存紧缩解决碎片的问题，其操作在于将被占用的空间移动到一起，将剩余空间空出来。</p>
</blockquote>
<h3 id="分段"><a href="#分段" class="headerlink" title="分段"></a>分段</h3><p>提供用户视角的内存管理方案，逻辑地址空间有一组段组成。每个段都有名称和长度，地址指定了段名称和段内偏移。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;segment-number,offset&gt;</span><br></pre></td></tr></table></figure>
<p>通常，一个C编译器程序会创建如下段：</p>
<ol>
<li>代码。</li>
<li>全局变量。</li>
<li>堆。</li>
<li>每个线程采用的栈。</li>
<li>标准的C库函数。</li>
</ol>
<h4 id="Intel-X86的分段硬件"><a href="#Intel-X86的分段硬件" class="headerlink" title="Intel X86的分段硬件"></a>Intel X86的分段硬件</h4><p>call/jmp selector : offset</p>
<p>code segment description 最终会加载到CS寄存器里。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://www.luodian.ink/2017-11-30/操作系统-内存/" data-id="cjeaokich000vf51y9ut4toah" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-天算计划-Ubuntu-Spark组网计划配置操作" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017-11-30/天算计划-Ubuntu-Spark组网计划配置操作/" class="article-date">
  <time datetime="2017-11-29T16:26:51.000Z" itemprop="datePublished">2017-11-30</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/分布式计算/">分布式计算</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017-11-30/天算计划-Ubuntu-Spark组网计划配置操作/">天算计划-Ubuntu-Spark组网计划配置操作</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>记录下组内环境的配置流程，目前我们需要实现五个人在Ubuntu环境下的Hadoop+Spark配置，配置流程如下。</p>
<h3 id="SSH无密码互联"><a href="#SSH无密码互联" class="headerlink" title="SSH无密码互联"></a>SSH无密码互联</h3><ol>
<li>使用<code>ssh-keygen -t rsa -P &quot;&quot;</code> 命令生成公钥，表示生成的公钥不含登录密码，只要A机器拿到B的公钥就可以实现 A 机器无密码登录 B 机器。</li>
<li><code>cd $HOME/.ssh</code>目录下，使用<code>cat $HOME/.ssh/id_rsa.pub &gt;&gt; $HOME/.ssh/authorized_keys</code> 命令或者直接将<code>id_rsa.pub</code>中的最后一行复制到<code>authorized_keys</code>当中。</li>
<li>最终保证五个人的电脑的中都有一份相同<code>authorized_keys</code>文件是最好的，这样就可以实现无密码登陆了（第一次可能需要输密码，这里建议咱们先都设置成12345678，方便实验）。</li>
<li>两个人之间测试能否通过当前的内网IP互相登录，如<code>elrond@master</code>这种格式，使用<code>ssh &#39;inet IP&#39;@master</code>登录 elrond 的机器。</li>
</ol>
<p><strong>错误收集</strong></p>
<ol>
<li><p>如果遇到<code>sign_and_send_pubkey: signing failed: agent refused operation</code>的错误，原因是因为ssh-agent并没有真正的工作，输入下列命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">eval `ssh-agent -s` </span><br><span class="line">ssh-add</span><br></pre></td></tr></table></figure>
<p>​</p>
</li>
</ol>
<h3 id="统一化HOSTNAME"><a href="#统一化HOSTNAME" class="headerlink" title="统一化HOSTNAME"></a>统一化HOSTNAME</h3><ol>
<li><p>对于不同的电脑有可能有不同的用户名，我们这里针对于hadoop统一设置一下我们每个人的用户名。</p>
<p>为了更好的在Shell中区分三台主机，修改其显示的主机名，执行如下命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/hostname</span><br></pre></td></tr></table></figure>
<p>master的/etc/hostname添加如下配置：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">master</span><br></pre></td></tr></table></figure>
<p>同样slave01的/etc/hostname添加如下配置：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">slave01</span><br></pre></td></tr></table></figure>
<p>同样slave02的/etc/hostname添加如下配置：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">slave02</span><br></pre></td></tr></table></figure>
<p>重启三台电脑，重启后在终端Shell中才会看到机器名的变化,如下图：</p>
<p><img src="http://7xjnip.com1.z0.glb.clouddn.com/20161205_005.png" alt="img"></p>
</li>
<li><p>到<code>/etc/hosts</code>路径下修改<code>ip - 缩写</code>，如当前阿臻是<code>master</code>用户，那么我在<code>hosts</code>下面加入了<code>172.20.0.39   master</code>这行语句之后，我再使用<code>ping master</code>实际上是<code>ping 172.20.0.39</code> 。</p>
<p>因此我们最好把<code>hosts</code>文件修改为如下的形式：</p>
<p>使用</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/hosts</span><br></pre></td></tr></table></figure>
<p>配置如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1 localhost</span><br><span class="line">172.20.0.39 master</span><br><span class="line">172.20.0.38 slave01</span><br><span class="line">172.20.0.37 slave02</span><br></pre></td></tr></table></figure>
<p>然后master需要修改~/.ssh/config文件，如果没有此文件，自己创建文件。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Host master</span><br><span class="line">  user elrond // 阿臻的电脑</span><br><span class="line">Host slave01</span><br><span class="line">  user hadoop // 丹丹的电脑</span><br><span class="line">Host slave02</span><br><span class="line">  user yuhongzhong  // 宇宏的电脑</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注：这里的user和host对应的是命令行下的elrond@master，等于在master主机下的elrond用户。</p>
</blockquote>
<p>这时我们尝试下面操作，应该就能登录到丹丹的电脑上了。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh slave01</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="Hadoop配置"><a href="#Hadoop配置" class="headerlink" title="Hadoop配置"></a>Hadoop配置</h3><ol>
<li><p>修改master主机修改Hadoop如下配置文件，这些配置文件都位于/usr/local/hadoop/etc/hadoop目录下。</p>
<ol>
<li><p>slaves<br>这里把DataNode的主机名写入该文件，每行一个。这里让master节点主机仅作为NameNode使用。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">slave01</span><br><span class="line">slave02</span><br></pre></td></tr></table></figure>
</li>
<li><p>core-site.xml</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;file:/usr/local/hadoop/tmp&lt;/value&gt;</span><br><span class="line">        &lt;description&gt;Abase for other temporary directories.&lt;/description&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hdfs://master:9000&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>hdfs-site.xml</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">      &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;3&lt;/value&gt; //注：这里只能是奇数，代表当前允许的datanode个数，即slaver个数。</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>mapred-site.xml(复制mapred-site.xml.template,再修改文件名)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">      &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>yarn-site.xml</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;!-- Site specific YARN configuration properties --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;master&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
<li><p>此时阿臻的电脑上 /usr/local 文件夹下面有一个hadoop.tar文件，我们使用<code>scp</code>指令将其传送到其他的slave结点上。</p>
<p>如传送到宇宏的电脑，我们使用：<code>scp hadoop.tar slave02:/usr/local</code>，传送之前要保证宇宏执行了了<code>sudo chmod 777 /usr/local/</code>。</p>
</li>
<li><p>传送完毕文件之后（丹丹和宇宏的电脑都已经有了），解压，在 slave01，slave02 节点上执行 <code>sudo chown -R hadoop /usr/local/hadoop</code>，以保证 master 有权限去修改 slaver 的这个目录。</p>
</li>
<li><p>在 master 主机上执行如下命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/hadoop</span><br><span class="line">bin/hdfs namenode -format</span><br><span class="line">sbin/start-dfs.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p>运行过程中理论上不应该输入密码，如果要输入密码，重回 SSH 的步骤，检查 SSH 是否能够相互无密码登录。</p>
<ul>
<li><p>理论情形如下：</p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1flzx9vlmytj30zq071go1.jpg" alt="img"></p>
</li>
<li><p>我们通过浏览器来查看整个集群的HDFS状态，地址为：<a href="http://172.20.0.39（master的内网IP）:50070/dfshealth.html#tab-overview" target="_blank" rel="noopener">http://172.20.0.39（master的内网IP）:50070/dfshealth.html#tab-overview</a></p>
<p><img src="https://ws4.sinaimg.cn/large/006tNc79ly1flzhf07xmuj30wp0aumxu.jpg" alt="img"></p>
</li>
</ul>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://www.luodian.ink/2017-11-30/天算计划-Ubuntu-Spark组网计划配置操作/" data-id="cjeaokicd000qf51y0h2hfz0u" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-11-29-异常检测周报" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017-11-29/11-29-异常检测周报/" class="article-date">
  <time datetime="2017-11-29T01:31:39.000Z" itemprop="datePublished">2017-11-29</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/异常检测/">异常检测</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017-11-29/11-29-异常检测周报/">11-29-异常检测周报</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>这周因为机器学习的考试和软工课的一些其他事情。</p>
<p>我还没有进行我的计划：对于DBSCAN针对于时间序列数据的代码级别改进，但是从思路上考虑到了一些方向，下面主要结合这段时间对于这个问题的思考以及一切实验来进行汇报。</p>
<h2 id="数据平滑之后的结果"><a href="#数据平滑之后的结果" class="headerlink" title="数据平滑之后的结果"></a>数据平滑之后的结果</h2><p>首先我考虑对数据集进行平滑处理，目前能够使用的是如窗口移动平均这类做法，这类做法的时间复杂度为 $O(N)$ ，常数较大，但是复杂度在可以接受的返回值内。</p>
<p>平滑的目的是将工业中因为传感器误差而引入的背景噪声消除，在平滑了曲线后我再使用差分的方法找出局部的最大最小值，效果更为理想（注意在演示中因为使用的数据太大，太密，导致了我们没有办法很好的细粒度的展示）</p>
<p>平滑的含义如下：</p>
<p align="center">
<img src="http://www.redpoppet.com/wp-content/uploads/2016/05/figure_2_thumb.png">
</p>

<p>在平滑之后的数据，使用差分标记可能的异常值（红点里标记的为局部的最大最小值，我们通过让用户设置阈值，规定差距大于 $\epsilon$ 时，我们检测这个异常值，可以实现针对不同类型的传感器数据报出异常）。</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1flyw2mhb45j31hc140q62.jpg" alt=""></p>
<p>对差分之后的结果进行 K-means和DBSCAN聚类的结果分别如下。</p>
<p>K-MEANS的效果：</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1flyw6x0zc3j31hc140grp.jpg" alt=""></p>
<p>但是很可惜的是，K-MEANS的效果是基于空间的聚类，经过更大规模数据的观察，显然它是更多的在根据Y轴坐标进行聚类的划分。</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1flywen9hd7j31hc140adh.jpg" alt=""></p>
<p>以下是DBSCAN的效果，DBSCAN能够识别出数据大的模式的转化，下一步我打算在红点处加重权值 minEps，希望能够成功的使用DBSCAN进行模式的划分。</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1flywc8z89rj31hc14045m.jpg" alt=""></p>
<h3 id="MRDBSCAN"><a href="#MRDBSCAN" class="headerlink" title="MRDBSCAN"></a>MRDBSCAN</h3><p>最近一段时间，我接触到了分布式计算，并且在尝试使用Spark完成一些分布式计算的任务。我也了解到了一个比较前沿的分布式使用DBSCAN的算法：MRDBSCAN。</p>
<p>下面对这个算法做一些简单的记录以及报告：</p>
<ol>
<li><p>第一步将平面划分为等点数的几个子平面。</p>
</li>
<li><p>将每个子平面交给一个Worknode去进行DBSCAN的划分。</p>
</li>
<li><p>收集每个子结点计算的结果，考虑子平面边界的情况，对于边界的点，能够向哪边传播，就属于哪边的簇，如果两边都能够同时传播，那么它就属于两边的簇，这时说明两边的簇能够连接到一起去，这时将两边修改为同样的颜色。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1flyx4irf5oj30ri0gm451.jpg" alt=""></p>
</li>
</ol>
<h3 id="下一步方向规划"><a href="#下一步方向规划" class="headerlink" title="下一步方向规划"></a>下一步方向规划</h3><p>目前我的方法是基于差分-&gt;DBSCAN-&gt;LSTM进行的组合方法的异常点+异常模式段的识别。</p>
<p>下一步我打算分为以下两个阶段进行：</p>
<ol>
<li>去广泛的使用其他的算法进行异常点（和差分比较）和异常模式（和DBSCAN+LSTM比较）识别检测的效果比较。</li>
<li>将差分找异常点的算法打成包或者写成函数，向外提供调用的接口。</li>
<li>尝试针对于时序数据特性改进DBSCAN算法，并且尝试实现此函数。</li>
</ol>
<h3 id="一些疑惑"><a href="#一些疑惑" class="headerlink" title="一些疑惑"></a>一些疑惑</h3><ol>
<li>能够实现同样效果的有很多其余的算法，浩哥也在研究其他的一些算法，但是有一些算法时间空间效果不高，对于工业大数据要求的尽可能 $O(N)$ 级别的处理速度，这些算法还有其研究的意义吗？我们有没有必要去广泛的收集各类算法进行比较，测试？即使它看起来很慢而且效果不见得会很好。</li>
<li>目前我们的数据感觉存在低质量的情况，很多时候做不出和理论相近的效果，这方面可能会牺牲一些，需要用户自己多设置一些参数，去调整最后的效果。</li>
<li>最后用户希望从我们的系统检测出来的异常值获取什么信息，能够对工业上有什么帮助呢？</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://www.luodian.ink/2017-11-29/11-29-异常检测周报/" data-id="cjeaokibr0001f51yw6junsji" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-机器学习-第四章-SVM" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017-11-26/机器学习-第四章-SVM/" class="article-date">
  <time datetime="2017-11-26T11:41:31.000Z" itemprop="datePublished">2017-11-26</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017-11-26/机器学习-第四章-SVM/">机器学习-第四章-SVM（Updating）</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>主要梳理以下三个方向：支持向量机，核函数，序列最小最优化算法</p>
<h2 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h2><p>支持向量学习方法包含构建线性可分支持向量机（Linear support vector machine in linearly separable case）、线性支持向量机（Linear support vector machine）及非线性支持向量机（non-linear support vector machine）。</p>
<p>在提到SVM以及逻辑回归，有如下几种情况。</p>
<ul>
<li>当我们使用线性可分的数据集时，通过硬间隔最大化（hard margin maximization），学习一个线性的分类器，即线性可分支持向量机。</li>
<li>当训练数据近似可分，通过软间隔最大化（soft margin maximization），也学习一个线性分类器。</li>
<li>再则，当训练数据线性不可分时，通过引入核技巧（kernel trick）及软间隔最大化，学习非线性支持向量机。</li>
</ul>
<h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>假设在给定的特征空间训练集如下：$T = \{(x_1,y_1),…(x_n,y_n)\}$，其中，$x_i \in \chi= \Re^n, y_i \in \{1,-1\}$</p>
<p>假设训练数据集是线性可分的，我们需要找到一个分离的超平面 $w \cdot x + b$ 能够将不同的实例分成两部分，我们利用间隔最大化求最优的分离超平面，这时，解是唯一的。</p>
<h3 id="函数间隔和几何间隔"><a href="#函数间隔和几何间隔" class="headerlink" title="函数间隔和几何间隔"></a>函数间隔和几何间隔</h3><p><strong>函数间隔</strong>：</p>
<ol>
<li>定义给定的数据集 $T$ 和超平面 $（w，b）$.</li>
<li>定义超平面 $(w,b)$ 和样本点 $(x_i,y_i)$ 的函数间隔为：$\hat{\gamma} = y_i(w \dot x_i + b)$.</li>
<li>定义超平面 $(w,b)$ 和数据集 $T$ 的函数间隔为：$\hat{\gamma} = min_{1…n}(\hat{\gamma}_i)$.</li>
</ol>
<p><strong>几何间隔</strong></p>
<p>由于函数间隔在成倍数变化时，虽然超平面不变动，但是数值却在发生变化，因此我们继续定义几何间隔来对函数间隔进行规范化。</p>
<p>几何间隔：$\gamma_i = \frac{w}{\mid \mid w \mid \mid} \cdot x_i + \frac{b}{\mid \mid w \mid \mid}$</p>
<p><strong>为什么要间隔最大化</strong></p>
<p>对于训练数据及找到几何间隔最大化的超平面意味着以充分大的确信度（我们可以定义离超平面越远的点对于分类面的确信度越大）对训练数据进行分类，这样的分类结果对于最难分类的点也有足够大的确信度将其分开，这样的超平面应该对未知的新实例有更好的泛化的效果。</p>
<p><strong>支持向量和间隔边界</strong></p>
<p>在线性可分的情况下，训练数据的样本点与分离超平面距离最近的样本点的实例称为支持向量（Support Vector）.支持向量是使约束条件式子等号成立的点，即 $y_i(w \cdot x_i + b) - 1=0$</p>
<p>对于 $y_i = +1$ 的正例点，支持向量在超平面：$H_1:w \cdot x + b = 1$ 上。</p>
<p>对于 $y_i = -1$ 的负例点，支持向量在超平面：$H_1:w \cdot x + b = -1$ 上。</p>
<blockquote>
<p>在决定分离平面时只有支持向量起作用，支持向量两侧的其余点并不起作用，所以我们将这种分类模型称为支持向量机，支持向量的个数一般很少，所以支持向量机由很少的『重要的』训练样本决定。</p>
</blockquote>
<p><strong>拉格朗日对偶</strong></p>
<p>通过求解对偶问题的解来获取原问题的最优解，被称为Linear SVM的对偶算法，这样做的优点在于，一是，对偶问题往往更容易求解，二是，引入核函数，进而推广到非线性分类问题。</p>
<p>定义拉格朗日函数：$L(w,b,\alpha) = \frac{1}{2} \mid \mid w \mid \mid^2 - \Sigma^N_{i} \alpha_i y_i(w \cdot x_i + b) + \Sigma^N_{i} \alpha_i$. </p>
<p>对于支持向量需要尽量满足 $y_i(w  \cdot x_i + b) - 1 \geq0$，根据拉格朗日对偶性，原始问题的对偶问题是极大极小问题：$\max \limits_{\alpha} \cdot \min \limits_{w,b} \{L(w,b,a)\}$.</p>
<h2 id="核技巧"><a href="#核技巧" class="headerlink" title="核技巧"></a>核技巧</h2><p>当输入空间为欧式空间或者离散集合，特征空间为希尔伯特空间时，核函数表示将输入从输入空间映射到特征空间得到的特征向量之间的内积，通过核函数可以学习到非线性支持向量机，等价于隐式地在高维的特征空间中学习线性支持向量机，这样的方法称为核技巧。</p>
<p>概述的说，线性SVM+核技巧 = 非线性SVM。</p>
<blockquote>
<p>希尔伯特空间：抽象空间中的极限与实数上的极限有一个很大的不同就是，极限点可能不在原来给定的集合中，所以又引入了完备的概念，完备的内积空间就称为Hilbert空间。</p>
</blockquote>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://www.luodian.ink/2017-11-26/机器学习-第四章-SVM/" data-id="cjeaokidf001sf51ypetlb0vw" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-机器学习-第三章-逻辑回归" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017-11-26/机器学习-第三章-逻辑回归/" class="article-date">
  <time datetime="2017-11-26T11:39:47.000Z" itemprop="datePublished">2017-11-26</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017-11-26/机器学习-第三章-逻辑回归/">机器学习复习-第三章-逻辑回归（Updating）</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
      
    </div>
    <footer class="article-footer">
      <a data-url="https://www.luodian.ink/2017-11-26/机器学习-第三章-逻辑回归/" data-id="cjeaokid8001pf51yydxwnaie" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-机器学习-第二章-概率" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017-11-25/机器学习-第二章-概率/" class="article-date">
  <time datetime="2017-11-25T02:22:10.000Z" itemprop="datePublished">2017-11-25</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017-11-25/机器学习-第二章-概率/">机器学习复习-第二章-概率</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="几个公式"><a href="#几个公式" class="headerlink" title="几个公式"></a>几个公式</h3><ul>
<li>贝叶斯公式：$P(B \mid A) = \frac{P(B)  \cdot  P(A \mid B)}{P(A)}$</li>
<li>全概率公式：$P(A) = \Sigma_{n} P(A \mid B_n) \cdot P(B_n)$.</li>
</ul>
<h3 id="生成模型与判别模型"><a href="#生成模型与判别模型" class="headerlink" title="生成模型与判别模型"></a>生成模型与判别模型</h3><p>监督学习的任务就是学习一个模型，应用这一模型，对给定的输入预测相应的输出，这个模型的一般形式为决策函数：$Y = f(x)$，或者条件概率分布：$P(Y \mid X)$</p>
<p>监督学习方法又可以分为生成方法（Generative Approach）和判别方法（Discriminative Approach），所学习到的模型分别称为生成模型和判别模型。</p>
<h4 id="生成方法"><a href="#生成方法" class="headerlink" title="生成方法"></a><strong>生成方法</strong></h4><p>生成方法由数据学习联合概率分布 $P(X,Y)$，然后求出条件概率分布 $P(Y \mid X)$ 作为预测的模型.</p>
<p>即生成模型：$P(Y \mid X) = \frac{P(X,Y)}{P(X)}$</p>
<p>这样的方法之所以称为生成方法，是因为模型表示了给定输入 $X$ 产生输出 $Y$ 的生成关系，典型的生成模型有：朴素贝叶斯方法和隐马尔科夫模型。</p>
<h4 id="判别方法"><a href="#判别方法" class="headerlink" title="判别方法"></a><strong>判别方法</strong></h4><p>判别方法由数据直接学习决策函数 $f(X)$ 或者条件概率分布 $P(Y \mid X)$ 作为预测的模型，即判别模型。判别方法关心的是对给定的输入 $X$，应该预测什么样的输出 $Y$。典型的判别模型包括：$k$ 近邻法，感知机，决策树，逻辑斯蒂回归模型，最大熵模型，支持向量机，提升方法和条件随机场等。</p>
<h4 id="评价分类指标"><a href="#评价分类指标" class="headerlink" title="评价分类指标"></a>评价分类指标</h4><p><strong>准确率（accuracy）</strong></p>
<p><strong>精确率（precision）</strong></p>
<p><strong>召回率（recall）</strong></p>
<h3 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h3><p>医生对病人进行诊断就是一个典型的分类过程，任何一个医生都无法直接看到病人的病情，只能观察病人表现出的症状和各种化验检测数据来推断病情，这时医生就好比一个分类器，而这个医生诊断的准确率，与他当初受到的教育方式（构造方法）、病人的症状是否突出（待分类数据的特性）以及医生的经验多少（训练样本数量）都有密切关系。</p>
<p>回忆朴素贝叶斯中的公式 $P(Y = y_k \mid X_1,X_2,\ldots X_n) = \frac{P(Y = y_k)\prod_i P(X_i \mid Y = y_k)}{\Sigma_j ( P(Y = y_j)\prod_i P(X_i \mid Y = y_j))}$</p>
<p>对比与医生看病，就是医生利用他已知的发病的征兆，结合病人的征兆去获取这个 $\prod_i P(X_i \mid Y = y_k)$，然后再结合发病的概率，去推断病人现在身上的征兆，有多大的可能发病。</p>
<p>朴素贝叶斯学习和分类器与其他相比可以非常快。在条件独立的假设下，类条件特征分布的解耦意味着 每个分布可以独立估计为一个一维分布，这反过来又有助于缓解维灾难问题。</p>
<p><strong>高斯朴素贝叶斯的训练过程</strong></p>
<ul>
<li><p>训练：对于每个 $y_k$：</p>
<ol>
<li>估计 $\pi_k (即P(Y = y_k))$</li>
<li>对于 $X$ 的每一个属性 $X_i$，估计类条件均值和方差 $\mu_{i,k},\sigma_{i,k}$.</li>
</ol>
</li>
<li><p>分类：</p>
<ol>
<li><p>$Y_{new} \leftarrow argmax_{y_k} \prod_i {P(X^{new}_i \mid Y = y_k)}$</p>
</li>
<li><p>$Y_{new} \leftarrow argmax_{y_k} \pi_k \prod_i N(X^{new}_i,\mu_{i,k},\sigma_{i,k}) $</p>
</li>
<li><p>对于均值和方差的计算如下：</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1flvkhkdjluj315o0m20wb.jpg" alt=""><strong>一些问题</strong></p>
<ol>
<li>怎么对两组数据进行独立性检验？<ul>
<li>皮尔森卡方检验</li>
</ul>
</li>
<li>标准的朴素贝叶斯分类器的决策面看起来是什么样的？<ul>
<li>对于高斯分布的话，如果两个类的协方差相同，决策面是线性的超平面</li>
</ul>
</li>
</ol>
</li>
</ol>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://www.luodian.ink/2017-11-25/机器学习-第二章-概率/" data-id="cjeaokidh001vf51yy0qolgj1" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-机器学习-第一章-决策树" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017-11-24/机器学习-第一章-决策树/" class="article-date">
  <time datetime="2017-11-24T11:00:13.000Z" itemprop="datePublished">2017-11-24</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017-11-24/机器学习-第一章-决策树/">机器学习复习-第一章-决策树（Updating）</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>在这里我记录下在学习决策树之后，我自己的思考以及重点，不会包含太多介绍性的内容。</p>
<p>新手入门的话推荐周志华的《机器学习》和李航的《统计学习方法》。</p>
<h3 id="信息熵，基尼系数，分类误差定义"><a href="#信息熵，基尼系数，分类误差定义" class="headerlink" title="信息熵，基尼系数，分类误差定义"></a>信息熵，基尼系数，分类误差定义</h3><h3 id="关于过拟合"><a href="#关于过拟合" class="headerlink" title="关于过拟合"></a>关于过拟合</h3><p>决策树十分容易产生<strong>过拟合</strong>的情况，也就是说当前的决策树有很多的节点，整个决策树很大，此时会把样本中一些并不需要拿来作为分类的属性学习到，因此学习的决策树模型并不是最优的模型，这就是机器学习中的过拟合现象，与此相关的概念就是欠拟合，欠拟合主要是因为当前的样本不够，导致实际在学习的时候可以用来学习的信息很少，因此也会出现学习不好的现象。</p>
<h3 id="预处理（Pre-Prunning）"><a href="#预处理（Pre-Prunning）" class="headerlink" title="预处理（Pre-Prunning）"></a>预处理（Pre-Prunning）</h3><ol>
<li>在树已经成长成为完全树之后停止算法。</li>
<li>对于结点的剪枝规则<ul>
<li>当所有类可以被分到一个类别时。</li>
<li>当某些类别的数量小于用户设定的阈值。</li>
<li>当某个结点并不能带来显著（高于阈值）的基尼系数（这里可以参考CART算法）或者信息熵的增长时。</li>
</ul>
</li>
</ol>
<h3 id="后处理（Post-Prunning）"><a href="#后处理（Post-Prunning）" class="headerlink" title="后处理（Post-Prunning）"></a>后处理（Post-Prunning）</h3><p>使用MDL的思想，对于决策树自底向上逐层扫描剪枝。</p>
<p>注意预剪枝和后剪枝都可以使用验证集作为是否分裂的标准，与决策树的构建先后无关。<br>但两者所获得的结果是有区别的，往往后剪枝获得的决策树要比预剪枝获得的大，且欠拟合风险很小，泛化性能往往更优，但毫无疑问的是，后剪枝的开销更大。</p>
<h3 id="斜决策树"><a href="#斜决策树" class="headerlink" title="斜决策树"></a>斜决策树</h3><p>单变量决策树的每个节点都是使用一个属性，这样生成的决策树如果用坐标空间来刻画（属性即坐标轴），划分的边界都是平行于坐标轴的。 但有时候单一的属性很难刻画分类的边缘，会造成抖动，而这个抖动只需要一条斜边就可以很好的解决了，其实所谓的斜边就是属性的线性组合，即节点使用多个属性的线性表达式来作为评判标准。</p>
<h3 id="缺失值"><a href="#缺失值" class="headerlink" title="缺失值"></a>缺失值</h3><p>对于缺失值需要考虑两个问题： </p>
<ol>
<li><p>样本集属性缺失，如何根据缺失的属性来选择划分节点？</p>
<p>在不做缺失值填充的情况下，显然只能使用在该节点没有确实值的子样本集进行计算，然后信息增益的计算最后需要乘上一个不缺失系数（即该节点不缺失的样本集数与总样本的比） 。</p>
<p>假如你使用 ID3 算法，那么选择分类属性时，就要计算所有属性的熵增(信息增益，Gain)。假设10个样本，属性是 $a,b,c$。在计算 $a$ 属性熵时发现，第10个样本的 $a$ 属性缺失，那么就把第10个样本去掉，前9个样本组成新的样本集，在新样本集上按正常方法计算 $a$ 属性的熵增。然后结果乘 0.9（新样本占raw样本的比例），就是 $a$ 属性最终的熵。</p>
<p>这里给出一个课程 handouts 中的图示。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fltohlpn1aj315o0pmgwf.jpg" alt=""></p>
</li>
<li><p>预测集属性缺失 </p>
<p>若预测时，某个属性缺失，则以一定概率将该样本划分到该节点的各个取值中。至于这个概率如何选取，参考资料决策树是如何处理不完整数据的？</p>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://www.luodian.ink/2017-11-24/机器学习-第一章-决策树/" data-id="cjeaokidb001qf51ykk7hrqkw" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-11-24-异常检测周报" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017-11-24/11-24-异常检测周报/" class="article-date">
  <time datetime="2017-11-23T18:54:39.000Z" itemprop="datePublished">2017-11-24</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/异常检测/">异常检测</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017-11-24/11-24-异常检测周报/">11-24-异常检测周报</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>这周的工作主要有了两个方向的进展，下面的报告分以下两个方面阐述。</p>
<h3 id="一、异常点的识别"><a href="#一、异常点的识别" class="headerlink" title="一、异常点的识别"></a><strong>一、异常点的识别</strong></h3><p>首先要解释下，其实单一维度和多维度异常点识别可以看成是两类异常情况的识别，并不能简单的将单一维度看成是多维度的简化版本，对于我们手里的这组传感器数据，理性的思考，多维度的异常其实并不容易发生，很多时候其实就只是某个传感器的数据出了问题，但是我们利用多维的异常检测，比如iforest，DBSCAN聚类去扫描的方法，其实是不容易看出这点异常的，而且也有可能存在，本来就是单点异常，但是我们却把这个时段的所有点标记成异常，导致可能工人需要去检查所有的传感器，这样实际操作中费时费力且算法层面并不高效（iforest还好，但是DBSCAN最少都是nlogn的）。</p>
<p>因此目前我认为，不能先入为主的拿多维去做异常检测，而是首先对单一维度做异常的检测，也可以对多个强相关的维度进行协同检测。</p>
<p>下面首先讲述下我对于单一维度异常检测的一些思考和实验结果。</p>
<ol>
<li><p><strong>单一维度：差分方法</strong></p>
<p><strong>思路</strong></p>
<p>利用多阶段的差分，我们可以识别出单点以及模式的异常。这个idea来自于梯度，当函数突然出现了一个异常的峰值点，或者是出现了突然地连续下降时，这个点的领域的梯度一定是有别于周围的其他点的，但是对于求区间的梯度（或者是斜率），我们首先要知道我们怎么去划分这个区间，但是这个区间的长度却会因数据的变化而动态变化（注意这里跟周期不是一个概念，虽然周期也是动态变化的），我们不容易确定这个值，因此我们选择利用差分，我们初始的差分可以从前后两个点开始，然后逐渐的调整差分的参数（实际上也就是去动态的找这个区间），显然单点异常一定会在差分之后的结果中突出出来，而模式的的异常，我们在增加差分的区间长度之后，也会显示出来。</p>
<p>下面的图中，第一行是原始数据，第二行是diff(1)的结果，第二行是diff(100)的结果。</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1flsjizl61rj31kw0ub7a8.jpg" alt="Figure_2"></p>
<p>从图中可以看出在diff（1）的时候，已经可以看出异常点了，而在diff（100）的时候，我们成功的检测到了梯度的突然下降。</p>
<p>再回到差分这个方法，虽然这个思想简单，比不得高大上的其他机器学习算法，但是目前这是我能够想到的效果不错，且效率最高的算法，因为这是一个在线的算法，它不需要累计一段时间的数据然后统一的进行处理（我使用过isolation forest和lof，效果不如差分好，且它们并不能实时的计算），我们可以部署到传感器上，自己就能轻松的实现报警。</p>
<p><strong>还需改进的地方</strong></p>
<p>目前差分对于简单异常点的识别非常暴力且轻松，但是对于比如某个区间梯度突然地变化这种异常情况，会比较依赖于差分参数的选择，而这个差分参数怎么自动化调整，是一个需要进一步解决的问题，我也在思考，目前有些思路比如『每个点统计前后n个点的均值方差，然后判断这个点究竟是需要进行一阶差分还是需要更高阶的差分』，这些思路其实也可以和聚类结合起来，因为最终我们的目的是<strong>去识别出函数断层的地方！</strong>，能够实现这个，我们的异常检测就能够粗略的达到了要求。</p>
</li>
<li><p><strong>多维协同：孤立森林方法</strong></p>
<p>这个方法对于单维数据，我并不推荐，我认为它的用处可以用作多维协同（多维一定要选取强相关的维度，否则一定会出错，而自动判定维度之间是否强相关是一个复杂度很高的问题！）的异常检测，这里我就不再赘述。</p>
</li>
</ol>
<h3 id="二、异常模式的识别"><a href="#二、异常模式的识别" class="headerlink" title="二、异常模式的识别"></a>二、异常模式的识别</h3><p>首先也需要解释，我对于异常模式识别的理解，首先我们的目标是要识别出正常的模式，然后有别于这种模式的其他段就是异常。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1flsjky0cjrj31640gygno.jpg" alt="187EB725735840F8C13A1C65EA598139"></p>
<p>​        </p>
<p>而识别正常模式的第一个阶段，我认为需要去对总的数据进行分类（不能拿整体数据进行模式的识别），对于上面的数据，如果我们能够大致的判断出其中包括了三类区间，就能够用神经网络（LSTM）对小区间的模式进行识别，那么我们针对于这种情况，能够想到的只有聚类这个方式。目前常用的聚类方法我认为可行的只有K-Means和DBSCAN，下面分别对这两种方法进行说明。</p>
<ol>
<li><p><strong>K-Means</strong></p>
<p>对于kmeans其实效果都还挺好，但是这个方法的局限性在于我们需要为我们的数据指定固定的cluster的个数。</p>
<p>下面是对15，16，17，18列的数据进行协同的模式分析（这里也要说明，如果要对多维数据协同分析，一定要利用先验知识或者是互相的拟合关系说明他们是强相关的，在下面的四组数据中实际上我为了观察聚类效果能否将其他维度的非模式段拉到本维度的正常模式，而放松了这个界限）</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1flsjltrz88j31hc140dm2.jpg" alt="k-means-cluster5-with-time"></p>
</li>
<li><p><strong>DBSCAN</strong></p>
<p>DBSCAN相比如K-MEANS最具有优势的两点在于，其一，其不用指定数据的聚类，其二，其可以对于非凸的cluster进行较好的聚类，大致效果就是这个意思。</p>
<div align="center">![这里写图片描述](https://ws4.sinaimg.cn/large/006tKfTcly1flsjmxbcr4j309b0l1djr.jpg)</div>

<p>显然DBSCAN聚类的效果才是我们希望达到的目标，但是需要注意的是，这里的eps的选取对聚类效果影响很    大，同样这里也是影响到我对于windmachine数据测试的聚类效果一大关键的点。</p>
<p>在我调整参数的过程中出现了两个极端的情况。</p>
<p>第一种则是所有数据聚成一类</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1flsjnqw423j31kw16otng.jpg" alt="dbscan"></p>
<p>第二种情况则是算法自动将1000多个点分为了700多个类，效果五彩斑斓</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1flsjnzbp7gj31kw0ub78c.jpg" alt="Figure_2"></p>
<p>目前这个问题还没有解决，但是我有两个还没有实验的想法。</p>
<ol>
<li>我推测是没有正确的使用时间这个属性，权重？或者是对于已知异常点动态的加入参数。</li>
<li>对于1000个点分为了700类的情况，在图中实际可以看出类与类之间也有相似度的区别（从颜色就可以看出来），那么再对这个类的质心进行一次聚类，是否可以能够划分为更少的大类？</li>
</ol>
<p>后者方法其实我认为非常可行与可解，最近时间比较紧凑，但是我会尽快去做相应的尝试。</p>
</li>
</ol>
<ol>
<li><p><strong>聚类之后</strong></p>
<p>说完了聚类之后，那么对于较小区间的模式识别其实已经是有了现成的方法（但是时间复杂度很高，因此我们必须要尽可能多的去进行区间的识别，去划分有可能存在周期函数的区间出来再往上并行的套神经网络，不能对所有的层都做一遍线性的神经网络，复杂度太高了！）</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1flsjwmvzi7j31kw0ubq8a.jpg" alt="Figure_1"></p>
<p>如上图，我使用周期函数加了高斯噪声，并在中间这个地方加入了人工的异常点，进行了一组测试，LSTM是可以找出异常的模式并加以权重十分高的Error，我认为这个效果非常的好，所以我们只要能打通聚类的那一步，我认为对于区间函数下异常模式，其实是可以很好解决的。</p>
</li>
</ol>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ol>
<li><strong>差分</strong>目前主要的问题在于需要去细化差分的参数，使其不仅能够找出异常点，而也能够对区间的异常有一定的检测作用，这方面得去看一些金融时间序列的东西，希望能够从统计这里得到一些信息。</li>
<li>对于聚类，目前认为DBSCAN以及其各种改进，比如OPTICS，SNN是一些较好的方法，但是聚类我认为应该结合具有相关性的几个维度去做，然后做模式的区分，目前使用K-Means已经有了一个较可观的实现，希望能够有一定的效果。</li>
<li>我之后的方向是希望去细化研究上述1，2点，能够通过对DBSCAN的细化研究，希望能够将DBSCAN在特定的数据集上做一些自己的优化，然后还能够研究下DBSCAN在时间序列下的更适配的应用（要注意时间序列的时间这一维特性，是否完全不用？我认为不行，但是要怎么用，我也不太清楚）</li>
<li>LSTM是否是唯一最好的用于这种区间函数下异常模式识别的方法？我对神经网络了解的不多，我不太清楚，还需要请教一些高人。</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://www.luodian.ink/2017-11-24/11-24-异常检测周报/" data-id="cjeaokibn0000f51y2yiizzno" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/大数据异常检测/">大数据异常检测</a></li></ul>

    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    <a class="extend prev" rel="prev" href="/page/2/">&laquo; __('prev')</a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span>
  </nav>
</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Codeforces/">Codeforces</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Kaggle/">Kaggle</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/其余/">其余</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/分布式计算/">分布式计算</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/异常检测/">异常检测</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/投资/">投资</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/操作系统/">操作系统</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/时间序列/">时间序列</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/软件工程/">软件工程</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/量化交易/">量化交易</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/随想/">随想</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/大数据异常检测/">大数据异常检测</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/机器学习/">机器学习</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/大数据异常检测/" style="font-size: 10px;">大数据异常检测</a> <a href="/tags/机器学习/" style="font-size: 20px;">机器学习</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">三月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">二月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">一月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">十二月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">十一月 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018-03-01/2018-MetaTrade-网格交易简述/">MetaTrader-网格交易简述</a>
          </li>
        
          <li>
            <a href="/2018-02-26/异常检测-2018春季第一周周报/">异常检测-2018春季第一周周报</a>
          </li>
        
          <li>
            <a href="/2018-01-24/Contest-911-D-Inversion-Counting/">Contest-911-D-Inversion Counting</a>
          </li>
        
          <li>
            <a href="/2017-12-29/基于统计方法进行时序数据预测的异常检测模型/">基于统计方法进行时序数据预测的异常检测模型</a>
          </li>
        
          <li>
            <a href="/2017-12-27/数据之美-时间序列分析/">数据之美-时间序列分析</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 Luodian<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>